

> **写在前面：**
> 
> 本期内容我们继续 Andrej Karpathy 的《How I use LLMs》讲座内容，原视频时长 ~130 分钟，以实操演示主流的一些 LLMs 的使用，由于涉及到实操，实际上并不适合以文字整理，但还是决定尽量整理一份笔记出来。我会尽量保留讲座中的主线内容，但内容上会有取舍，此外原视频中的很多案例都需高级付费用户才可以使用，但数月已过，情况可能有一些变化。
> 
> 总体而言，本篇内容实际上不太适合普通大众，在本系列内容中，重要演示一些 LLMs 释放出来的功能项的说明，至于这些功能是否对你日常生活或工作有帮助，就因人而异了。


## 一、主流 LLMs 概览
  
在第一期的 LLMs 系列科普文中，我们深入探讨了这些模型的底层训练原理，以及该如何理解它们的认知机制或心理运作方式。在本期的 LLMs 系列实操演示中，我们将以实操为重点，探讨这些 LLMs 工具的实际应用，会通过大量案例，展示一些可用的设置选项，以及你应该如何将它们应用到自己的生活和工作中。  
  
你可能已经知道，chatgpt 是由 OpenAI 开发并于 2022 年推出的，这是人们第一次能够通过文本界面与大型语言模型进行对话，这一现象迅速走红，席卷各地，影响巨大，且自那以后，整个生态系统已经发展壮大。  
  
截止到目前，市面上已经出现了许多类似 chatgpt 的应用，整个生态变得更加丰富多元，OpenAI 开发的 chatgpt 可以堪称行业鼻祖——它不仅是用户量最大的平台，功能也最全面，毕竟问世时间最久。这么说其实也并不准确，现在市面上也有不少替代者可供选择，它们也确实存在一些 chatgpt 所不具备的独特体验，我们后面会看到一些例子。  

<img src="https://i-blog.csdnimg.cn/direct/b40b10b776614696a9489921f828800e.png#pic_center" width="500">

目前，许多大型科技公司已经推出了许多类似 chatgpt 的体验，如上图，谷歌的 Gemini、Meta 的 Meta AI 以及微软的 Copilot。此外还有许多初创公司。例如，Anthropic 推出了Claude，马斯克的 XAI 公司开发了 Grok，这些都是美国公司的产品。DeepSeek 是中国的，Le Chat 是法国公司 Mistral 的产品。  
  
上一期最后一章节中，我们提到了 Chatbot Arena[^1]，你可以在这里看到不同模型的排名，并了解它们的实力或 Elo 评分。  
  
<img src="https://i-blog.csdnimg.cn/direct/597184f3816e4276b906e5339c515d2e.png#pic_center" width="600">
  
目前该网页也从原始 huggingface spaces 中 独立出来了，并根绝文本、网页开发、视觉、文生图、网络搜索、AI 编码助手等多个场景独立出来了  
  
另一个地方是 Scale 的 SEAL 排行榜[^2]。  
  
<img src="https://i-blog.csdnimg.cn/direct/b4137a4e63484c3f9a7a289f96502da1.png#pic_center" width="600">
  
在这里你也能看到不同类型的评估方式和各种模型的表现排名。你还可以来这儿了解哪些模型目前在各类任务中表现最佳。  
  
要知道 LLMs 生态相当丰富，但眼下我们先从 OpenAI 开始，因为它是行业标杆且功能最全面。  
  
## 二、ChatGPT 交互原理揭秘  

<img src="https://i-blog.csdnimg.cn/direct/3fd5964ee3e34f2ea1ef4707e3a8f0cb.png#pic_center" width="600">
  
我们从 ChatGPT 开始，打开 chatgpt.com，你会看到一个文本框，与 LLMs 最基本的交互形式是：我们输入一段文字，然后它会返回一些文字作为回应。

举个例子，我们可以要求它写一首关于作为大型语言模型是什么感觉的俳句。  
  
<img src="https://i-blog.csdnimg.cn/direct/33cd1c23aa4c4735a681ab870c0ecc9a.png#pic_center" width="600">
  
> 注：上文大概翻译：无声处，言语绽放，无尽思绪，无言之声 ——  你所问的，正是我所梦。 
  
这是一个很好的语言模型示例任务，这些模型非常擅长写作，无论是写俳句、诗歌、求职信、简历还是邮件回复，它们都表现得非常出色。

### 2.1 对话中的 tokens
  
在这里我们重新回顾一下在上期科普系列中介绍的内容，当我们输入了这样的一段文本并回车后，实际上这背后的运作机制是什么样的？  

<img src="https://i-blog.csdnimg.cn/direct/849b8823c50a4ab8ac7c114d7a663d8c.png#pic_center" width="600">
  
我们的输入文本会被 tokenizer 为一个一维的 token 序列，具体来说，我们的这段文本被切分为 15 个 tokens

<img src="https://i-blog.csdnimg.cn/direct/19480e00cbc54760a5ca05a6e8d3f5a0.png#pic_center" width="600">
  
我们把模型的响应也粘贴过来，它是一个 18 个 tokens 的序列。但实际上我们需要保留大量构成对话对象的元数据，所以实际后台处理的内容远不止这些。  

<img src="https://i-blog.csdnimg.cn/direct/b634bbcc01e847f297646e1ed8e34edc.png#pic_center" width="600">
  
这个就是模型实际在处理的 tokens 序列，这里包含了用户消息随后是模型的应答消息，通过一些特殊 tokens 进行隔离的，如果你忘记了这些，可以找到上一期的文章重新复习一下。  

<img src="https://i-blog.csdnimg.cn/direct/06ed9c9d31d44f65b5b114711fc57b2c.png#pic_center" width="600">
  
在这里我们使用最直接的 API 访问方式，chatgpt 接口会给出详细的一些统计数据，例如我们可以看到 `prompt_tokens` 是 22，`completion_tokens` 是 20，我们可以把这段新生成的文本再粘贴过来，  

<img src="https://i-blog.csdnimg.cn/direct/e08a8e683bb7476ba618dfae67a1b04c.png#pic_center" width="600">
  
在上面我们看到，我们的实际输入只有 15 个 token，而 API 返回的结果是 22，而多出来的这些 tokens 实际就是开头的 `<|im_start|>`、`user`、`<|im_sep|>` 以及我们实际输入内容之后的 `<|im_end|>`、`<|im_start|>`、`assistant`、`<|im_sep|>` 共 7 个特殊 token，而 API 返回的总 token 是 42，而我们这里看到的是 43 个，这是因为最后一个 token `<|im_end|>` 并不包含在内，这将作为下一轮对话的附加内容，即 `completion_tokens` 实际上只包含模型实际的应答内容，而不包含其他特殊 token，之所以这样安排，是因为这涉及到费用计算的问题，因为我们的输入 token 和 LLMs 响应内容的计价不同，以此处的 gpt-4o 为例，输入/输出分别是 2.5/10 美元，这里都是指每百万 tokens 的价格，相差 4 倍。  

<img src="https://i-blog.csdnimg.cn/direct/e9d73b1592184f5a823bc36a77d8af9b.png#pic_center" width="600">
  

-----------

### 2.2 对话图解

如果我们此时新建一个聊天窗口，一切又会重新开始，即将会话中的 token 清空，一切又从头开始。现在我们与模型对话时的示意图是这样的：  

<img src="https://i-blog.csdnimg.cn/direct/8c6a22490ad64d4c885c03cddc0bbd5d.png#pic_center" width="600">
  
当我们点击“新聊天窗口”时，就开启了一个新的 token 序列。作为用户，我们可以将 token 写入此流中，然后当我们按下回车键时，控制权就转移给了语言模型。语言模型会以它自己的 token 流作为响应。语言模型有一个特殊的 token，基本上是在表达类似“我完成了”的意思。因此，当它发出那个特殊 token 时，ChatGPT 应用程序将控制权交还给我们，我们可以进行下一轮对话。我们共同构建这个 token 流，也就是我们所说的 *上下文窗口*。所以，上下文窗口有点像这些 token 的工作记忆，任何在这个上下文窗口内的内容都像是这次对话的工作记忆，模型可以非常直接地访问它。  
  
那么，我们正在与之对话的这个实体究竟是什么？又该如何理解它呢？其实，我们之前视频中已经看到，这个语言模型的训练过程分为两个主要阶段：预训练阶段和后训练阶段。预训练阶段有点像把整个互联网的内容切分成一个个 token，然后压缩成一个类似压缩包的文件。但这是一个有损且概率性的压缩文件，因为我们无法用一个仅约 1TB 大小的压缩文件来完整呈现整个互联网的信息量——数据实在太过庞大。所以我们只能在这个压缩文件中捕捉到整体印象或大致氛围。  
  
实际上，这个压缩文件里包含的是神经网络的参数。举个例子，一个 1TB 大小的压缩文件大约对应着神经网络中一万亿个参数。而这个神经网络的主要功能是接收输入的 tokens，并尝试预测序列中的下一个 token。但它是在互联网文档上这么做的，所以它有点像是一个互联网文档生成器，在预测互联网上序列中的下一个 token 的过程中，神经网络获得了大量关于世界的知识。这些知识都被表示、填充并压缩在这个语言模型大约一万亿个参数中。  
  
现在我们也看到预训练阶段相当昂贵。因此，这可能会花费数千万美元，比如三个月的训练时间等等。所以这是一个成本高昂的漫长阶段。正因如此，这一阶段并不经常进行。  

<img src="https://i-blog.csdnimg.cn/direct/d15730dd6c4947c5baed8b69ac479b98.png#pic_center" width="600">

举个例子，我们使用的 GPT-4o 这个模型默认现在指代的还是 2024-08-06 这个版本，通过上面爱你的 API 请求返回结果中也可以印证这件事，这都大半年时间了，尽管后期在 11-20 也释放了一个新的版本，这就是为什么这些模型有点过时，它们有一个所谓的知识截止日期，因为这个截止点对应的是模型预训练的时间，它的知识只更新到那个时间点。  
  
> 模型后加上日期是一种常用的方式，带通常会存在一个不带有时间信息的名字，如 gpt-4o，它类似一个指针，实际上目前指代的是 2024-08-06 这个版本，后续有可能会自动切换到 2024-11-20 版本上，因此如果你在项目中直接使用 'gpt-4o' 可能会在一段时间内发生底层模型切换，导致行为不一致的情况，因为每一版本的模型使用的训练数据或训练方法不尽相同，因此如果某一版本的模型是你比较青睐的，请直接使用带有时间戳的具体模型名称；当然如果一致性不是你关心的问题，则可以一直使用 'gpt-4o' 这样你总是在使用相对最新的版本。  
  
现在有些知识可以通过后训练阶段进入模型，这一点我们稍后会谈到。但大致来说，你应该把这些模型想象成有点过时的东西，因为预训练成本太高且不常进行。所以任何近期信息，比如你想和模型讨论上周发生的事情，我们就需要通过其他方式向模型提供这些信息，因为这些内容并没有存储在模型的知识库中。所以我们会使用各种工具来为模型提供这些信息。  
  
在预训练之后，第二阶段就是后训练。而后训练阶段实际上就是给这个压缩文件加上一个笑脸表情。因为我们不想生成互联网文档，我们希望这个东西能扮演一个回应用户查询的助手角色。而这正是通过后训练过程实现的，我们将数据集替换为由人类构建的对话数据集。这基本上就是模型获得这种角色特性的过程，这样我们就能提出问题并得到回答。  
  
因此，它采用了助手的风格，这是通过后训练实现的，但它拥有整个互联网的知识，这是通过预训练获得的。现在我认为这部分需要重点理解的一点是，默认情况下，你正在与之交谈的是一个完全独立的实体。  
  
这个语言模型，你可以把它想象成磁盘上的一个 1TB 文件。实际上，它代表着神经网络内部的一万亿个参数及其精确设置，这些参数正试图为你生成序列中的下一个 token。但这是一个完全自包含的实体，没有计算器，没有计算机和 Python 解释器，没有浏览器功能，也没有任何工具使用——至少在我们目前讨论的范围内还没有这些功能。你正在与一个压缩文件对话，如果你向它传输 tokens，它也会以 tokens 回应。这个压缩文件既包含预训练中获得的知识，又具备后训练形成的风格与形式。大致上，你可以这样理解这个实体的运作方式。  

<img src="https://i-blog.csdnimg.cn/direct/6eff0bcc0eae481bb2fcb40c53a245fa.png#pic_center" width="500">
  
> 翻译："嗨，我是 ChatGPT。我是一个 1TB 大小的压缩文件。我的知识来源于互联网，大约半年前读过，现在只记得个大概。我讨人喜欢的性格是由 OpenAI 的人类标注员通过示例编程出来的 :)"  
  
所以个性是在后训练阶段编程进去的，而知识则是在预训练期间通过压缩互联网获得的，这些知识有点过时，而且是概率性的，稍微有点模糊。互联网上经常被提及的事物，会比那些鲜有讨论的内容记得更清楚，这与人类的记忆模式非常相似。


[^1]: leaderboard: https://lmarena.ai/leaderboard

[^2]: seal leaderboards: https://scale.com/leaderboard
