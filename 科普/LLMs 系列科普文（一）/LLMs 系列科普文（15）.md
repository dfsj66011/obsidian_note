
前面 14 篇文章，就是本系列科普文中想介绍的大部分技术内容。重点讲述了训练这些模型的三个主要阶段和范式：*预训练、监督微调和强化学习*。

我向你们展示了这些步骤大致对应于我们已用于教导儿童的过程。具体来说，我们将预训练比作通过阅读说明获取基础知识，监督微调则是通过大量范例模仿专家并练习解题的过程。唯一的区别在于，我们现在需要为大型语言模型和人工智能编写涵盖人类知识所有学科的教材，包括我们希望它们实际应用的领域，如编程、数学以及几乎所有其他学科。

因此，我们正在为他们编写教材，完善我提出的所有高层次算法，当然还要在高效大规模训练这些模型方面做到极致。具体来说，虽然我没有深入太多细节，但这些任务规模极其庞大且复杂，属于分布式作业，需要在数万甚至数十万个 GPU 上运行。而实现这一切所需的工程技术，确实代表了当前计算机技术在这种规模下所能达到的最高水平。所以我并没有过多涉及这方面，但归根结底，所有这些看似简单的算法背后都蕴含着非常严肃的探索。此外，我也稍微谈到了这些模型的智力问题，我希望你们记住的是：*这些模型确实很出色，但它们本质上只是辅助你工作的工具。你不应该完全信任它们*——我也给你们展示过一些相关的例子。

尽管我们已经采取了缓解幻觉的措施，但模型并不完美，它们仍会产生幻觉。随着时间的推移，情况有所改善，未来还会继续改进，但幻觉现象仍可能发生。换句话说，除此之外，我还介绍了我称之为"瑞士奶酪"式的大语言模型能力认知框架，这应该是你们需要牢记在心的。

![[cheese.png|300]]
这些模型在众多不同学科领域表现出色得令人难以置信，但在某些独特案例中却会莫名其妙地出错。比如问 9.11 和 9.9 哪个更大？模型可能答不上来，但它同时又能解答奥赛难题。这就像瑞士奶酪上的孔洞，类似的漏洞还有很多，你肯定不想被它们绊倒。

所以*不要把这些模型当作完美无缺的典范*。要检查它们的工作成果。把它们当作工具来使用。将它们作为灵感来源。将它们用于初稿，但要把它们当作工具来使用，并最终对你工作的成果负责。这就是我大致想说的内容。这就是它们的训练方式，也是它们的本质。

## 十五、其他方面

我们将探讨这些模型的一些潜力，看看它们可能具备哪些其他能力。我有几个要点可以分享，这些都是可以期待的进展。首先，你会注意到模型将很快变得多模态化。

### 多模态

我所讨论的一切都围绕着文本展开，但我们现在或很快就有了一些不仅能处理文本，还能 *原生* 且轻松地操作音频的 LLMs，这意味着它们可以听和说；同时也能处理图像，从而能够看和绘制。我们已经看到了这一切的雏形，但这一切都将原生地在语言模型内部完成，这将促成一种近乎自然的对话。大致来说，这与我们之前讨论的所有内容并无本质区别，因为从根本上讲，你可以将音频和图像进行 token 化处理，并应用我们之前讨论过的完全相同的方法。

> 需要说明的是，你现在使用的一些模型，尽管也可以处理图片，甚至可以直接语音对话，大部分其实并不是原生支持的，而是借助了类似外部工具这种专门用于处理图片或语音的模型处理，将其转为 LLMs 可以接收的 token 再进一步处理，这并不是原生的，近期比较典型的原生场景是，gpt-4o 可以直接原生的按用户指令完整图像创作，而以往通常是调用 DaLL·E 模型，这是一个专门用于图像创作的模型。

所以这并不是根本性的改变。我们只需要添加一些 token。举个例子，对于音频的标记化，我们可以查看音频信号的频谱图切片，然后对其进行标记化，只需添加一些突然代表音频的新 token，并将它们加入上下文窗口，然后像上面那样进行训练即可。对于图像也是如此，我们可以使用图像块，将它们分别转换为 token，那么图像是什么呢？图像不过是一系列 token 的序列。这种方法实际上相当有效，而且在这一方向上已有大量早期研究。因此，我们可以创建代表音频、图像以及文本的 token 流，将它们交织在一起，并在同一个模型中同时处理所有这些内容。这就是多模态的一个例子。

---

### 代理（Agent）

其次，目前人们非常感兴趣的是，大部分工作都是我们把单个任务交给模型，比如“请帮我解决这个任务”。然后模型就会完成这个小任务。但如何有条理地组织任务执行以完成工作，仍取决于我们。目前这些模型还不具备在长时间内以连贯且能自我纠错的方式完成这类工作的能力，因此它们无法完全串联任务来执行这些耗时更长的工作。

但他们正在逐步实现，而且这一过程会随时间不断改进。不过，这里可能发生的情况是，我们将开始看到所谓的"智能代理"——它们会持续执行任务，由你进行监督和观察工作进展，这些代理会时不时向你汇报进度等等。因此，我们将看到更多长期运行的智能代理，这些任务不再只是几秒钟就能完成的即时响应，而是会持续数十秒、甚至数分钟或数小时之久。但正如我们之前讨论的，这些模型并非万无一失。因此，所有这些都需要监督。例如，在工厂中，人们会讨论自动化的人机比例。我认为在数字领域我们也会看到类似的情况，届时我们将讨论人类与智能体之间的比例关系，人类将更多地扮演数字领域中智能体任务的监督者角色。

接下来，我认为一切将变得更加无处不在却又隐于无形，就像被整合进各种工具中，渗透到每个角落。此外，有点类似电脑操作。目前这些模型还无法代表你执行操作，但我认为这是另一个要点。如果你看过 chatgpt 推出的 operator 功能[^1]，那就是一个早期的例子，你可以真正将控制权交给模型，让它代表你执行键盘和鼠标操作。因此，我认为这一点也非常有趣。

最后我想说的是，这个领域还有很多潜在的研究可做。其中一个例子就是类似于 *测试时训练*(test time training) 这样的方向。请记住，我们上面所做和讨论的一切都包含两个主要阶段。首先是训练阶段，我们会调整模型的参数以使其能很好地完成任务。一旦获得这些参数，我们就会固定它们，然后将模型部署用于推理。从那时起，模型就固定了。它不再改变，也不会从测试阶段的所有操作中学习。这是一个固定数量的参数。唯一变化的是上下文窗口中的 token。因此，模型能够进行的唯一学习或测试时学习类型，就是其动态可调整上下文窗口的上下文学习，这取决于它在测试时所执行的操作。但我认为这与人类仍有不同，人类实际上能根据所做的事情来学习，尤其是睡觉时。比如，你的大脑会更新参数之类的。目前这些模型和工具还没有类似的功能。

我认为还有很多更复杂的想法有待探索。尤其是考虑到上下文窗口是一种有限且宝贵的资源，这一点尤为必要。特别是当我们开始处理长时间运行的多模态任务时，比如输入视频，这些标记窗口将变得极其庞大——不是几千甚至几十万，而是远超这个数量级。而我们目前唯一能用的技巧就是延长上下文窗口。但我认为仅靠这种方法无法扩展到实际需要长时间运行的多模态任务。因此，我认为在某些领域、在某些迷宫般复杂的情况下，当这些任务需要非常长的上下文时，我们需要新的思路。

### 跟进 LLMs 发展

那么在哪里可以实时跟踪这些进展，并了解该领域最新、最前沿的动态。这里分享三个资源：

![[lmarena.png|600]]

第一，lmarena[^2]。这是一个大型语言模型排行榜，它对所有顶级模型进行排名。而排名是基于人类对比评测得出的，人类向这些模型提问，然后判断哪个模型给出的答案更好。他们不知道哪个模型对应哪个答案，只是单纯地评估哪个答案更优。在这些排名靠前的模型中基本比较垄断了，而且前几名中只有 deepseek 是 MIT 许可，它是开源的，任何人都可以下载使用它。如果你往下滑，还会看到更多，如果不知道该使用哪个模型，或者想知道哪个模型目前大概处于什么水平，可以参考一下这里，但这里的排名未必不存在某种人为操作的可能，因此还是要自己实测一下。

![[ainews.png|600]]

第二， ainews[^3]。这个名字起得不算很有创意，但它是由 SWIX 和朋友们制作的一份非常优秀的简报。感谢你们一直坚持更新。这份简报对我帮助很大，因为它涵盖的内容极其全面。所以如果你去档案库看看，就会发现它几乎每隔一天就会发布一次。内容非常全面，其中一部分是由人类撰写并由人类编辑的。但其中大部分内容是由大语言模型自动生成的。你会发现这些内容非常全面，如果你仔细阅读的话，基本不会遗漏任何重要信息。当然，你可能不会真的去通读它，因为它实在太长了。但我确实认为顶部的这些摘要相当不错，而且我认为有人工审核。所以这对我非常有帮助。

第三、X 或 Twitter，很多 AI 相关的动态都发在 X 上，我建议你关注那些你喜欢且信任的人，这样你也能在 X 上获取最新最棒的内容，当然这一代对于国内人群可能存在一些网络上的障碍。


## 十六、本科普系列总体概要

那么现在让我回到我们最初的问题。问题是：当我们访问 chatgpt.com，输入某个查询并点击“搜索”时，这里到底发生了什么？我们看到的是什么？我们在与什么对话？这一切是如何运作的？我希望这一系列文章能让你对这些模型的训练机制及其返回结果的内在原理有所了解。

具体来说，我们现在知道你的查询首先会被分解成一个个 tokens。所以我们来到 TickTokenizer。这里是用户查询的格式位置。我们基本上就是把查询内容放在这里。因此，我们的查询进入了我们这里所说的对话协议格式，也就是我们维护对话对象的方式。这样它就被插入到那里。然后，整个过程最终只是一个一维的 token 序列。
 
所以 chatgpt 看到了这个 token 序列后，它的作用类似于 token 自动补全。现在问题变成了：好吧，为什么模型会生成这些 token？这些 token 是什么？它们从何而来？我们到底在和什么对话？以及我们该如何编程这个系统？我们讨论了其背后的技术细节。

这个过程分为三个阶段，第一阶段是预训练阶段，其核心任务是从互联网获取知识并将其编码到神经网络的参数中。因此，神经网络会从互联网中吸收大量知识。但真正体现个性的地方在于这里的监督微调过程。具体来说，像 OpenAI 这样的公司会精心策划一个庞大的对话数据集，比如 100 万条涵盖各种主题的对话。这些对话将发生在人类和助手之间。

尽管在整个过程中使用了大量合成数据生成和大型语言模型的帮助，但本质上这是一项需要大量人力参与的数据整理工作。具体来说，这些人力是 OpenAI 雇佣的数据标注员，他们会学习标注指南。他们的任务是为任意提示创建理想的助手回应。

因此，他们通过示例来教导神经网络如何响应提示。那么，该如何理解这里返回的内容呢？这到底是什么？我认为正确的理解方式是，这是 OpenAI 数据标注员的神经网络模拟。也就是说，就像我把这个查询交给 OpenAI 的数据标注员，然后这位标注员首先阅读 OpenAI 的所有标注指令，再花两个小时写出针对这个查询的理想助手回复，最后交给我。所以，我们在这里得到的是那个过程的神经网络模拟。我们必须记住，这些神经网络的运作方式与人类大脑不同。

对他们来说容易或困难的事情与人类不同。因此，我们实际上只是在模拟。然后我们展示了一个神经网络，中间有一大堆激活函数和神经元。这是一个固定的数学表达式，它将来自 token 的输入与模型的参数混合在一起，经过混合后，就能得到序列中的下一个 token 。但这是针对每一个 token 进行的有限计算量。因此，这是一种有损的人类模拟方式，在某种程度上受到了这样的限制。无论人类写下什么，语言模型都只是在序列中逐个 token 地进行模仿，且每个 token 只能进行这种特定的计算。

我们也看到，由于这种机制和认知差异，模型会在多方面表现出不足。使用它们时必须非常谨慎。例如，我们发现它们可能会出现幻觉现象。此外，我们观察到大型语言模型的能力存在类似瑞士奶酪模型的特征——本质上就像奶酪上布满了孔洞。有时候模型就是会莫名其妙地犯傻。尽管它们能完成许多神奇的任务，但偶尔就是无能为力。可能你给它们的思考空间不够，也可能它们的"心算"崩溃了，于是就开始胡编乱造。也许他们突然不会数字母了，或者无法告诉你 9.11 比 9.9 小，这看起来有点蠢。所以这是一种漏洞百出的能力，我们必须小心对待。我们也看到了其中的原因。

后面我们提到了 RLHF，但我已经告诉过你们，RLHF 并不等同于 RL。那里没时间施展魔法。可以把它看作只是一种微调。但这些思维模型确实使用了强化学习。

因此，他们经历了完善思维过程的第三阶段，发现新的思维策略和解决问题的方法，这些方法有点像你头脑中的内心独白。他们在 OpenAI 等公司创建、整理并供大型语言模型使用的大量练习题上练习这些方法。当然，OpenAI 并没有向我们展示其背后的思考过程和推理链条，但我们知道这样的东西确实存在。

我认为，在可验证领域内发展出的思维策略能否迁移并推广到其他不可验证的领域（如创意写作），这是一个悬而未决的问题。可以说，该领域对这种迁移的程度尚不明确。因此，我们无法确定是否能在所有可验证事物上进行强化学习，并看到其对这类不可验证提示所产生的效益。所以这是一个悬而未决的问题。另一个有趣之处在于，强化学习仍然非常新颖、原始且处于萌芽阶段。因此，我们只是在推理问题中看到了伟大潜力的初步迹象。

我们正在见证一种原则上能够实现类似 MOVE37 水平的事物，但不是在围棋领域，而是在开放领域的思维和问题解决上。从理论上讲，这种范式能够做出一些真正酷炫、新颖且激动人心的事情，甚至是人类从未想到过的事情。原则上，这些模型能够进行人类从未有过的类比推理。所以我认为这非常令人兴奋。虽然它们已经存在，但目前仍处于非常早期的阶段，这些还只是原始模型。它们在可验证的领域（如数学和代码等）会表现得尤为出色。使用它们进行探索和思考非常有趣。大致就是这样。

总的来说，现在进入这个领域是一个极其激动人心的时刻。我个人每天都在使用这些模型，少则几十次，多则上百次，因为它们极大地加速了我的工作。我想很多人都看到了同样的现象。我认为这些模型将创造巨大的财富，但也要意识到它们的一些缺点。即使是强化学习模型，也会存在一些问题。*把它们当作工具箱中的工具来使用，不要完全信任它们*，因为它们有时会做出愚蠢的事情，产生幻觉，或者跳过一些心算步骤而得不到正确答案。有时它们甚至无法正确计数。所以，把它们当作工具箱中的工具，检查它们的工作，并对自己的工作成果负责。用它们来获取灵感、起草初稿，向它们提问，但始终要检查和验证。如果你这样做，你会在工作中非常成功。希望本系列科普对你来说既有用又有趣。






[^1]: gpt operator: https://operator.chatgpt.com/
[^2]: lmarena: https://lmarena.ai/leaderboard
[^3]: ainews: https://news.smol.ai/
