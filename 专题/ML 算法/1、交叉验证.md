
## 一、概述

交叉验证涉及将数据集划分为多个子集，并多次训练模型。每次使用不同的子集作为验证集，其余的作为训练集。这有助于更好地估计模型在未见数据上的表现。

## 二、动机

当进行 K 折交叉验证时，是在测试模型在某些数据上训练后预测未见数据的能力。我们使用交叉验证是因为如果用所有数据进行训练，就没有数据用于测试。这在数据有限时尤为重要。

我们可以用 80% 的数据进行训练，20% 进行测试，但如果选中的 20% 测试集恰好包含特别容易（或特别难）预测的数据点呢？这样我们可能无法很好地估计模型的学习和预测能力。不过，通过随机抽样可以在一定程度上缓解这个问题。

理想情况下，我们希望使用所有数据。以 80/20 划分为例，我们可以进行 5 折交叉验证，5 次用 80% 的数据训练模型，20% 测试。这样确保每个数据点恰好在 20% 的测试集中出现一次。因此，我们利用了所有数据点来帮助理解模型在从一些数据中学习和预测新数据方面的表现。

## 三、最终模型训练

交叉验证的目的不是为了得到我们的最终模型。我们不会用之前例子中的 5 个训练模型实例进行实际预测。为了得到最佳模型，我们需要使用所有数据。交叉验证的目的是模型检查，而不是模型构建。

假设我们有两个模型，比如线性回归模型和神经网络。如何判断哪个模型更好？我们可以进行 K 折交叉验证，看看哪个模型在预测测试集数据点时表现更好。但一旦通过交叉验证选出了表现更好的模型，我们就会用所有数据来训练该模型（无论是线性回归还是神经网络）。我们不会使用交叉验证中训练的模型实例作为最终预测模型。注意，有一种叫做自举聚合（通常简称为“bagging”）的技术，确实以类似于交叉验证的方式使用模型实例来构建集成模型。


