
- [Hyperparameter Tuning](https://aman.ai/primers/ai/hyperparameter-tuning/#hyperparameter-tuning)
- [Random Search and Grid Search](https://aman.ai/primers/ai/hyperparameter-tuning/#random-search-and-grid-search)
    - [Bayesian Optimization](https://aman.ai/primers/ai/hyperparameter-tuning/#bayesian-optimization)
- [References](https://aman.ai/primers/ai/hyperparameter-tuning/#references)
- [Citation](https://aman.ai/primers/ai/hyperparameter-tuning/#citation)


## 随机搜索和网格搜索

考虑如下函数 $f(x,y)=g(x)+h(y)$ 关于参数 $x,y$ 的最大化问题。$$\max_{x,y} f(x,y)$$
假设我们只能通过一个“预言机”（oracle）来访问函数 $f(x,y)$（即我们可以在某个点 $(x,y)$ 处计算 $f$ 的值，但我们不知道 $f$ 的函数形式）。  

问题在于……我们如何找到 $x$ 和 $y$ 的最优值？一个自然的想法是为 $x$ 和 $y$ 的值选择一个范围，并在这个范围内采样一个网格点。  

我们还可以在超参数空间中计算数值梯度。这种方法的一个挑战是，与模型训练的一次迭代不同，每次超参数的评估都非常昂贵和耗时，这使得尝试多种超参数组合变得不可行。

现在假设我们知道：$$f(x,y)=g(x)+h(y)≈g(x)$$
在这种情况下，网格搜索仍然是一个好的策略吗？函数 $f$ 主要依赖于 $x$。因此，网格搜索策略会浪费大量迭代来测试 $y$ 的不同值。  

如果我们对 $(x, y)$ 的评估次数有限，更好的策略是在一定范围内随机采样 $x$ 和 $y$，这样每个样本都会测试每个超参数的不同值。  

随机搜索如何改进网格搜索超参数的示例。“*网格搜索的这种失败在高维超参数优化中是常态* 而非例外。”（Bergstra & Bengio, 2011）
[![|500](https://aman.ai/primers/ai/assets/hyperparam-tuning-and-tensorboard/random-grid.png)](http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf)
随机搜索的弱点和假设是什么？随机搜索假设超参数之间没有相关性。理想情况下，我们会从一个考虑到这种关系的联合分布中采样超参数。

此外，它不会利用之前迭代的结果来指导我们如何为未来的迭代选择参数值。这就是贝叶斯优化背后的动机。

### 贝叶斯优化

贝叶斯推断是一种统计推断形式，在进行估计时利用贝叶斯定理纳入先验知识。贝叶斯定理是一个简单却极其强大的公式，用于关联随机变量的条件分布和联合分布。设 $M$ 为表示我们模型质量的随机变量，$θ$ 表示我们超参数的随机变量。那么贝叶斯规则将分布 $P(θ∣M)$（后验）、$P(M∣θ)$（似然）、$P(θ)$（先验）和 $P(M)$（边际）关联起来，如下所示：$$P(\theta | M) = \frac{P(M|\theta)P(\theta)}{P(M)}$$
那么下一个问题是：我们如何利用贝叶斯规则来改进随机搜索？

通过对超参数施加先验分布，我们可以将先验知识融入优化器中。通过从后验分布而非均匀分布中采样，我们可以利用先前样本的结果来改进搜索过程。

让我们重新考虑寻找函数 $f(x,y)$ 最大值的优化问题。贝叶斯优化策略将会：

1. 对参数 $x$ 和 $y$ 初始化一个先验；
2. 采样一个点 $(x,y)$ 来对 $f$ 进行求值。
3. 利用 $f(x,y)$ 的结果来更新关于 $x,y$ 的后验分布。
4. 重复 2 和 3.

目标是猜测函数，即使我们无法知道其真实形式。通过在每次迭代中添加一个新的数据点，算法可以更准确地猜测函数，并更智能地选择下一个要评估的点以改进其猜测。高斯过程用于从其输入和输出的样本中推断函数。它还根据观察到的数据提供了对可能函数的分布。

让我们考虑一个例子：假设我们想要找到某个表达式未知的函数的最小值。该函数有一个输入和一个输出，我们已经采集了四个不同的样本（蓝色点）。


    
- A Gaussian process distribution, given four sampled data points in blue:

[![](https://aman.ai/primers/ai/assets/hyperparam-tuning-and-tensorboard/bayes.png)](https://www.quora.com/How-does-Bayesian-optimization-work)

- The Gaussian process provides a distribution of continuous functions that fit these points, which is represented in green. The darker the shade, the more likely the true function is within that region. The green line is the mean guess of the “true” function, and each band of green is a half standard deviation of the Gaussian process distribution.
- Now, given this useful guess, what point should we evaluate next? We have two possible options:
    - **Exploitation:** Evaluate a point that, based on our current model of likely functions, will yield a low output value. For instance, 1.0 could be an option in the above graph.
    - **Exploration:** Get a datapoint on an area we’re most unsure about. In the graph above, we could focus on the zone between 0.65 and 0.75, rather than between 0.15 and 0.25, since we have a pretty good idea as to what’s going on in the latter zone. That way, we will will be able to reduce the variance of future guesses.
- Balancing these two is the **exploration-exploitation** trade-off. We choose between the two strategies using an acquisition function.
- With each iteration ‘the algorithm balances its needs of exploration and exploitation’ (Nogueira):

[![](https://aman.ai/primers/ai/assets/hyperparam-tuning-and-tensorboard/bayesopt.gif)](https://github.com/fmfn/BayesianOptimization)

- If you’re interested in learning more or trying out the optimizer, here is a good [Python code base](https://github.com/fmfn/BayesianOptimization) for using Bayesian Optimization with Gaussian processes.

## References

- [Structuring Machine Learning Projects on Coursera](https://www.coursera.org/learn/machine-learning-projects)
- [CS230 code examples](https://github.com/cs230-stanford/cs230-code-examples)

## Citation

If you found our work useful, please cite it as:

![](https://aman.ai/images/copy.png)

`@article{Chadha2020DistilledHyperparameterTuning,   title   = {Hyperparameter Tuning},   author  = {Chadha, Aman},   journal = {Distilled AI},   year    = {2020},   note    = {\url{https://aman.ai}} }`

-  [](https://github.com/amanchadha)|  [](https://citations.amanchadha.com/)|  [](https://twitter.com/i_amanchadha)|  [](mailto:hi@aman.ai)| 

[www.amanchadha.com](https://www.amanchadha.com/)