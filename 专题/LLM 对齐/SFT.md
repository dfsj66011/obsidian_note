
> https://huggingface.co/learn/llm-course/chapter11/1?fw=pt



æ¨¡å‹å¯ä»¥é’ˆå¯¹ç‰¹å®šä»»åŠ¡ï¼ˆå¦‚æ‘˜è¦å’Œé—®ç­”ï¼‰è¿›è¡Œå¾®è°ƒï¼Œä½†æ›´å¸¸è§çš„æ˜¯åœ¨å¹¿æ³›çš„ä»»åŠ¡ä¸ŠåŒæ—¶å¾®è°ƒè¯­è¨€æ¨¡å‹ï¼Œè¿™ç§æ–¹æ³•è¢«ç§°ä¸ºç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ã€‚è¿™ä¸€è¿‡ç¨‹å¸®åŠ©æ¨¡å‹å˜å¾—æ›´åŠ å¤šæ‰å¤šè‰ºï¼Œèƒ½å¤Ÿå¤„ç†å¤šæ ·åŒ–çš„ç”¨ä¾‹ï¼Œå¹¶ä½¿å…¶æ›´åŠ æœ‰ç”¨å¹¶ç¬¦åˆäººç±»åå¥½ã€‚

## ä¸€ã€èŠå¤©æ¨¡æ¿

èŠå¤©æ¨¡æ¿å¯¹äºæ„å»ºè¯­è¨€æ¨¡å‹ä¸ç”¨æˆ·ä¹‹é—´çš„äº¤äº’ç»“æ„è‡³å…³é‡è¦ã€‚æ— è®ºæ˜¯æ„å»ºç®€å•çš„èŠå¤©æœºå™¨äººè¿˜æ˜¯å¤æ‚çš„ AI ä»£ç†ï¼Œç†è§£å¦‚ä½•æ­£ç¡®æ ¼å¼åŒ–å¯¹è¯å†…å®¹å¯¹äºä»æ¨¡å‹è·å¾—æœ€ä½³ç»“æœéƒ½è‡³å…³é‡è¦ã€‚èŠå¤©æ¨¡æ¿å¯¹äºä»¥ä¸‹æ–¹é¢è‡³å…³é‡è¦ï¼š

- ä¿æŒä¸€è‡´çš„å¯¹è¯ç»“æ„
- ç¡®ä¿æ­£ç¡®çš„è§’è‰²è¯†åˆ«
- ç®¡ç†å¤šè½®å¯¹è¯çš„ä¸Šä¸‹æ–‡
- æ”¯æŒå·¥å…·ä½¿ç”¨ç­‰é«˜çº§åŠŸèƒ½  

### 1.1 æ¨¡å‹ç±»å‹ä¸æ¨¡æ¿

#### 1.1.1 åŸºç¡€æ¨¡å‹ vs æŒ‡ä»¤æ¨¡å‹

åŸºç¡€æ¨¡å‹é€šè¿‡åŸå§‹æ–‡æœ¬æ•°æ®è®­ç»ƒæ¥é¢„æµ‹ä¸‹ä¸€ä¸ª tokenï¼Œè€ŒæŒ‡ä»¤æ¨¡å‹åˆ™ä¸“é—¨é’ˆå¯¹éµå¾ªæŒ‡ä»¤å’Œè¿›è¡Œå¯¹è¯è¿›è¡Œäº†å¾®è°ƒã€‚ä¾‹å¦‚ï¼Œ`SmolLM2-135M` æ˜¯åŸºç¡€æ¨¡å‹ï¼Œè€Œ `SmolLM2-135M-Instruct` æ˜¯å…¶æŒ‡ä»¤è°ƒä¼˜ç‰ˆæœ¬ã€‚

æŒ‡ä»¤è°ƒä¼˜æ¨¡å‹ç»è¿‡è®­ç»ƒéµå¾ªç‰¹å®šçš„å¯¹è¯ç»“æ„ï¼Œä½¿å…¶æ›´é€‚åˆèŠå¤©æœºå™¨äººåº”ç”¨ã€‚æ­¤å¤–ï¼ŒæŒ‡ä»¤æ¨¡å‹å¯ä»¥å¤„ç†å¤æ‚çš„äº¤äº’ï¼ŒåŒ…æ‹¬å·¥å…·ä½¿ç”¨ã€å¤šæ¨¡æ€è¾“å…¥å’Œå‡½æ•°è°ƒç”¨ã€‚

è¦ä½¿åŸºç¡€æ¨¡å‹è¡¨ç°å¾—åƒæŒ‡ä»¤æ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦ä»¥æ¨¡å‹èƒ½å¤Ÿç†è§£çš„ç»Ÿä¸€æ–¹å¼æ ¼å¼åŒ–æç¤ºã€‚è¿™å°±æ˜¯èŠå¤©æ¨¡æ¿çš„ä½œç”¨ã€‚ChatML æ˜¯ä¸€ç§æ¨¡æ¿æ ¼å¼ï¼Œé€šè¿‡æ¸…æ™°çš„è§’è‰²æ ‡è¯†ç¬¦ï¼ˆç³»ç»Ÿã€ç”¨æˆ·ã€åŠ©æ‰‹ï¼‰æ¥æ„å»ºå¯¹è¯ã€‚å‚è€ƒ[è¿™é‡Œ](https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct/blob/e2c3f7557efbdec707ae3a336371d169783f1da1/tokenizer_config.json#L146)
```
"chat_template": "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\nYou are a helpful AI assistant named SmolLM, trained by Hugging Face<|im_end|>\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}"
```

> [!warning]
> ä½¿ç”¨æŒ‡ä»¤æ¨¡å‹æ—¶ï¼ŒåŠ¡å¿…éªŒè¯ä½¿ç”¨çš„æ˜¯æ­£ç¡®çš„èŠå¤©æ¨¡æ¿æ ¼å¼ã€‚ä½¿ç”¨é”™è¯¯çš„æ¨¡æ¿å¯èƒ½å¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸ä½³æˆ–æ„å¤–è¡Œä¸ºã€‚æœ€ç®€ä¾¿çš„éªŒè¯æ–¹æ³•æ˜¯æ£€æŸ¥ Hub ä¸Šçš„æ¨¡å‹åˆ†è¯å™¨é…ç½®ã€‚ä¾‹å¦‚ï¼Œ`SmolLM2-135M-Instruct` æ¨¡å‹ä½¿ç”¨[æ­¤é…ç½®](https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct/blob/e2c3f7557efbdec707ae3a336371d169783f1da1/tokenizer_config.json#L146)ã€‚  

#### 1.1.2 å¸¸è§æ¨¡æ¿æ ¼å¼

è¿™æ˜¯ `SmolLM2` å’Œ `Qwen 2` ç­‰æ¨¡å‹ä½¿ç”¨çš„ ChatML æ¨¡æ¿ï¼š

```sh
<|im_start|>system
You are a helpful assistant.<|im_end|>
<|im_start|>user
Hello!<|im_end|>
<|im_start|>assistant
Hi! How can I help you today?<|im_end|>
<|im_start|>user
What's the weather?<|im_start|>assistant
```

è¿™æ˜¯ä½¿ç”¨ `mistral` æ¨¡æ¿æ ¼å¼çš„ç¤ºä¾‹ï¼š

```sh
<s>[INST] You are a helpful assistant. [/INST]
Hi! How can I help you today?</s>
[INST] Hello! [/INST]
```

è¿™äº›æ ¼å¼ä¹‹é—´çš„ä¸»è¦åŒºåˆ«åŒ…æ‹¬ï¼š

1. â€‹**ç³»ç»Ÿæ¶ˆæ¯å¤„ç†**â€‹ï¼š
    - Llama 2 ç”¨ `<<SYS>>` æ ‡ç­¾åŒ…è£¹ç³»ç»Ÿæ¶ˆæ¯
    - Llama 3 ä½¿ç”¨ `<|system|>` æ ‡ç­¾å’Œ `</s>` ç»“å°¾
    - Mistral åœ¨ç¬¬ä¸€æ¡æŒ‡ä»¤ä¸­åŒ…å«ç³»ç»Ÿæ¶ˆæ¯
    - Qwen ä½¿ç”¨æ˜ç¡®çš„ `system` è§’è‰²å’Œ `<|im_start|>` æ ‡ç­¾
    - ChatGPT ä½¿ç”¨ `SYSTEM:` å‰ç¼€
2. â€‹**æ¶ˆæ¯è¾¹ç•Œ**â€‹ï¼š
    - Llama 2 ä½¿ç”¨ `[INST]` å’Œ `[/INST]` æ ‡ç­¾
    - Llama 3 ä½¿ç”¨è§’è‰²ç‰¹å®šæ ‡ç­¾ï¼ˆ`<|system|>`ã€`<|user|>`ã€`<|assistant|>`ï¼‰å’Œ`</s>`ç»“å°¾
    - Mistral ä½¿ç”¨ `[INST]` å’Œ `[/INST]` ä¸ `<s>` å’Œ `</s>`
    - Qwen ä½¿ç”¨è§’è‰²ç‰¹å®šçš„å¼€å§‹/ç»“æŸæ ‡è®°
3. â€‹**ç‰¹æ®Šæ ‡è®°**â€‹ï¼š
    - Llama 2 ä½¿ç”¨ `<s>` å’Œ `</s>` ä½œä¸ºå¯¹è¯è¾¹ç•Œ
    - Llama 3 ä½¿ç”¨ `</s>` ç»“æŸæ¯æ¡æ¶ˆæ¯
    - Mistral ä½¿ç”¨ `<s>` å’Œ `</s>` ä½œä¸ºè½®æ¬¡è¾¹ç•Œ
    - Qwen ä½¿ç”¨è§’è‰²ç‰¹å®šçš„å¼€å§‹/ç»“æŸæ ‡è®°

ç†è§£è¿™äº›å·®å¼‚æ˜¯ä½¿ç”¨å„ç§æ¨¡å‹çš„å…³é”®ã€‚transformers åº“ä¼šå¸®åŠ©æˆ‘ä»¬è‡ªåŠ¨å¤„ç†è¿™äº›å˜åŒ–ï¼š

```python
from transformers import AutoTokenizer

# è¿™äº›ä¼šè‡ªåŠ¨ä½¿ç”¨ä¸åŒçš„æ¨¡æ¿
mistral_tokenizer = AutoTokenizer.from_pretrained("mistralai/Mistral-7B-Instruct-v0.1")
qwen_tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen-7B-Chat")
smol_tokenizer = AutoTokenizer.from_pretrained("HuggingFaceTB/SmolLM2-135M-Instruct")

messages = [
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚"},
    {"role": "user", "content": "ä½ å¥½ï¼"},
]

# æ¯ä¸ªéƒ½ä¼šæ ¹æ®å…¶æ¨¡å‹çš„æ¨¡æ¿æ ¼å¼åŒ–
mistral_chat = mistral_tokenizer.apply_chat_template(messages, tokenize=False)
qwen_chat = qwen_tokenizer.apply_chat_template(messages, tokenize=False)
smol_chat = smol_tokenizer.apply_chat_template(messages, tokenize=False)
```

#### 1.1.3 é«˜çº§åŠŸèƒ½

èŠå¤©æ¨¡æ¿å¯ä»¥å¤„ç†æ¯”ç®€å•å¯¹è¯äº¤äº’æ›´å¤æ‚çš„åœºæ™¯ï¼ŒåŒ…æ‹¬ï¼š

1. â€‹**å·¥å…·ä½¿ç”¨**â€‹ï¼šå½“æ¨¡å‹éœ€è¦ä¸å¤–éƒ¨å·¥å…·æˆ– API äº¤äº’æ—¶
2. â€‹**å¤šæ¨¡æ€è¾“å…¥**â€‹ï¼šç”¨äºå¤„ç†å›¾åƒã€éŸ³é¢‘æˆ–å…¶ä»–åª’ä½“ç±»å‹
3. â€‹**å‡½æ•°è°ƒç”¨**â€‹ï¼šç”¨äºç»“æ„åŒ–å‡½æ•°æ‰§è¡Œ
4. â€‹**å¤šè½®ä¸Šä¸‹æ–‡**â€‹ï¼šç”¨äºç»´æŠ¤å¯¹è¯å†å²



å¯¹äºå¤šæ¨¡æ€å¯¹è¯ï¼ŒèŠå¤©æ¨¡æ¿å¯ä»¥åŒ…å«å›¾åƒå¼•ç”¨æˆ– base64 ç¼–ç çš„å›¾åƒï¼š

```python
messages = [
    {
        "role": "system",
        "content": "You are a helpful vision assistant that can analyze images.",
    },
    {
        "role": "user",
        "content": [
            {"type": "text", "text": "What's in this image?"},
            {"type": "image", "image_url": "https://example.com/image.jpg"},
        ],
    },
]
```

è¿™æ˜¯ä¸€ä¸ªå¸¦æœ‰å·¥å…·ä½¿ç”¨çš„èŠå¤©æ¨¡æ¿ç¤ºä¾‹ï¼š

```python
messages = [
    {
        "role": "system",
        "content": "You are an AI assistant that can use tools. Available tools: calculator, weather_api",
    },
    {"role": "user", "content": "What's 123 * 456 and is it raining in Paris?"},
    {
        "role": "assistant",
        "content": "Let me help you with that.",
        "tool_calls": [
            {
                "tool": "calculator",
                "parameters": {"operation": "multiply", "x": 123, "y": 456},
            },
            {"tool": "weather_api", "parameters": {"city": "Paris", "country": "France"}},
        ],
    },
    {"role": "tool", "tool_name": "calculator", "content": "56088"},
    {
        "role": "tool",
        "tool_name": "weather_api",
        "content": "{'condition': 'rain', 'temperature': 15}",
    },
]
```

### 1.2 æœ€ä½³å®è·µ

#### 1.2.1 é€šç”¨æŒ‡å—

ä½¿ç”¨èŠå¤©æ¨¡æ¿æ—¶ï¼Œéµå¾ªä»¥ä¸‹å…³é”®å®è·µï¼š

1. â€‹**ä¸€è‡´çš„æ ¼å¼åŒ–**â€‹ï¼šåœ¨æ•´ä¸ªåº”ç”¨ç¨‹åºä¸­ä½¿ç”¨ç›¸åŒçš„æ¨¡æ¿æ ¼å¼
2. â€‹**æ¸…æ™°çš„è§’è‰²å®šä¹‰**â€‹ï¼šä¸ºæ¯æ¡æ¶ˆæ¯æ˜ç¡®æŒ‡å®šè§’è‰²ï¼ˆç³»ç»Ÿã€ç”¨æˆ·ã€åŠ©æ‰‹ã€å·¥å…·ï¼‰
3. â€‹**ä¸Šä¸‹æ–‡ç®¡ç†**â€‹ï¼šç»´æŠ¤å¯¹è¯å†å²æ—¶æ³¨æ„ token é™åˆ¶
4. â€‹**é”™è¯¯å¤„ç†**â€‹ï¼šä¸ºå·¥å…·è°ƒç”¨å’Œå¤šæ¨¡æ€è¾“å…¥åŒ…å«é€‚å½“çš„é”™è¯¯å¤„ç†
5. â€‹**éªŒè¯**â€‹ï¼šåœ¨å‘é€åˆ°æ¨¡å‹ä¹‹å‰éªŒè¯æ¶ˆæ¯ç»“æ„

> [!tip]
> éœ€è¦é¿å…çš„å¸¸è§é™·é˜±ï¼š
> 
> - åœ¨åŒä¸€åº”ç”¨ç¨‹åºä¸­æ··åˆä¸åŒçš„æ¨¡æ¿æ ¼å¼
> - å› é•¿å¯¹è¯å†å²è€Œè¶…å‡ºæ ‡è®°é™åˆ¶
> - æœªæ­£ç¡®è½¬ä¹‰æ¶ˆæ¯ä¸­çš„ç‰¹æ®Šå­—ç¬¦
> - å¿˜è®°éªŒè¯è¾“å…¥æ¶ˆæ¯ç»“æ„
> - å¿½ç•¥æ¨¡å‹ç‰¹å®šçš„æ¨¡æ¿è¦æ±‚  
> 

### 1.3 å®è·µç»ƒä¹ 

è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªçœŸå®ç¤ºä¾‹æ¥å®è·µå®ç°èŠå¤©æ¨¡æ¿ã€‚æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å°† `HuggingFaceTB/smoltalk` æ•°æ®é›†è½¬æ¢ä¸º chatml æ ¼å¼ï¼š

```python
from datasets import load_dataset

dataset = load_dataset("HuggingFaceTB/smoltalk")
```

2. åˆ›å»ºå¤„ç†å‡½æ•°ï¼š

python

å¤åˆ¶

```python
def convert_to_chatml(example):
    return {
        "messages": [
            {"role": "user", "content": example["input"]},
            {"role": "assistant", "content": example["output"]},
        ]
    }
```

3. ä½¿ç”¨æ‰€é€‰æ¨¡å‹çš„åˆ†è¯å™¨åº”ç”¨èŠå¤©æ¨¡æ¿

è®°å¾—éªŒè¯æ‚¨çš„è¾“å‡ºæ ¼å¼æ˜¯å¦ç¬¦åˆç›®æ ‡æ¨¡å‹çš„è¦æ±‚ï¼  
</æç¤º>

## é™„åŠ èµ„æº

- Hugging Face èŠå¤©æ¨¡æ¿æŒ‡å—
- Transformers æ–‡æ¡£
- èŠå¤©æ¨¡æ¿ç¤ºä¾‹ä»“åº“




## 1ï¸âƒ£ èŠå¤©æ¨¡æ¿

èŠå¤©æ¨¡æ¿ç”¨äºç»“æ„åŒ–ç”¨æˆ·å’ŒAIæ¨¡å‹ä¹‹é—´çš„äº¤äº’ï¼Œç¡®ä¿å“åº”çš„ä¸€è‡´æ€§å’Œä¸Šä¸‹æ–‡çš„é€‚å½“æ€§ã€‚å®ƒä»¬åŒ…æ‹¬ç³»ç»Ÿæç¤ºå’ŒåŸºäºè§’è‰²çš„æ¶ˆæ¯ç­‰ç»„ä»¶ã€‚

## 2ï¸âƒ£ ç›‘ç£å¾®è°ƒ

ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æ˜¯å°†é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹é€‚åº”ç‰¹å®šä»»åŠ¡çš„å…³é”®è¿‡ç¨‹ã€‚å®ƒæ¶‰åŠåœ¨å¸¦æ ‡æ³¨çš„ä»»åŠ¡ç‰¹å®šæ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ã€‚æœ‰å…³SFTçš„è¯¦ç»†æŒ‡å—ï¼ŒåŒ…æ‹¬å…³é”®æ­¥éª¤å’Œæœ€ä½³å®è·µï¼Œè¯·å‚é˜…[TRLæ–‡æ¡£ä¸­çš„ç›‘ç£å¾®è°ƒéƒ¨åˆ†](https://huggingface.co/docs/trl/en/sft_trainer)ã€‚

## 3ï¸âƒ£ ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰

ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰æ˜¯ä¸€ç§é€šè¿‡å‘æ¨¡å‹å±‚æ·»åŠ ä½ç§©çŸ©é˜µæ¥å¾®è°ƒè¯­è¨€æ¨¡å‹çš„æŠ€æœ¯ã€‚è¿™å…è®¸åœ¨ä¿ç•™æ¨¡å‹é¢„è®­ç»ƒçŸ¥è¯†çš„åŒæ—¶è¿›è¡Œé«˜æ•ˆå¾®è°ƒã€‚LoRAçš„ä¸€ä¸ªä¸»è¦ä¼˜ç‚¹æ˜¯æ˜¾è‘—çš„å†…å­˜èŠ‚çœï¼Œä½¿å¾—åœ¨èµ„æºæœ‰é™çš„ç¡¬ä»¶ä¸Šå¾®è°ƒå¤§å‹æ¨¡å‹æˆä¸ºå¯èƒ½ã€‚

## 4ï¸âƒ£ è¯„ä¼°

è¯„ä¼°æ˜¯å¾®è°ƒè¿‡ç¨‹ä¸­è‡³å…³é‡è¦çš„ä¸€æ­¥ã€‚å®ƒå…è®¸æˆ‘ä»¬æµ‹é‡æ¨¡å‹åœ¨ä»»åŠ¡ç‰¹å®šæ•°æ®é›†ä¸Šçš„æ€§èƒ½ã€‚

<æç¤º>
âš ï¸ ä¸ºäº†åˆ©ç”¨æ¨¡å‹ä¸­å¿ƒå’ŒğŸ¤— Transformersæä¾›çš„æ‰€æœ‰åŠŸèƒ½ï¼Œæˆ‘ä»¬å»ºè®®<a href="https://huggingface.co/join">åˆ›å»ºä¸€ä¸ªè´¦æˆ·</a>ã€‚
</æç¤º>

## 



In [Chapter 2 Section 2](/course/chapter2/2), we saw that generative language models can be fine-tuned on specific tasks like summarization and question answering. However, nowadays it is far more common to fine-tune language models on a broad range of tasks simultaneously; a method known as supervised fine-tuning (SFT). This process helps models become more versatile and capable of handling diverse use cases. Most LLMs that people interact with on platforms like ChatGPT have undergone SFT to make them more helpful and aligned with human preferences. We will separate this chapter into four sections:

## 1ï¸âƒ£ Chat Templates

Chat templates structure interactions between users and AI models, ensuring consistent and contextually appropriate responses. They include components like system prompts and role-based messages.

## 2ï¸âƒ£ Supervised Fine-Tuning

Supervised Fine-Tuning (SFT) is a critical process for adapting pre-trained language models to specific tasks. It involves training the model on a task-specific dataset with labeled examples. For a detailed guide on SFT, including key steps and best practices, see [the supervised fine-tuning section of the TRL documentation](https://huggingface.co/docs/trl/en/sft_trainer).

## 3ï¸âƒ£ Low Rank Adaptation (LoRA)

Low Rank Adaptation (LoRA) is a technique for fine-tuning language models by adding low-rank matrices to the model's layers. This allows for efficient fine-tuning while preserving the model's pre-trained knowledge. One of the key benefits of LoRA is the significant memory savings it offers, making it possible to fine-tune large models on hardware with limited resources.

## 4ï¸âƒ£ Evaluation

Evaluation is a crucial step in the fine-tuning process. It allows us to measure the performance of the model on a task-specific dataset.

<Tip>
âš ï¸ In order to benefit from all features available with the Model Hub and ğŸ¤— Transformers, we recommend <a href="https://huggingface.co/join">creating an account</a>.
</Tip>

## References

- [Transformers documentation on chat templates](https://huggingface.co/docs/transformers/main/en/chat_templating)
- [Script for Supervised Fine-Tuning in TRL](https://github.com/huggingface/trl/blob/main/trl/scripts/sft.py)
- [`SFTTrainer` in TRL](https://huggingface.co/docs/trl/main/en/sft_trainer)
- [Direct Preference Optimization Paper](https://arxiv.org/abs/2305.18290)
- [Supervised Fine-Tuning with TRL](https://huggingface.co/docs/trl/sft_trainer)
- [How to fine-tune Google Gemma with ChatML and Hugging Face TRL](https://github.com/huggingface/alignment-handbook)  
- [Fine-tuning LLM to Generate Persian Product Catalogs in JSON Format](https://huggingface.co/learn/cookbook/en/fine_tuning_llm_to_generate_persian_product_catalogs_in_json_format)



å‚è€ƒèµ„æ–™

- [Transformerså…³äºèŠå¤©æ¨¡æ¿çš„æ–‡æ¡£](https://huggingface.co/docs/transformers/main/en/chat_templating)
- [TRLä¸­çš„ç›‘ç£å¾®è°ƒè„šæœ¬](https://github.com/huggingface/trl/blob/main/trl/scripts/sft.py)
- [TRLä¸­çš„`SFTTrainer`](https://huggingface.co/docs/trl/main/en/sft_trainer)
- [ç›´æ¥åå¥½ä¼˜åŒ–è®ºæ–‡](https://arxiv.org/abs/2305.18290)
- [ä½¿ç”¨TRLè¿›è¡Œç›‘ç£å¾®è°ƒ](https://huggingface.co/docs/trl/sft_trainer)
- [å¦‚ä½•ä½¿ç”¨ChatMLå’ŒHugging Face TRLå¾®è°ƒGoogle Gemma](https://github.com/huggingface/alignment-handbook)
- [å¾®è°ƒLLMä»¥ç”ŸæˆJSONæ ¼å¼çš„æ³¢æ–¯äº§å“ç›®å½•](https://huggingface.co/learn/cookbook/en/fine_tuning_llm_to_generate_persian_product_catalogs_in_json_forma)

