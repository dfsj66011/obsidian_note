
本模块将指导你完成指令微调语言模型的操作。指令微调是指通过在特定任务的专用数据集上对预训练模型进行进一步训练，使其适应特定任务的过程。这一过程有助于模型提升在目标任务上的表现。

在本模块中，我们将探讨两个主题：*1）* 聊天模板；*2）* 有监督微调。

* 聊天模板：聊天模板构建了用户与 AI 模型之间的交互结构，确保响应的一致性和上下文相关性。它们包括系统提示和基于角色的消息等组件。
* SFT：监督微调（SFT）是将预训练语言模型适配到特定任务的关键过程。它涉及在带有标记示例的特定任务数据集上对模型进行训练。

## 一、聊天模板

聊天模板对于构建语言模型与用户之间的交互至关重要。它们为对话提供了统一的格式，确保模型理解每条消息的上下文和角色，同时保持适当的回应模式。

### 1.1 基础模型与指令模型

基础模型在原始文本数据上进行训练以预测下一个标记，而指令模型则经过微调专门用于遵循指令并进行对话。例如，`SmolLM2-135M` 是一个基础模型，而 `SmolLM2-135M-Instruct` 是其指令微调变体。

要让基础模型表现出指令模型的特性，我们需要以一种模型能够理解的连贯方式来格式化提示词。这时就需要用到聊天模板。ChatML 就是这样一个模板格式，它通过明确的角色标识（系统、用户、助手）来构建对话结构。

需要注意的是，基础模型可以在不同的聊天模板上进行微调，因此当我们使用指令模型时，需要确保使用了正确的聊天模板。

### 1.2 理解聊天模板

从根本上说，聊天模板定义了与语言模型交流时对话应采用的格式。它们以模型能够理解的结构化格式，包含系统级指令、用户消息和助手回复。这种结构有助于在不同交互中保持一致性，并确保模型能对不同类型的输入做出恰当回应。以下是一个聊天模板的示例。

```sh
<|im_start|>user
Hi there!<|im_end|>
<|im_start|>assistant
Nice to meet you!<|im_end|>
<|im_start|>user
Can I ask a question?<|im_end|>
<|im_start|>assistant
```

`transformers` 库将根据模型的分词器为你处理聊天模板。我们所要做的就是以正确的方式组织我们的消息，其余的事情将由分词器来处理。以下是一个基本对话示例：

```python
messages = [
    {"role": "system", "content": "You are a helpful assistant focused on technical topics."},
    {"role": "user", "content": "Can you explain what a chat template is?"},
    {"role": "assistant", "content": "A chat template structures conversations between users and AI models..."}
]
```

让我们分解上面的例子，看看它是如何映射到聊天模板格式的。

### 1.3 系统消息

系统消息为模型的行为方式奠定了基础。它们作为持久性指令，影响着后续的所有交互。例如：

```python
system_message = {
    "role": "system",
    "content": "You are a professional customer service agent. Always be polite, clear, and helpful."
}
```

### 1.4 会话

聊天模板通过对话历史记录来维持上下文，存储用户与助手之间的先前交流内容。这使得多轮对话更加连贯。

```python
conversation = [
    {"role": "user", "content": "I need help with my order"},
    {"role": "assistant", "content": "I'd be happy to help. Could you provide your order number?"},
    {"role": "user", "content": "It's ORDER-123"},
]
```

### 1.5 使用 Transformer 的实现

Transformers 库内置了对聊天模板的支持。以下是使用方法：

```python
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("HuggingFaceTB/SmolLM2-135M-Instruct")

messages = [
    {"role": "system", "content": "You are a helpful coding assistant."},
    {"role": "user", "content": "Write a Python function to sort a list"},
]

# Apply the chat template
formatted_chat = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True
)
"""
<|im_start|>system
You are a helpful coding assistant.<|im_end|>
<|im_start|>user
Write a Python function to sort a list<|im_end|>
<|im_start|>assistant
"""
```

### 1.6 自定义格式

你可以自定义不同消息类型的格式。例如，为不同角色添加特殊标记或进行格式设置。

```python
template = """
<|system|>{system_message}
<|user|>{user_message}
<|assistant|>{assistant_message}
""".lstrip()

formatted_text = template.format(
    system_message="你是一个AI助手",
    user_message="你好！",
    assistant_message="你好，有什么可以帮您？"
)
```

### 1.7 多轮支持

模板可以在保持上下文的同时处理复杂的多轮对话。

```python
messages = [
    {"role": "system", "content": "You are a math tutor."},
    {"role": "user", "content": "What is calculus?"},
    {"role": "assistant", "content": "Calculus is a branch of mathematics..."},
    {"role": "user", "content": "Can you give me an example?"},
]
```


### 参考资料

- [Hugging Face Chat Templating Guide](https://huggingface.co/docs/transformers/main/en/chat_templating)
- [Transformers Documentation](https://huggingface.co/docs/transformers)
- [Chat Templates Examples Repository](https://github.com/chujiezheng/chat_templates) 









## Exercise Notebooks

| Title                  | Description                                                                          | Exercise                                                                                                                                        | Link                                                 | Colab                                                                                                                                                                                                                                                          |
| ---------------------- | ------------------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Chat Templates         | Learn how to use chat templates with SmolLM2 and process datasets into chatml format | 🐢 Convert the `HuggingFaceTB/smoltalk` dataset into chatml format <br> 🐕 Convert the `openai/gsm8k` dataset into chatml format                | [Notebook](./notebooks/chat_templates_example.ipynb) | <a target="_blank" href="https://colab.research.google.com/github/huggingface/smol-course/blob/main/1_instruction_tuning/notebooks/chat_templates_example.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> |
| Supervised Fine-Tuning | Learn how to fine-tune SmolLM2 using the SFTTrainer                                  | 🐢 Use the `HuggingFaceTB/smoltalk` dataset<br>🐕 Try out the `bigcode/the-stack-smol` dataset<br>🦁 Select a dataset for a real world use case | [Notebook](./notebooks/sft_finetuning_example.ipynb) | <a target="_blank" href="https://colab.research.google.com/github/huggingface/smol-course/blob/main/1_instruction_tuning/notebooks/sft_finetuning_example.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a> |
|                        |                                                                                      |                                                                                                                                                 |                                                      |                                                                                                                                                                                                                                                                |

## 引用

- [Transformers documentation on chat templates](https://huggingface.co/docs/transformers/main/en/chat_templating)
- [Script for Supervised Fine-Tuning in TRL](https://github.com/huggingface/trl/blob/main/examples/scripts/sft.py)
- [`SFTTrainer` in TRL](https://huggingface.co/docs/trl/main/en/sft_trainer)
- [Direct Preference Optimization Paper](https://arxiv.org/abs/2305.18290)
- [Supervised Fine-Tuning with TRL](https://huggingface.co/docs/trl/main/en/tutorials/supervised_finetuning)
- [How to fine-tune Google Gemma with ChatML and Hugging Face TRL](https://www.philschmid.de/fine-tune-google-gemma)
- [Fine-tuning LLM to Generate Persian Product Catalogs in JSON Format](https://huggingface.co/learn/cookbook/en/fine_tuning_llm_to_generate_persian_product_catalogs_in_json_format)

