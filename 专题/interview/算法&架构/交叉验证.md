
交叉验证涉及将数据集划分为多个子集，并多次训练模型。每次使用不同的子集作为验证集，其余部分作为训练集。这有助于更好地评估模型在未见数据上的性能表现。

当你进行 K-折交叉验证时，你实际上是在测试模型通过部分数据训练后，对未见过数据的预测能力。我们之所以采用交叉验证，是因为如果使用全部数据进行训练，就没有剩余数据可用于测试。这在手头数据有限的情况下尤为关键。

此外，我们可以用 80% 的数据进行训练，20% 的数据进行测试。但如果你恰好选取的那 20% 测试数据中包含了一堆特别容易（或特别难）预测的点呢？这样我们就无法对模型的学习和预测能力做出最佳评估。不过，通过随机抽样可以在一定程度上缓解这个问题。

我们理想情况下希望利用所有数据。继续以上述 80/20 分割为例，我们将进行 5 折交叉验证：在 80% 的数据上训练模型 5 次，并在 20% 的数据上进行测试。我们确保每个数据点最终都会出现在 20% 的测试集中恰好一次。这样一来，我们就利用了所有数据点来帮助我们理解模型在从某些数据中学习并预测新数据时的表现如何。

交叉验证的目的并不是为了得出我们的最终模型。我们不会使用上述例子中训练出的 5 个模型实例来进行任何实际的预测。为此，我们希望利用所有可用数据来构建最佳模型。交叉验证的目的是模型检验，而非模型构建。

现在，假设我们有两个模型，比如一个线性回归模型和一个神经网络。我们如何判断哪个模型更好呢？我们可以进行 K-折交叉验证，看看哪个模型在预测测试集数据点时表现更优。但一旦我们通过交叉验证选出了表现更好的模型，我们就会在所有数据上重新训练该模型（无论是线性回归还是神经网络）。我们不会将交叉验证过程中训练的实际模型实例直接用作最终的预测模型。需要注意的是，有一种称为自助聚合（通常简称为 “bagging”）的技术，在某种程度上确实会使用类似于交叉验证方式产生的模型实例来构建集成模型。

