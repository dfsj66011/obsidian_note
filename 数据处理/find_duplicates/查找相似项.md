
> [Finding Similar Items](http://infolab.stanford.edu/~ullman/mmds/ch3a.pdf)

一个基本的数据挖掘问题是检查数据中的“相似”项。我们将在 3.1 节讨论应用，但一个例子是查看一组网页并找到近似重复的页面。例如，这些页面可能是抄袭的，或者它们可能是镜像页面，内容几乎相同，但在关于主机和其他镜像的信息上有所不同。

我们首先将相似性问题表述为寻找具有相对较大交集的集合的问题。我们展示了如何通过一种称为“指纹”的技术，将查找文本相似文档的问题转化为这样的集合问题。然后，我们介绍了一种称为 “minhashing” 的技术，该技术以这样一种方式压缩大型集合，即我们仍然可以从它们的压缩版本中推断出底层集合的相似性。在第 3.9 节中介绍了当所需相似度非常高时适用的其他技术。

当我们搜索任何类型的相似物品时出现的另一个重要问题是，即使计算任意一对物品的相似度变得非常容易，也可能有太多物品对需要测试每对物品的相似度。这一担忧促使了一种称为“局部敏感哈希”的技术的发展，该技术专注于最有可能相似的物品对。最后，我们探讨了无法用集合交集来表达的“相似性”概念。这项研究引导我们考虑任意空间中的距离度量理论。它还激发了一个适用于其他“相似性”定义的局部敏感哈希通用框架。

### 3.1 近邻搜索的应用

我们最初将重点关注一种特定的“相似性”概念：通过观察集合交集的相对大小来判断集合的相似性。这种相似性概念被称为“杰卡德相似性”（Jaccard similarity），将在第 3.1.1 节中介绍。然后，我们将探讨寻找相似集合的一些应用。这些应用包括查找文本相似的文档以及通过寻找相似的客户和相似的产品进行协同过滤。为了将文档文本相似性问题转化为集合交集问题，我们使用一种称为“词袋”（shingling）的技术，该技术将在第 3.2 节中介绍。

#### 3.1.1 集合的 Jaccard 相似度

Jaccard 相似度是集合 $S$ 和 $T$ 的交集大小与并集大小的比值，表示为：$$\text{SIM}(S, T) = \frac{|S \cap T|}{|S \cup T|}$$**示例 3.1：** 图 3.1 中展示了两个集合 $S$ 和 $T$。它们的交集中有三个元素，而出现在 $S$ 或 $T$ 或两者中的元素总共有八个。因此，$\text{SIM}(S, T) = \frac{3}{8}$。

![[Pasted image 20250506214359.png|300]]
**图 3.1：** 两个集合的 Jaccard 相似度为 $3/8$

#### 3.1.2 文档相似性

Jaccard 相似性能有效解决的一类重要问题是在大型语料库（如网络或新闻文章集合）中找出文本相似的文档。我们应该明白，这里所指的相似性是字符层面的相似性，而非“语义相似”，后者需要我们分析文档中的词汇及其用法。语义相似问题也很有趣，但需要通过其他技术来解决，我们在 1.3.1 节中有所提及。不过，文本相似性也有重要的应用场景。其中很多涉及查找重复或近似重复的内容。首先，我们注意到检测两个文档是否完全相同很容易；只需逐个字符进行比较，如果发现任何不同之处，则它们不相同。然而，在许多应用中，文档并非完全一致，但它们却共享了大量文本内容。以下是一些例子：


**剽窃**   检测剽窃文档考验我们发现文本相似性的能力。剽窃者可能只提取文档的某些部分供自己使用。他可能会改动一些词语，也可能改变原文中句子的顺序。然而，最终形成的文档仍可能包含原文档 50% 甚至更多的内容。仅仅通过逐字逐句比较文档的简单方法，是无法检测出这种精心策划的剽窃行为的。

**镜像页面**   为了分担流量负载，重要或热门网站通常会在多个主机上进行复制。这些镜像网站的页面会非常相似，但极少完全相同。例如，它们可能各自包含与特定主机相关的信息，并且可能都包含指向其他镜像网站的链接，但不会指向自身。与此相关的一种现象是从一个课程中借用页面到另一个课程。这些页面可能包括课堂笔记、作业和讲义幻灯片。相似的页面可能会更改课程名称、年份，并每年进行少量修改。能够检测出这类相似页面非常重要，因为搜索引擎如果在搜索结果的第一页避免显示几乎相同的两个页面，就能提供更好的搜索结果。

**来自同一来源的文章**   一名记者撰写的新闻文章通常会被分发，比如通过美联社，发送到许多报纸，然后这些报纸会在其网站上发布该文章。每家报纸会对文章进行一定程度的修改。他们可能会删减段落，甚至添加自己的内容。他们很可能会在文章周围加上自己的标志、广告以及指向其网站其他文章的链接。然而，每家报纸页面的核心内容仍然是原始文章。像谷歌新闻这样的新闻聚合器会尝试找到该文章的所有版本，以便只展示其中一个，而这项任务需要找出两个网页在文本上相似但不完全相同的情况。

#### 3.1.3 将协同过滤视为相似集合问题

另一类集合相似性非常重要的应用被称为协同过滤，这是一个过程，我们通过该过程向用户推荐那些被其他表现出相似品味的用户所喜欢的物品。我们将在第 9.3 节详细探讨协同过滤，但现在让我们来看一些常见的例子。

**在线购物**   亚马逊网站拥有数百万客户，销售数百万种商品。其数据库记录了哪些客户购买了哪些商品。如果两个客户的已购商品集合具有较高的 Jaccard 相似度，我们可以说这两个客户是相似的。同样地，如果两个商品的购买者集合具有较高的 Jaccard 相似度，这两个商品也会被认为是相似的。需要注意的是，虽然我们可能预期镜像网站的 Jaccard 相似度超过 90%，但任何两个客户的 Jaccard 相似度达到如此之高是不太可能的（除非他们只购买了一件商品）。即使像 20% 这样的 Jaccard 相似度也可能足够不寻常，足以识别出具有相似品味的客户。对于商品来说也是如此；Jaccard 相似度不必非常高才具有意义。

协同过滤需要多种工具，除了寻找相似的客户或商品（正如我们在第 9 章中讨论的那样）。例如，两个喜欢科幻小说的亚马逊客户可能各自购买了许多科幻书籍，但这些书籍中只有少数是相同的。然而，通过将相似性查找与聚类（第 7 章）相结合，我们可能会发现科幻书籍彼此之间具有相似性，并将它们归为一组。然后，我们可以通过询问他们是否在许多相同组别中进行了购买，来获得更强大的客户相似性概念。



主要利用的是 shingling-minhash-LSH 技术：

* shingling：将文本拆解为拆解为长度为 K 的字符串集合
* minhash：文本签名，能够表示集合并反映其相似性的较短长度的整数向量
* LSH：局部敏感哈希的目的是生成测试候选对



### 二、Shingling

#### 2.1 k-shingles

Shingling 是将文档表示为集合的一种方式，k-Shingles 就是将文本拆分为长度为 $k$ 的字符串子集，例如，假设我们的文本 $D$ 的内容为 ”abcdabd“，则当 $k=2$ 时，拆解的全部子集为 $\{ab, bc, cd, da, bd\}$，其中 ab 在文本 $D$ 中出现了两次，但是在 shingling 集合中只保留一次（另一个版本采用的 bag，而不是 set 则支持重复项）。这里的小字符串就称为 ”shingle“。

另外关于空白符的处理也有很多种选择，例如 $k=9$，有两个句子分别为：“The plane was ready for touch down” 和 “The quarterback scored a touchdown”。当考虑空格时，第一个句子有 ”tourch dow“ 和 ”ourch down“，第二个句子有 ”tourchdown“，当忽略空格时，两个句子都有 ”tourchdown“均。

#### 2.2 k 的选择

如果 k 选择的比较小，则任意文本相似性很高，例如极限情况下，$k=1$，且只考虑字母+空格情况，则几乎任意文档都是有 27 个元素（26个字母+1个空格）组成，相似度为 1；所以**K 应该足够大，以至于任意给定的 shingle 出现在任意给定的文档中的概率都很低。**

例如当 $k=5$，$27^5=14,348,907$，对于短文本，字符长度远远小于 1.4 亿的长度，因此通常选择 k=5 就挺好，不过实际上文本中的字符可能不止 27 个，同时每个字母出现的概率也不一样，大致可以按 $20^k$ 计算，对于很大的文本，可以考虑用 $k=9$.

#### 2.3 Hashing Shingles

假设 $k=9$，则一个 shingles 长度为 9，则需要 9 个字节空间存储，如果将其 hash 到 0 到 $2^{32}-1$ 范围内，则可以用 4 个字节（32位）的长度表示，可以节省空间。需要注意的是，如果我们使用 9-shingle 并将它们散列到 4 个字节，那么我们可以更好地区分文档，而不是使用 4-shingle，即使用于表示 shingle 的空间是相同的。

### 三、MinHash 过程

#### 3.1 minhash

shingle 集合非常大，即使我们将其都 hash 到 4 个字节，一篇文档的 shingle 集合所需要的空间仍然大概是原文档所需空间的 4 倍。例如原始文档 $D$ 长度为 $ld$，如果不考虑重复 shingle 出现，则一个文档 D 的 shingles 集合大小为 $ld-k+1$，而每个 shingles 需要 4 个字节存储，$k$ 又远远小于 $ld$，所以需要大致 $4ld$ 空间。

所以我们需要想办法将上述大集合替换为规模小得多的”签名“。但这种签名是有要求的，即通过比较签名之间的相似度就可以估计实际 shingle 集合之间的 Jaccard 相似度。当然，通过签名无法得到原始 shingle 集合之间 Jaccard相似度的精确值，但是估计结果与真实结果相差不大，并且签名集合越大，估计的精度也越高。例如， 50000 字节文档的 shingle 可能会映射为 200000 字节的哈希结果，然后替换成 1000 字节大小的签名集合。基于最终签名集合得到的原始文档 Jaccard 相似度的估计值与真实值的差异也就在几个百分点之内。

首先将一系列集合表示成特征矩阵形式：

![image-20211016145825668](./images/image-20211016145825668.png)

例如这里有 4 个集合，$S_1 = \{a, d\}, S_2 = \{c\}, S_3 = \{b, d, e\},  S_4 = \{a, c, d\}$。

为了对特征矩阵每列所表示的集合进行最小哈希计算，首先选择行的一个排列转换。任意一列的最小哈希值是在排列转换后的行排列次序下第一个列值为 1 的行的行号。例如下图中我们把行的顺序按照 beadc 顺序排列后，得到

![image-20211016150309594](./images/image-20211016150309594.png)

$S_1$ 中第一次出现 1 的位置是 $a$ 行，则 $h(S_1)=a$，同理 $h(S_2) = c, h(S_3) = b,  h(S_4) = a$

#### 3.2 minhash 与 Jaccard 相似度

**两个集合经随机排列转换之后得到的两个最小哈希值相等的概率等于这两个集合的 Jaccard 相似度。**

解释一下，假设只考虑集合 $S_1$ 和 $S_2$ 所对应的列，那么它们所在的行可以按照所有可能的结果分成如下 3 类：

1. 属于 $X$ 类的行，意思是两列的值均为 1;
2. 属于 $Y$ 类的行，意思是其中一列的值为 0, 另一列的值为 1;
3. 属于 $Z$ 类的行，意思两列的值都为 0 。

由于特征矩阵十分稀疏，因此大部分行都属于 $Z$ 类。但我们可以忽略都是 0 的行，实际由 $X$ 和 $Y$ 类行数目的比例决定了 $\text{SIM}(S_1, S_2)$ 及概率 $h(S_1)=h(S_2)$ 的大小。假定 $X$ 类行的数目为 $x$, $Y$ 类的行的数目为 $y$, 则$\text{SIM}(S_1,S_2) =x/(x+y)$。原因是 $S_1 \cap S_2$ 的大小为 $x$，而 $S_1 \cup S_2$ 的大小为 $x+y$。

接下来我们考虑 $h(S_1)=h(S_2)$ 的概率。设想所有行进行随机排列转换，然后我们从上到下进行扫描处理，在碰到 $Y$ 类行之前碰到 $X$ 行的概率是 $x/(x+y)$。但是如果从上往下扫描遇到的除 $Z$ 类行之外的第一行属于 $X$ 类，那么肯定有 $h(S_1)=h(S_2)$ 。另一方面，如果首先碰到的是 $Y$ 类行，而不是 $Z$ 类行，那么值为1 的那个集合的最小哈希值为当前行。但值为 0 的那个集合必将会进一步扫描下去。因此，如果首先碰到 $Y$ 类行，那么此时$h(S_1) \neq h(S_2)$。于是，我们可以得到最终结论，即 $h(S_1)=h(S_2)$ 的概率是 $x/(x+y)$，而这也是两个集合Jaccard 相似度的计算公式。

#### 3.3 minhash 签名

我们可以把上面介绍的过程随机置换行顺序 $n$ 次，$n$ 大概为几百次的规模，则我们会得到 $h_1,h_2,\cdots,h_n$，而对于集合 $S$，我们现在可以表示为 $[h_1(S),h_2(S),\cdots,h_n(S)]$，这样一来，数据规模就小很多了，原来的特征矩阵需要 len(k-shingles) 行，而现在只需要 $n$ 行。$n$ 越大，则结果与原始的 Jaccard 相似度越接近。

**然而这种做法听起来不错，却根本无法实现**，即使对上百万甚至数十亿的行选择一个随机排列转换也极其消耗时间，而对行进行必要的排序则需要花费更多的时间。幸运的是，我们可以通过一个随机哈希函数来模拟随机排列转换的效果，该函数将行号映射到与行数目大致相等数量的桶中。通常而言，一个将整数 $0,1, …, k-1$ 映射到桶号 $0, 1, …, k-1$ 的哈希函数会将某些整数映射到同一个桶中，而有些桶却没有被任何整数所映射到。然而，只要 $k$ 很大且哈希结果冲突不太频繁的话，差异就不是很重要。于是，我们就可以继续假设哈希函数 "h" 将原来的第 $r$ 行放在排列转换后次序中的第 $h(r)$ 个位置上。

因此，我们就可以不对行选择 $n$ 个随机排列转换，取而代之的是随机选择 $n$ 个哈希函数 $h_1, h_2, ···,h_n$ 作用于行。在上述处理基础上，就可以根据每行在哈希之后的位置来构建签名矩阵。令 $\text{SIG}(i, c)$  为签名矩阵中第 $i$ 个哈希函数在第 $c$ 列上的元素。一开始，对于所有的 $i$ 和 $C$, 将 $\text{SIG}(i, c)$ 都初始化为 $\infty$。然后，对行 $r$ 进行如下处理：

1. 计算 $h_1(r), h_i(r), …, h_n(r)$;
2. 对每列 $c$ 进行如下操作：
   1. 如果 $c$ 在第 $r$ 行为 0, 则什么都不做；
   2. 否则，如果 $c$ 在第 $r$ 行为 1 , 那么对于每个 $i=1, 2, …, n$, 将 $\text{SIG}(i, c)$ 置为原来的 $\text{SIG}(i, c)$ 和 $h_(r)$ 之中的较小值。

例如下图中，我们把上面的特征矩阵加上了行号，以及设定两个哈希函数分别是 $h_1(x) = (x+1) \% 5, h_2(x) = (3x+1) \% 5$，这里的 $x$​ 指的是行号。两个哈希函数产生的结果在最后两列。注意到这里的两个简单哈希函数对应真正的行排列转换，当然这里只有当行数目为质数（这里为 5) 时才有会有真正的排列转换。通常来说，哈希结果都会存在冲突，即至少有两行得到的哈希值相等。

![image-20211016155236323](./images/image-20211016155236323.png)

接下来模拟计算签名矩阵的算法。一开始，签名矩阵全都由 $\infty$ 构成：

![image-20211016121822025](./images/image-20211016121822025.png)

首先，考虑第 0 行。此时，不论是 $h_1(0)$ 还是 $h_2(0)$ 的结果值都是 1 。而只有集合 $S_1$ 和 $S_4$ 在第 0 行为 1, 因此签名矩阵中只有这两列的值需要修改。因为 $1 < \infty$， 所以实际上是对 $S_1$ 和 $S_4$ 的对应列值进行修改，所以当前签名矩阵的估计结果为：

接下来，我们看第 2 行。对于该行，只有 $S_3$ 的值为 1 , 此时其哈希值 $h_1(1) = 2,h_2(1) =4$ ，更新后的签名矩阵为：

![image-20211016121933550](./images/image-20211016121933550.png)

再接下来看第 2 行中只有 $S_2$ 和 $S_4$ 对应的列为 1，且其哈希值 $h_1(2)=3, h_2(2)=2$ 。$S_4$ 对应的签名本应修改，但是签名矩阵中对应列值为 [1, 1] 小于相应的哈希值 [3, 2]，因此其签名最后不会修改（其实仔细想想，在此处为什么不修改，是因为这里的 hash 值充当置换后的新行，如果行数较小的行中已经有 1，则置换后行数较大的行中再出现 1 其实也没啥用了）。而 $S_2$ 对应的列中仍然是初始值 $\infty$。我们将它替换为 [3, 2], 得到：

![image-20211016122008417](./images/image-20211016122008417.png)

同理可以继续进行下去，最后得到的签名矩阵为：

![image-20211016122056725](./images/image-20211016122056725.png)

其实如果你真的按照两次哈希后的顺序，真的去排列后重新找第一次出现 1 的行，得到的也是上面的结果。

基于上述签名矩阵，我们可以估计原始集合之间的 Jaccard 相似度。注意到在签名矩阵中 $S_1$ 和 $S_4$ 对应的列向量完全相同，因此我们可以猜测 $\text{SIM}(S_1, S_4)=1.0$。如果回到原始图中, 我们会发现 $S_1$ 和 $S_4$ 的真实 Jaccard 相似度为 2/3 。需要记住的是，签名矩阵中行之间的一致程度只是真实 Jaccard 相似度的一个估计值，因为本例规模太小，所以并不足以说明在大规模数据情况下估计值和真实值相近的规律。

#### 3.4 加速

上面的计算方法虽然从计算结果上看，可以把不可能实现的置换操作以哈希方式给实现了，可以将矩阵从行数非常巨大的特征矩阵变成只有几百行的签名矩阵。然而在这个过程中计算量非常大，因为它需要考虑整个特征矩阵的所有行。

我们重新回到最原始的特征矩阵上

![image-20211016145825668](./images/image-20211016145825668.png)

假设我们目前看到的已经是置换后的，那我们其实在找第一行为 1 的时候就停下了，例如对于 $S_1$ 而言，我们不会再看 bcde 行，对于 $S_2$ 而言，也不会再看 de 行，所以我们的注意力并没有看完所有的特征矩阵的每一行。所以我们由此可以想象出，对于一个非常巨大的特征矩阵，我们可以只看前 $m$ 行（假设一共 $k$ 行），这样一来就可以大大的减少计算量，例如上图，实际上只看前 3 行完全就可以得到正确答案。

但是这样也会引入新的问题，例如上图中，如果我只看前两行，那么 $S_2$ 这一列将看不到 1，怎么办？用 $\infty$ 表示。这样一来，含 $\infty$ 符号，在计算 Jaccard 的时候，就有 3 种情况：

1. 两列都不含 $\infty$，那就正常比较
2. 一列有，另一列没有，那么前者真实出现第一个 1 的行肯定不在前 $m$ 行，即两列 minhash 不等
3. 两列都有 $\infty$，则既不作为等值处理，也不作为不等值处理

第 3 种情况不是很常见，这种影响将在一定程度上降低我们对 Jaccard 距离估计的准确性，但不会太大。由于我们现在能够比检查所有行更快地计算所有列的 minhash 值，因此我们可以节省时间来应用更多的 minhash 函数。我们得到了比原来更好的准确度，而且比以前更快。

#### 3.5 在 Hash 函数基础上加速

实际上是将上面 3.3 中提到的 hash 方法（并不真的进行置换）与 3.4 中提到的只关注前 $m$ 行方法进行结合。虽然这种方式可能产生全是 0 的列，以至于签名矩阵中出现 $\infty$，但只要 $m$ 足够大，这种情况则很少发生，我们依然可以根据签名矩阵很好地评估原始 Jaccard 值。遇到的话，忽略掉该行。

假设 $T$ 是特征矩阵的前 $m$ 行包含的所有元素集合，那么 $S_1$ 在前 $m$ 行的元素集合为 $S_1 \cap T$，同理 $S_2$ 在前 $m$ 行的集合为 $S_2 \cap T$，现在再算 Jaccard，则，计算公式需要修改为：
$$
\text{Jaccard}(S_1, S_2)=\frac{|S_1 \cap S_2 \cap T|}{|(S_1 \cup S_2) \cap T|}
$$
然而，会有一些随机变化，因为根据 $T$，我们可以在矩阵的前 $m$ 行中可能会找到多于或少于 $X$ 类行（两列中均为 1的行）和/或 $Y$ 类行（一列为 1，另一列为 0 的行）。

为了缓解这种变化，我们对每个 minhashing 不使用相同的集合 $T$。相反，我们将特征矩阵划分为 $k/m$ 组。然后，对于每个 hash 函数，我们通过第一个 $m$ 行来计算一个 minhash 值，通过第二个 $m$ 行计算不同的 minhash 值，依此类推。因此，我们从单个 hash 函数和对 $m$ 的所有行的单次传递中获得 $k/m$ 个 minhash值。事实上，如果 $k/m$ 足够大，我们可以单个 hash 函数通过应用于特征矩阵的每个子集上m$ 的每个行获得整个特征矩阵的签名矩阵。

例如下图中，$k=8,m=4$，$\text{SIM}(S_1, S_2) = 1/2, \text{SIM}(S_1, S_3) = 1/5, \text{SIM}(S_2, S_3) = 1/2$（忽略都是 0 的行）。

![image-20211016173238876](./images/image-20211016173238876.png)

如果只看前 4 行，不管用什么 hash 函数，$S_1$ 和 $S_2$ 的 minhash 值将始终不等，因为 $S_1 \cap S_2 \cap T=\emptyset$，然而只看后四行，则相似度为 $2/3$。所以平均起来是 $(0+2/3)/2=1/3$，与真实的 $1/2$ 有误差，不是太大。在真实场景下，$m$ 远大于 4 行，这种误差将趋于 0。

同理比较 $S_1$ 与 $S_3$ 之间，是 $(0+1/3)/2=1/6$，与真实的 $1/5$ 比较接近，而 $S_2$ 与 $S_3$ 之间完全一致。

### 3.4 LSH

#### 3.4.1 面向最小哈希签名的 LSH

虽然 minhash 可以大幅度压缩特征矩阵，但矩阵的列数并没有变化，那么依然解决不了如何在大量文件之间高效的找到最大相似度的文档。下面介绍局部敏感哈希（LSH）。

LSH 的一个一般性做法就是对目标项进行多次哈希处理，使得相似项会比不相似项更可能哈希到同一桶中。然后将至少有一次哈希到同一桶中的文档对看成是候选对，我们只会检查这些候选对之间的相似度。我们希望大部分不相似的文档对将永远不会哈希到相同的桶中，这样就永远不需要检查它们的相似度。那些哈希到同一个桶中的非相似文档对称为伪正例(false positive) , 我们希望它们在所有对中占的比例越低越好。同时，我们也希望大部分真正相似的文档对会至少被一个哈希函数映射到同一桶中。那些没有映射到相同桶中的真正相似的文档对称为伪反例(false negative) , 我们希望它们在所有真正相似文档对中的比例也很小。

如果拥有目标项的最小哈希签名矩阵，那么一个有效的哈希处理方法是将签名矩阵划分成 $b$ 个行条(band), 每个行条由 $r$ 行组成。对每个行条，存在一个哈希函数能够将行条中的每 $r$ 个整数组成的列向釐（行条中的每一列）映射到某个大数目范围的桶中。可以对所有行条使用相同的哈希函数，但是对每个行条我们都使用一个独立的桶数组，因此即使是不同行条中的相同向量列，它们也不会被哈希到同一桶中。

如下图所示：

![image-20211016175800408](./images/image-20211016175800408.png)

包含 12 行的签名矩阵的一部分，有 4 个行条，每个行条 3 行，图中显式可见的行条1 中第 2 列和第 4 列均包含列向量 [0, 2, 1], 因此它们肯定会哈希到行条l 下的相同桶中。因此，不管这两列在其他 3 个行条下的结果如何，它们都是一个相似候选对。图中显式给出的其他列也有可能会哈希到行条 1 下的同一桶中。但是，由于此时两个列向量 [1, 3, 0J 和 [0, 2, 1] 不同，加上哈希的桶数目也不少，因此偶然冲突的预期概率会非常低。通常我们都假设当且仅当两个向量相等时，它们才会哈希到同一桶中。

在行条1 中不相等的两个列仍然还有另外3次机会成为候选对，只要它们在剩余的 3 个行条中有一次相等即可。然而，我们观察到，如果签名矩阵的两列越相似，那么在多个行条中的向量相等的可能性也越大。因此，直观上看，行条化策略能够使得相似列会比不相似列更有可能成为候选对。

#### 3.4.2 行条化策略分析

假定使用 $b$ 个行条，每个行条由 $r$ 行组成，并假定某对具体文档之间的 Jaccard 相似度为 $s$。则文档的最小哈希签名矩阵中某个具体行中的两个签名相等的概率等于 $s$ 。接下来我们可以计算这些文档（或其签名）作为候选对的概率，具体计算过程如下：

1. 在某个具体行条中所有行的两个签名相等的概率是 $s^r$
2. 在某个具体行条中至少有一对签名不相等的概率是 $1-s^r$
3. 在任何行条中的任意一行的签名对都不相等的概率为 $(1-s^r)^b$
4. 签名至少在一个行条中全部相等的概率，也即成为候选对的概率为 $1-(1-s^r)^b$

虽然有可能并不特别明显，但是不论常数 $b$ 和 $r$ 的取值如何，上述形式的概率函数图像大致为下图中的 S-曲线。

![image-20211016180658409](./images/image-20211016180658409.png)



曲线中候选概率 $1/2$ 处对应的相似度就是所谓的阈值。它是 $b$ 和 $r$ 的函数。阈值对应的大概是上升最陡峭的地方，对于较大的 $b$ 和 $r$, 相似度在阈值之上的对很可能成为候选对，而在阈值之下的对则不太可能成为候选对，这正是我们想要的结果。阈值的一个近似估计是 $(1/b)^{l/r}$。例如，如果 $b=16,r=4$, 那么由于 16  的 4 次方根为 2, 阈值的近似值为 1/2 。

考虑 $b=20, r=5$ 的情况，也就是说假定签名的个数为 100, 分成 20 个行条，每个行条包含 5 行。下表给出了函数 $1-(1-s^5)^{20}$ 的部分值。注意到的是，这里的阈值，也就是曲线中部上升处的 $s$ 值，仅仅比 0.5 稍大一点。另外也注意到，该曲线并非从 0 到 1 在阈值处跳跃的最理想步进函数，但是曲线中部的斜率十分显著。例如， $s$ 从 0.4 变到 0.6, 增加的函数值大于 0.6,  因此中间部分的斜率大于 3 。

![image-20211016181251776](./images/image-20211016181251776.png)



又例如， $s=0.8$ 时， $1-(0.8)^5$ 大约为 0.672。如果再求 20 次方得到大约 0.000 35, 用 1 减去该值以后得 0.999 65 。也就是说，如果认为两篇文档的相似度为 80%, 那么在任意行条中， 5 行中签名对全部相等的可能性，即它们会成为候选对的概率只有约 33%。然而，这里有 20 个行条，因此有 20 次机会成为一个候选对。3000 个对中，大致仅有 1 个相似度为 80% 的对不会成为候选对，即成为伪反例。

#### 3.4.3 上述技术综合

本节将给出一个完整的相似项发现方法：首先找出可能的候选对相似文档集合，然后基于该集合发现真正的相似文档。必须强调的是，这种方法可能会产生伪反例，即某些相似文档对由于没有进入候选对所以最终没有被识别出来。同样，该方法也可能会产生伪正例，即在评估了某些候选对后，发现其相似度不足。

1. 选择某个 $k$, 并对每篇文档构建其 k-shingle 集合。将这些 k-shingle 映射成更短的桶编号（后一步可选）。

2. 将文档-shingle 对按照 shingle 排序，构建特征矩阵。
3. 选择最小哈希签名的长度 $n$ 。计算所有文档的最小哈希签名。
4. 选择阈值 $t$ 来定义应该达到的相似程度使之被看做是预期的”相似对“。选择行条数 $b$ 和每个行条中的行数 $r$, 使得 $br=n$, 而阈值 $t$ 近似等于 $(1/b)^{1/r}$。如果避免伪反例的产生很重要，那么选择合适的 $b$ 和 $r$ 以产生小于 $t$ 的阈值。而如果速度相当重要并且希望限制伪正例的数目，那么选择合适的 $b$和 $r$ 来获得更高的阈值。
5. 应用 LSH 技术来构建候选对。
6. 检查每个候选对的签名，确定它们一致性的比例是否大于 $t$。
7.  (该步可选）如果签名足够相似，则直接检查文档本身看它们是否真正相似。不相似的文档有时碰巧会具有相似的签名。

