
此外，我们可以用 80% 的数据进行训练，20% 的数据进行测试。但如果你恰好选中的 20% 测试数据中包含了一堆特别容易（或特别难）预测的点呢？这样我们就无法对模型的学习和预测能力做出最佳评估。不过，通过随机抽样可以在一定程度上缓解这个问题。

我们理想情况下希望利用所有数据。继续以上述 80/20 分割为例，我们会进行 5 折交叉验证：在 80% 的数据上训练模型 5 次，并在 20% 的数据上进行测试。我们确保每个数据点最终都会出现在 20% 的测试集中恰好一次。这样一来，我们就利用了手头的每一个数据点，来帮助我们理解模型在从某些数据中学习并预测新数据时的表现如何。

## 三、最终模型训练

交叉验证的目的并非得出最终模型。我们不会用前文示例中训练的 5 个模型实例进行实际预测。为此，我们需要利用所有可用数据来构建最优模型。交叉验证的核心在于模型验证，而非模型构建。

假设我们现在有两个模型，比如线性回归模型和神经网络。如何判断哪个模型更好呢？我们可以进行 K 折交叉验证，看看哪个模型在预测测试集数据点时表现更优。但一旦通过交叉验证选出了性能更好的模型，我们就会在所有数据上重新训练该模型（无论是线性回归还是神经网络）。我们不会直接使用交叉验证过程中训练出的那些模型实例作为最终的预测模型。需要注意的是，有一种称为自助聚合（通常简称为"装袋法"）的技术，在某种程度上确实会使用类似交叉验证方式产生的模型实例来构建集成模型。

----

# Speculative Decoding（推测性解码）

[source](https://aman.ai/primers/ai/speculative-decoding/)

## 一、背景

大型语言模型（LLMs），如 GPT-4、Llama 和 T5，在自然语言理解、推理和生成任务中展现出了卓越的能力。这些模型通常采用下一个词元预测范式进行训练——即给定一个词元序列，模型被优化以预测下一个词元。尽管这种方法有效，但它存在重大效率问题，特别是在推理过程中。

**为什么推理速度这么慢？**

在自回归大语言模型中，生成 $K$ 个标记的序列需要进行 $K$ 次顺序前向传播。每一步都利用模型的预测来计算下一个输入。这种串行特性成为生成过程中的瓶颈，因为每个标记都依赖于前一个标记，从而无法实现并行化。

内存带宽瓶颈加剧了这一问题：在每个令牌生成步骤中，模型参数都必须从内存加载到加速器。随着模型规模的扩大（例如参数达到数千亿），推理的计算和内存成本也随之增加。

**推测解码的动机：**

为了解决自回归大语言模型中的推理瓶颈，推测式解码应运而生，这类策略旨在不显著改变模型输出分布的情况下加速生成过程。不同于每次仅预测一个标记，这些方法尝试并行猜测多个未来标记并进行高效验证。这一通用理念可通过多种方式实现，以下列举三种最常见的方法：

1. 通过草稿模型进行推测性解码：一个更小、更快的“草稿模型”在主模型之前生成一系列候选标记。然后，完整模型并行验证这些标记，接受正确的预测，仅在检测到不匹配时回退到标准的自回归解码。这种方法在实践中可以实现 2 倍至 6 倍的加速。

2. 基于树的多头验证（Medusa）：不同于使用单独的草稿模型，主模型配备了多个并行的“验证头”，以树状结构生成和检查替代令牌路径。这使得可以同时探索多个候选延续路径，从而减少所需的全前向传播次数。

3. 多令牌预测头（自推测解码）：模型通过额外增加的输出头进行增强，这些输出头经过训练可直接从当前隐藏状态预测多个未来令牌。这些预测在内部进行验证，使模型能够绕过多个顺序步骤，而无需引入外部模型或分支搜索结构。

在这些方法中，核心原则始终如一：在每次前向传播时执行更多推测性工作，然后并行验证正确性，从而缓解逐个生成下一个标记的严格串行特性。

**示例场景：**

假设我们要生成 5 个标记。传统解码方法需要进行 5 次前向传播。而使用推测性解码时，草稿模型可能一次性生成所有 5 个标记。然后目标模型会对这批标记进行验证——根据需要接受或修正。例如，如果有 4 个标记被接受，则仅需 2 次前向传播，从而实现 2.5 倍的加速。

这一优化特别适用于：

* 实时应用（聊天机器人、代码补全）
* 边缘部署场景
* 高负载服务器环境

下图（来源）直观展示了非推测性生成（左）与推测性生成（右）的对比。

## 二、核心技术

推测解码有多种形式，但核心理念是一致的：使用轻量级方法猜测多个标记，然后通过原始（或“目标”）模型进行验证。接下来我们将探讨主要策略、实现模式及其权衡。

### 2.1 通过草稿模型进行推测解码

由Leviathan等人在2023年发表的《通过推测解码实现Transformer快速推理》中提出。

Pipeline 概述：

1. **起草**：使用一个更小（更快）的模型来生成 $γ$ 推测性标记。
2. **验证**：运行大模型对所有标记进行评分，直至 $γ$。
3. **接受度：** 接受与大模型预测结果相匹配的前缀标记。
4. **后备方案**：若令牌出现偏差，则回退至大模型采样进行修正。

论文中的下图展示了无条件语言建模案例中说明的一种技术。每条线代表算法的一次迭代。绿色标记是近似模型（此处为一个在1m1b数据集上训练、具有600万参数、处理8k标记的类GPT Transformer解码器）提出的建议，被目标模型（此处为相同设置下具有9700万参数的类GPT Transformer解码器）接受；而红色和蓝色标记分别是被拒绝的建议及其修正。例如，第一行中目标模型仅运行一次，生成了5个标记。

算法概要（根据 Leviathan 等人简化）：

```python
def speculative_decode(draft_model, target_model, prompt, gamma):
      draft_tokens = draft_model.generate(prompt, max_new_tokens=gamma)
      scores = target_model.score(prompt + draft_tokens)
        
      # accept up to the first mismatch
      n_accept = count_agreement(draft_tokens, scores)
      accepted = draft_tokens[:n_accept]
        
      # complete the next token from the target model
      next_token = target_model.sample(prompt + accepted)
      return accepted + [next_token]
```

**优点：**:

- 无需重新训练即可插入现有模型。
- 无需对大模型进行架构更改。
- 完全保留输出分布。

**挑战**:

- 维护一个独立的草稿模型会增加系统复杂性。
- 草稿模型与目标模型之间的分布不匹配可能会降低接受率。
- 如果两个模型都很大，会带来内存和计算压力。

### 2.2 基于树的多头验证（Medusa）

美杜莎（Medusa）由Cai等人（2024年）在论文《美杜莎：基于多重解码头的简易LLM推理加速框架》中提出，该框架通过采用树状注意力机制，对基础的多头推测解码技术进行了改进。

博客（来源）中的下图展示了Medusa在Vicuna-7b上的性能表现。

**核心功能：**

* 美杜莎头：每个头从最后一个隐藏状态预测未来 $k+1$ 个标记。
* 候选组合：将每个头部的 top-k 输出组合起来，形成推测树。
* 树注意力：一种自定义的注意力掩码确保标记仅关注其路径上的前驱节点。
* 接纳方案：两种选择：
	* 拒绝采样（匹配基础模型）
	* 典型验收（启发式，更快）

**好处：**

- 在质量下降最小的情况下实现更高的加速（生产环境中约 2.3-2.8 倍）。
- 无需重新训练（Medusa-1）或通过联合训练（Medusa-2）即可轻松集成到现有模型中。
- 适用于批量大小为 1，这与实际使用场景（如聊天）相符。

**实现细节：**

pkt=softmax(W2k∗(SiLU(W1k∗ht)+ht))

其中 W1k 初始化为 0，W2k 是基础模型语言模型头部的克隆副本。

### 2.3 多令牌预测头（自推测解码）

由Gloeckle等人（2024年）在《通过多令牌预测实现更好更快的语言模型》中提出。

最近的一个趋势是不使用单独的草稿模型，而是直接在主模型中构建推测能力。这就是多令牌预测头（multi-token prediction heads）的用武之地。

论文中的下图展示了多令牌预测的概览。（上）在训练过程中，模型通过共享主干和4个专用输出头，一次性预测4个未来令牌。在推理阶段，我们仅使用下一个令牌的输出头。可选地，其他三个头可用于加速推理时间。（下）多令牌预测提高了MBPP代码任务中的pass@1性能，且随着模型规模的增大效果尤为显著。误差条表示通过数据集样本的bootstrap计算得出的90%置信区间。

**架构**

- 共享的变压器主干对上下文进行编码。
- 多个解码器头（每个对应一个未来标记）进行独立预测。
- 第一个头部是标准的下一令牌预测器；其他头部预测第二、第三……第n个令牌。

每个头部都通过交叉熵损失在其各自的位置上进行训练：Ln=−ΣtΣni=1logP(xt+i|z1:t)

其中𝑧1:𝑡是共享的潜在上下文，每个𝑃(𝑥𝑡+𝑖)通过其专用头计算得出

**内存优化**

训练过程中不是为所有𝑛个头生成所有logits，而是顺序处理每个头以减少GPU内存占用：

* 计算前向和后向传播（头部1）
* 释放对数概率，移至头部2
* 在共享主干上累积梯度

这将峰值内存从𝑂(𝑛𝑉+𝑑)降低到𝑂(𝑉+𝑑)，且不会影响速度。

**优势**:

* 无需单独的草稿模型。
* 统一架构（更易于部署、量化和训练）。
* 兼容推测解码方法，如块级并行或Medusa。

**缺点**：

* 需要在预训练期间修改模型
* 收益仅在大规模模型（70亿以上）中显现
* 微调这些模型可能需要小心操作以保持对齐性。

## 三、对比分析

在本节中，我们将系统性地比较前文讨论的关键推测式解码策略——基于草稿模型的解码、多令牌预测头以及Medusa方法。我们将从性能表现、集成便捷性、训练需求以及部署复杂度等维度权衡这些策略的优劣。

