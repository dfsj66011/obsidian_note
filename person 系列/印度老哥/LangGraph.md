
## 一、引言

大家好，我叫 Nitesh，欢迎来到我的 YouTube 频道。我非常高兴地宣布，在这个 YouTube 频道上，我们将开启一个新的播放列表，主题是“基于 LangGraph 的 Agentic AI”。

老实说，这个话题很空洞，过去三四个月里我收到了无数相关的消息，都是你们这边发来的。你们一直跟我说："老师，请您做一个关于 LangGraph 的播放列表吧。"其实早在三四个月前，我就决定要好好做一个关于这个主题的播放列表。这几个月我一直在深入研究这个主题，花了很多时间制定课程大纲，然后围绕这个大纲做了大量准备工作来准备内容。在整个过程中，我做了很多文档研究。今天的视频之所以特别，是因为如果你想完整跟随这个播放列表，今天的视频就非常重要。因为在今天的视频里，我要告诉你我的整个思考过程，我会一步一步向你解释这个播放列表的所有内容。

首先是时机问题。我觉得现在正是学习 Agentic AI 的最佳时机。为什么呢？因为现在无论你打开哪个平台——YouTube、Twitter 还 是Instagram，都会不断看到这个术语。全世界都在大力炒作这个概念，而且我认为这种炒作是有道理的。想想看，2022 年 ChatGPT 来了，自从 ChatGPT 出现后，计算机科学中生成式 AI 开启了一条全新的轨迹。现在生成式 AI 工具已经变得如此成熟，借助它们真的可以构建出非常强大的代理。接下来的五年里，这些 AI 代理将在未来创造巨大的价值。因此，全球所有的大领导、大公司的 CEO 以及处于非常有影响力位置的人们都预见到，这是一项可以彻底改变世界的事物。如果你学习如何构建代理应用程序，那么在未来你将处于一个极具价值的位置。所以时机就是现在。

第二个关键点是需求。正如我在视频开头所说，过去三四个月里，我频道上每三个评论中就有一个是：“先生，请放下一切，在 LangGraph 上创建一个播放列表吧。”因为行业内对此讨论非常多。所以从你们那里传来了非常强烈的需求。第二个关键点就是这个。

而第三个关键点是积累。如果你现在看这个频道，我们一直在按顺序覆盖很多内容。我主要努力以非常系统的方式深入覆盖内容，然后继续前进。所以在这个频道上，我们先做了机器学习，然后做了深度学习，接着我们开始了 LangChain 等等。当我们开始生成式 AI 时，我个人觉得我们已经学习了很多，差不多准备好去学习和理解 LangGraph 以及如何构建 AI 代理了。这就是第三个原因。基于这三个原因，我认为我们现在处于一个应该开始这个特定播放列表并学习相关内容的位置。

好了，现在让我们继续讨论我启动这个播放列表背后的愿景是什么？每当你做任何事情时，背后都有一个强烈的愿景。所以我想与大家分享我的愿景，即通过这个播放列表我希望实现什么。如果我要诚实地告诉你，当 LangGraph 进入市场，并逐渐从你们的网站收到消息说“先生，请教授 LangGraph”时，我做的第一件事就是上 YouTube 搜索，看看目前有哪些关于 LangGraph 的现有内容。

我注意到 YouTube 上有两种类型的内容。第一种是直接使用 LangGraph 教授如何创建项目的内容，这是一种类型。然后还有第二种类型的内容，教授的是 LangGraph 非常基础的基本原理。在这两种内容中，我发现了一个缺陷：在教授如何创建项目的地方，没有讨论基本原理；而在专注于基本原理的地方，视频非常简短，很快就结束了。简而言之，我在 YouTube 上没有找到任何全面的播放列表。没有看到任何关于 LangGraph 的内容，如果有人从开始到结束完成它，那么通过 LangGraph 的帮助，他就能获得完整的端到端知识。于是，我决定创建一个包含大约 30、40、50 个视频的播放列表，并以这样的方式制作这个播放列表：如果有人从头到尾观看它，那么他将学会如何创建代理应用程序，并且完全掌握 LangGraph。

所以，我对于这个播放列表有三个明确的目标：我的第一个目标是制作一个简单易懂的播放列表。我想让任何人，即使是初学者，也能通过跟随这个播放列表轻松学会创建代理应用程序，并且在创建任何类型的代理时都不会遇到任何困难。其次，我的目标是让你通过这个播放列表以这样的方式掌握 LangGraph 的基础知识，从而对 LangGraph 有很强的掌控力。第三个愿景是，我希望通过这个播放列表给你提供如此深刻的概念性理解，以至于即使明天 LangGraph 被其他新框架取代，你也能凭借这种概念深度轻松掌握那个新框架。那么，这三个就是我希望通过这个播放列表实现的可操作目标。好了，我们已经讨论了为什么要开始这个播放列表，也讨论了关于这个播放列表我的目标和愿景是什么。现在我要告诉你最重要的事情：在这个播放列表中我们将遵循什么样的课程安排。

在开始讨论课程之前，我想先给大家一个免责声明：我即将介绍的课程内容并非最终版本。未来可能会出现一些目前尚未纳入课程的新内容，也可能我现在讨论的部分最终不会出现在正式课程中。这背后的原因很简单——AI 技术正在飞速发展，每天都在更新迭代，旧知识不断被取代。因此，我们今天制定的课程大纲，三个月后是否仍然适用尚未可知。这就是我想事先说明的免责声明。这就是为什么我不会告诉你具体的逐项课程安排，而是会告诉你我是如何将整个课程划分为不同的模块的。

好了，让我们从第一个模块开始。第一个模块将围绕 “Agentic AI 的基础” 展开，这将是我们整个播放列表的前 5-6 个视频。在这 5-6 个视频中，我的目标是为你提供一个关于 Agentic AI 及其相关术语的非常深入的概述。我们将在这里讨论什么是 Agentic AI。AI 代理与 Agentic AI 有什么区别，生成式 AI 与 Agentic AI 又有什么区别？除此之外，我们还将讨论 Agentic RAG 是什么，传统 RAG 与 Agentic RAG 有何不同。所有这些内容我们都将在这里进行探讨。我们还将讨论有哪些顶级框架可以帮助您构建 Agentic AI 应用程序。这将是一个包含 5-6 个视频的系列，如果您观看这些视频，您将获得一个非常好的高层次概述，了解我们在这个播放列表中将要涵盖的内容。所以这是一个非常重要的模块。

好的，接下来是模块 2，我们将开始我们的 LangGraph 之旅。在这个特定的模块中，我的目标是教你们 LangGraph 的基础知识，比如 graph 是如何构建的，state 的概念是什么，nodes 是什么，edges 是什么，conditional edges 是什么。我们将通过这些基础概念来学习，并且借助这些概念，我会教你们如何构建一些非常流行的 AI 工作流程。这就是我们模块 2 的计划。

接下来是模块3，我们将学习高级的 LangGraph 概念。如果你掌握了基础知识，并借助这些知识学会创建 AI 工作流程，你就会获得很大的信心。之后，就是深入了解 LangGraph 的合适时机。LangGraph 为你提供了许多概念，借助这些概念，你可以构建行业级的 AI 代理。例如持久性、内存的概念、人在循环中、断点、检查指针、时间旅行的概念，这些都是非常高级的概念。通过在你的 AI 代理中实现这些概念，你可以使它们真正达到行业级水平。所有这些内容我们都会在这个特定的模块中涵盖。

接下来是这个播放列表中最有趣的模块，在那里我们将学习如何创建 AI 代理。到目前为止，我们已经相当详细地介绍了 LangGraph，现在是时候利用这些知识来构建各种不同类型的人工智能代理了。在这个特定的模块中，首先我会给大家讲解关于人工智能代理的理论知识，以及目前行业中流行的设计模式。然后，我们将逐步学习创建不同类型的人工智能代理。我们将从反应代理开始，之后学习创建反思设计模式，接着是一个名为“自我提问求助”的模式，我们将在此基础上展开工作，进行规划。

我们将在此基础上展开工作，完成这些内容后，还将学习构建多智能体系统。这些核心内容会在本系列课程的第四模块中涵盖。当您完成这个模块时，就能掌握创建各类 AI 智能体的技能。之后我们将转向不同方向，学习构建智能 RAG 应用。您之前在 LangChain 中学习过传统 RAG 制作，而智能 RAG 是其进阶版本——我们将 AI 智能体与 RAG 概念相融合。这里涉及多种架构类型，我们将探讨标准RAG、自优化 RAG 等各种不同的 RAG 架构体系。

我们将在这里涵盖这些内容，然后进入播放列表的最后一个模块，在那里我们将学习产品化。到目前为止，我们在播放列表中学到的所有内容都将帮助我们构建一个项目。我们将以这样的方式构建这个项目，以便你可以将其添加到简历中，并在面试中展示给他人。因此，在这里我们将为我们的代理提供用户界面，添加调试支持，增加可观察性，集成 Langsmith，最后我们还将学习如何部署它。所以，整个播放列表中将有 6 个模块。我现在不想与你们详细讨论具体的主题，因为它们一直在变化，但播放列表的大致结构已经在你们的屏幕上显示出来了。

我希望你喜欢这个课程，它组织得非常系统，让你觉得很有逻辑性。如果你有任何反馈，请在评论中告诉我。如果我认为你的反馈非常非常有价值，我会将其整合到这个课程中。好了，现在我们来谈谈先决条件。很多人在开始这个播放列表时都会有疑问，那就是我们是否准备好开始这个播放列表了。如果你想学习、阅读或观看这个播放列表，你应该掌握三件事。首先，你需要懂 Python。这次我不会说“基础 Python 也行”，因为在这个播放列表中，你需要一些中级水平的 Python 知识。我们会涉及一些基础 Python 不涵盖的内容。我们会大量使用面向对象编程（OOP），也就是说 OOP 的原则是必须的。此外，你还会用到 typing 模块、pydantic 等。如果你不具备这些知识，你将无法很好地跟上这个播放列表。这是第一点。

第二点是你需要对大型语言模型（LLMs）有一定的熟悉度。你应该对 LLMs 有一点了解。如果你看过我的 Langchain 播放列表，那么这个问题对你来说就不会是问题。第三点是 Langgraph，它是建立在 Langchain 之上的。所以在这个播放列表中，你会经常看到，每当我们编写任何代码时，都会有一些 Langchain 的依赖。所以如果你一点都没有学过 Langchain，那么这个播放列表对你来说就会很难理解。所以我强烈建议你一定要看一下我的 Langchain 播放列表，里面有大约 18 个视频。

我有一些比较长的视频，但如果你看了它们，这个特定的播放列表会对你很有帮助，好吗？从先决条件的角度来看，你需要掌握这三样东西。现在我想回答一些更重要的问题。第一个问题是很多人经常问的，所以我在这里说一下：这个播放列表里总共有多少个视频？关于这一点，我无法给你确切的数字。下一个问题是上传视频的频率会是怎样的？说实话，我会尽力每周给你带来三个视频，好吗？对我来说，超过三个是不可能的。如果有时候我制作的视频少于三个，那背后一定是有原因的。

因为你知道每个人都有自己的个人生活，其中可能会有各种事情，所以请你稍微理解一下。但我想从我这边给你一个承诺，我会尽量每周上传三个视频，好吗？剩下的计算就交给你了，看看整个播放列表完成需要多长时间。是的，我觉得这两个问题很多人都会问，所以我提前回答一下。除此之外，如果你还有其他问题，可以在评论区提问，我和我的团队会尽力回答。另外，如果你想学习 LangGraph，请关注这个播放列表，我已经向自己承诺要构建它。

在 LangGraph 上创建最佳播放列表，接下来的 3-4 个月里，我会全力以赴打造这个播放列表，真心希望这个播放列表在未来会受到大家的喜爱。对这个播放列表超级兴奋，希望你们也是！如果你们喜欢这个视频，也喜欢我们将要做的事情，请给这个视频点赞，分享给那些想学习 LangGraph 的朋友们。如果你们还没有订阅这个频道，请务必订阅。下个视频见，拜拜！

## 二、

大家好，我叫 Nitesh，欢迎来到我的 YouTube 频道。今天的视频我们将开启一个新的播放列表，这个列表名为《基于 LangGraph 的 Agentic AI》。如果你看过我的上一个视频，应该记得我在其中介绍了我们将如何规划整个播放列表的内容框架，并讨论了课程大纲以及我对这个系列视频的愿景目标。

现在我们要开始这个列表的第一个视频了，今天的主题是《生成式 AI vs 代理式 AI》。我知道你们现在在想什么——"我们连 Agentic AI 是什么都不知道，怎么能理解它与生成式 AI 的区别呢？"你脑海中浮现的想法是正确的。现在，如果不了解 Agentic AI，你就无法理解这两者之间的区别。当我制定这个课程计划时，原本打算先教你什么是 Agentic AI，然后再教你生成式 AI 与 Agentic AI 的区别。在回顾课程时，我意识到内心的老师告诉我，如果我先向你们解释生成式 AI 与代理式 AI 之间的区别会更有趣。

先了解一下区别，然后在下一个视频中我们将正式涵盖 Agentic AI 的主题，为了解释这两种技术的区别，我做了一个实际的场景来演示，我们讨论生成式 AI 作为一种解决方案，然后使用代理式 AI 改进它，了解一场彻底的进化即将如何发生。

#### 什么是生成式 AI

如果你让我总结一下生成式 AI，我会说生成式 AI 是一项强大的变革性技术，它仅仅在三年前才问世，而在这短短三年间，它已经彻底改变了世界。如今，如果你去接触任何个人并询问他们对生成式 AI 的看法，你会发现他们内心会呈现出两种情绪：一种情绪是这个人可能会对生成式 AI 感到兴奋。因为我们都知道生成式 AI 非常强大，可以做很多事情，但同时个人可能会有点害怕，担心这项技术变得过于强大，以至于抢走我们的工作。

如果我们正式讨论一个定义的话，这里我写了一个定义，让我们来读一下：生成式 AI 指的是一类可以创造新内容的 AI 模型。例如文本、图像、音频、代码或视频等类似人类创造的数据。

这非常美丽地捕捉了生成式 AI 的精髓。简单来说，生成式 AI 是 AI 的一个分支，在这里你构建的模型能够在不同模态中创建新数据。模态指的是基于文本、图像或视频的数据。我们的生成式 AI 模型可以在这些任何模态中创建新数据。而生成式人工智能最棒的部分在于，它新创造的数据感觉完全像是人类创作的一样，对吧？这就是生成式人工智能的定义。

现在，如果我们谈论生成式人工智能的发展历程，它已经存在了大约三年。在这三年中，出现了许多非常成功的生成式人工智能产品。如果我要举一些例子，那么第一个例子肯定是 ChatGPT。ChatGPT 是那个标志着生成式人工智能旅程开始的产品，大约三年前这个聊天机器人进入了我们的生活。我想在当前的趋势下，它已经取代了我们所有人生活中的谷歌，不仅仅是 ChatGPT，除此之外还有很多其他聊天机器人，比如谷歌的 Gemini，或者 Claude，或者 Grok。这些都是非常强大的聊天机器人，它们完全具备像人类一样生成文本的能力。不仅如此，显然它们还很智能。因此，基于 LLM 的应用程序是生成式人工智能的第一个真正例子。


第二个是图像生成模型，基于扩散的模型，比如DALL·E或MidJourney，这些也非常流行。现在的情况是，你只需提供一个简单的文本描述，说明你想要什么样的图像，这些模型就能迅速为你生成完全符合要求的图像。


third example would be code generation LLMs so बहुत सारे large language models इस तरीके से fine tuned होते हैं कि वो software का code लिख सकते हैं जैसे की code lama is one example तो ये भी एक class of softwares है models हैं जो आप jni के अंदर देखते हो fourth is TTS models text to speech models ये ऐसे models होते हैं जहांपर आप एक description देते हो एक text provide करते हो और ये models क्या करते हैं कि उस description को speech में convert करते हैं और वो speech बिलकुल ऐसा सुनाई देता है जैसा कोई real human being जब बोलता है वैसी आवाज आती है right तो इसका बहुत अच्छा example है 11 labs I am pretty sure आपने कहीं न कहीं इसका नाम सुना होगा and lastly video generation models like SORA जहांपर again आप एक textual description दे रहे हो और पलट के वो model आपको एक short video clip बना के दे रहा है right तो ये सारे products हैं ये पिछले 3 सालों में आए हैं और अपने अपने domain में they are quite successful तो ये जो slide आपके screen पे है ये बहुत सही तरीके से आपको ये बताती है कि Gen AI क्या है और Gen AI की पिछले 3 सालों की journey कैसी रही अब Gen AI का true power अगर आपको समझना है तो उसकी लिए हम क्या कर सकते हैं कि हम Gen AI को compare कर सकते हैं with traditional AI systems अब आप सोच रहे होगे कि मैं traditional AI किसको बुला रहा हूँ मैं काफी सालों से AI के domain में काम कर रहा हूँ शायद अब 8-9 साल हो गए तो in my mind जो भी काम हम pre generative AI era में करते थे उसको मैं traditional AI बुला रहा हूँ मेरे कहने का मतलब है कि अगर आपने पास्ट में कभी classical ML के उपर काम किया है या फिर आपने deep learning models बिल्ड किये हैं तो मैं उनको collectively traditional AI बुला रहा हूँ खेक है तो what we will do is to truly understand कि gen AI कितना powerful है या कैसे different है हम इसको compare करेंगे with traditional AI systems जो हम past में build किया करते थे past में कि आपके बास डेटा होता है डेटा में कुछ input होता है कुछ output होता है और आपके जो models होते है traditional AI models उनका काम होता है patterns find out करना या फिर ऐसे बोला जाये input और output के बीच का relationship identify करना so that future में अगर कोई नया input आए तो हम उसके हिसाबसे एक output generate करके दे पाए for example traditional AI में हम classification problems की उपर बहुत काम करते हैं classification problems का example अगर मैं आपको दूँ तो let's say हम एक system मना रहे हैं जिसका काम है कि एक नए incoming mail को देख करके वो बता पाए कि वो mail spam होगा या फिर spam नहीं होगा this is an example of classification problem या फिर one more example could be कि एक patient का x-ray examine करके हम ये बता पाए कि उस patient को cancer है या नहीं है तो इसको हम classification problem बोलते हैं अब traditional AI systems क्या करते हैं इस तरह की problem को solve करने के लिए सबसे पहले डेटा को उठाते हैं डेटा में input भी होता है output भी होता है chest image भी है और बताया भी है कि वो cancer patient है या नहीं हमारा traditional AI model क्या करेगा डेटा को study करेगा, patterns खोजेगा, उस pattern के basis पे input और output के बीच का relationship समझने की कोशिश करेगा और एक बार जब वो relationship समझ जाएगा तो फिर किसी भी नए गिवन input के लिए हमारा model आराम से output update करके दे सकता है similarly अगर you are working on regression problem regression problem is where you don't classify data into one of the categories but instead you predict a continuous output for example based on past data आपको यह बताना है कि आज temperature कैसा रहेगा या फिर based on past data आपको यह बताना है कि किसी given company का stock का price आज कितना रहेगा तो इस तरह की problems के लिए भी जब आप traditional AI models बनाते हो वो बिल्कुल same करीके से काम करता है वो डेटा को देखता है उसमें patterns समझने की कोशिश करता है वो यह निकालने की कोशिश करता है कि input और output के बीच में क्या mathematical relationship है और फिर इस relationship के basis पे जब कोई नया input आता है तो हमारा model एक output predict करके देता है right so this is how traditional AI systems work in comparison to this generative AI fundamentally different है because generative AI क्या करता है कि जब उसको आप डेटा provide करते हो तो वो डेटा में input और output के बीच का relationship खोजने नहीं निकलता instead वो पूरे के पूरे डेटा का distribution समझने की कोशिश करने लगता है distribution समझने का मतलब है डेटा की फितरत समझने का कोशिश करता है या फिर आप ऐसे बोलू कि डेटा का nature समझने की कोशिश करता है for example अगर आपके पास एक gen AI model है और आप उसको धेर सारे cat के images दे दो तो फिर आपका gen AI model क्या करेगा कि वो समझने की कोशिश करेगा कि real life में cat दिखाई कैसे देती है cat का distribution कैसा है और एक बार जब gen AI model आपके डेटा का distribution समझ जाता है जब वो समझ जाएगा कि real world में cat ऐसी दिखाई देती है तो वो बहुत आसानी से उसी distribution के अंदर से एक नया sample generate करके आपको दे सकता है नया sample generate करने का मतलब so that it can generate a new sample from it and I hope इस चीज से आपको समझ में आ रहा होगा कि कैसे on a fundamental level traditional AI systems जो हमने पास्ट में पढ़े उन से different है gen AI and एक दम एक जो single बहुत बड़ी खुबी generative AI की रही है वो ये है कि generative AI इतना refined और इतना perfect output देता है कि उसका output बिलकुल ऐसा feel होता है जैसे किसी human being ने create किया है and because of this fact generative AI आज की date में बहुत सारे domains में apply किया जा रहा है और बहुत अच्छे result हमें देखने को मिल रहे हैं तो अब next हम लोग discuss करेंगे कि what are those areas जहांपर generative AI बहुत commonly apply किया जा रहा है सबसे पहला use case जो है generative AI का वो है creative and business writing जैसे हमने अभी discuss किया कि although generative AI can generate content around a lot of modalities बट जो सबसे पहला use case आया था वो था textual data के उपर जब charge gpt आया था तो it was able to generate text like human तो तब ही से creative and business writing में generative AI tools का बहुत use होने लगा है let's say if you want to write a blog तो आप बहुत आसानी से क्या कर सकते हो कि blog का एक outline define कर सकते हो और chat gpt जैसे tool पे जा करके पूरा का पूरा blog generate करवा सकते हो right या फिर आप किसी को एक business email कर रहे हो ठीक है और आप चाहते हो कि उसमें कोई भी grammatical mistake ना हो और जो tonality हो email का वो भी बहुत formal हो तो आप खुछ से एक mail लिख करके उसको chat gpt पे paste करके उसका एक बहुत formal version create कर सकते हो तो इस तरह के बहुत सारे use cases currently industry में देखने को मिल रहे हैं in fact जो भी popular tools and applications हम email में मैंने देखा है कि आप बहुत आसानी से किसी भी mail का summary पढ़ सकते हो और तुरंथ एक नया reply ड्राफ्ट कर सकते हो तो ये सारी चीज़े आपको already देखने को मिल रही है second जो use case है वो है software development में so past में हम लोग जो भी code लिखते थे हाँच से लिखते थे right और कभी कुछ errors बगर आते थे तो हम manually उसको debug करते थे stack overflow जैसी website पे जा करके अब generative AI के आने के बाद से क्या हो गया है first of all आप पूरा code हाँच से नहीं लिखते so auto completion tool आगे है जो automatically predict कर लेते हैं कि अगर आपने ये piece of code लिखा है तो आप आगे क्या करना चाहते हो और उसके basis पे they can generate the entire code right इसके अलावा अगर आपका code run करने में errors दे रहे हैं तो बहुत आसानी से आप उन errors को chat gpt जैसे tool में डाल करके figure out कर सकते हो कि error क्यूं आ रहा है ठीक है तो software development is one such domain जहांपे gen ai बहुत aggressively use हो रहा है third is customer support दुनिया की हर company को customer support की जरूरत है because आप कोई भी product sell कर रहे हो there is a good chance कि 100 में से 2 customers को कुछ problem हो सकती है तो ये जो customers हैं ये फिर पलट के आपके customer support team को call करते हैं या फिर message करते है अब अगर आप एक ऐसी company हो जिनके पास करोडो users हैं तो उस scale पे हर particular user को एक customer executive assign कर पाना थोड़ा मुश्किल काम है तो इस तरह के scenarios में companies क्या करती हैं कि वो एक chatbot बना लेती है और वो chatbot is basically gen ai chatbot जो based on user query उसको solve करने की कोशिश करता है अगर वो solve कर पाता है तो अच्छी बात है नहीं solve कर पाता है तो फिर वो एक human executive को जो complaint है उसको forward करता है तो आज के date में आप कुई भी बड़ी company उठा लो Uber उठा लो Zomato, Swiggy ये सारी companies जो बहुत बड़े scale पे operate कर रहे हैं इन companies का खुद का chatbot होता है Online education काफी transform हो रहा है अगर आप let's say YouTube पे वीडियो देख रहे हो तो आप किसी Gen AI tools की help से doubts clear कर सकते हो आपको वीडियो में कोई doubt आ रहे है आप वहाँ पे लिख सकते हो कि मुझे इस particular time stamp पे doubt आ रहे है और आपका Gen AI tool can explain की आपको उस doubt को कैसे resolve करना है या फिर आप एक नई technology सीखना चाहते हो तो आप बहुत आसानी से chat GPT पे जा करके अपने हिसाब से personalized एक curriculum बिल्ड करवा सकते हो अगर आपको कोई topic समझ में नहीं आ रहा है तो आप उसको paste करके उसका एक summarized simplified version generate करवा सकते हो तो education में बहुत possibility है in fact पिछले 3 सालों में हम सभी लोगों का सीखने का जो तरीका है वो थोड़ा सा change हुआ है JNI tools की आने की वज़े से lastly designing जैसा कि मैंने बोला apart from text there are other modalities जहांपे JNI can generate content so one of them is images and second is video तो let's say you are a graphics designer और आपका काम है day to day basis पे graphics बनाना let's say आप किसी YouTuber के लिए काम करते हो और आपका काम है thumbnail बनाना तो rather than creating that entire thumbnail by your own अब आप क्या कर सकते हो कि थोड़ा सा एक description provide करके thumbnail AI tools से generate करवा सकते हो और फिर उसको iteratively improve कर सकते हो let's say आप किसी company के लिए social media intern कि तरह काम कर रहे हो और वहाँ पर आपका काम है कि जो भी उनका product है उसके बारे में you have to create beautiful infographics तो ये infographics पहले लोग हाँच से बनाया करते थे as in softwares होते थे उन softwares में manually जाके you have to create these infographics now you can use these tools AI tools and they will generate the infographics for you चीक है या फिर let's say आप किसी advertising firm में काम करते हो और आपका काम है companies के लिए advertisements बनाना अब पहले लोग advertisements बनानी के लिए बहुत महनत करते थे वो shooting वगरा करनी पड़ती थी और पूरा ad edit करना पड़ता था अब आप क्या कर सकते हो कि चोटे चोटे clips video clips generate कर सकते हो using tools like Sora और Runway और फिर उन clips को जोड़ करके आप एक चोटा सा advertisement create कर सकते हो right तो ये कुछ application areas हैं मैंने सारे नहीं लिखे but you can understand कि ये जो quality है that it can mimic human creativity ये एक बहुत powerful attribute है जिसकी वज़े से Gen AI across industries बहुत तेजी से adopt किया जा रहा है and the best part about Gen AI is that Gen AI is constantly evolving and improving आप एक example ले के देखो जब image generation models आए थे तो शुरू में they were really bad अगर आप कोई एक image generate करते थे तो उसके अंदर जो spellings होती थी वो spellings बहुती गलत या उट पटांग सी होती थी but अब आप recent के models में देखोगे तो आपको दिखाई देगा कि अब जो images generate होते हैं उनके अंदर जो text लिखा होता है उसमें spelling mistakes नहीं होती है right तो you can see with this example कि पिछले 3 सालों में ही Gen AI बहुत जदा evolve कर गया है और बहुत जदा improve कर गया है and going forward भी ये बात true रहेगी तो आगे चलके there is a good chance कि आप कोई भी app use कर रहे हो अपनी life में वहाँ पे आपको Gen AI का कोई ना कोई integration देखने को मिलेगा right तो I hope मैं आपको पिछले 10-15 मिनिट में एक quick revision दे पाया कि Gen AI क्या है, Gen AI काम कैसे करता है, traditional AI से कैसे अलग है और what are the application areas जहांपे Gen AI useful है यह सारी चीज़े मैंने आपको quick revision में बता दी now that we have this introduction, अब हम क्या करेंगे कि एक practical scenario लेंगे, एक problem लेंगे और उस problem को solve करेंगे with the help of Gen AI, ठीक है, तो सबसे पहले मैं आपको बताता हूँ कि वो problem है क्या, जो हम solve करने वाले है so imagine करो कि आप किसी company में एक HR recruiter के post पे काम कर रहे हो, ठीक है आपका काम है कि आप जबी भी company को requirement होती है नए लोगों की hiring करते हो ठीक है, और currently आपको एक task दिया गया है कि आपकी company को एक back-end engineer hire करना है, ठीक है तो अब आपको end-to-end ये make sure करना है कि आपकी company को एक अच्छा back-end engineer मिल जाए ठीक है, तो अब अगर इस task को आप break down करो कि आपको एक अच्छा back-end engineer hire करने के लिए क्या-क्या steps execute करने होंगे तो देखते हैं वो steps क्या-क्या है सबसे पहला step यह होगा कि as a HR recruiter आपको एक job description draft करना पड़ेगा आपको एक document बनाना पड़ेगा जहां पे आप बहुत detail में सारा का सारा requirement mention करोगे कि आपको exactly उस back-end engineer से क्या करवाना है और आपको कैसा बनदा चाहिए as in उसके अंदर क्या skill set होनी चाहिए क्या कोई eligibility criteria है, आप कितना salary दोगे और उस employee से आपके क्या expectations रहेंगे तो आपको एक JD सबसे पहले create करनी पड़ेगी task number 2, एक बार जब JD create हो जाती है, तो आपको उसे किसी job platform पे डालना पड़ेगा, जैसे की job.com, एक बार जब JD platform पे चली जाती है उसके बाद आपको जितने भी applications मिलेंगे उन applications में short listing करनी पड़ेगी, let's say आपको 1000 लोगों ने apply किया आपके job के उपर obviously 1000 लोगों का आप interview नहीं ले सकते, तो आप उन में से 10, 20, 25 लोगों को short list करोगे based on their resume, आप हर किसी का resume study करोगे, आप जो भी आपका requirement है, उससे compare करोगे and you will finalize the top 25 candidates जिनका आप interview लोगे, right उसके बाद आता है interview उनका step जहांपे आप उन 25 candidates को interview करोगे to understand कि कौन उन में से best fit है, एक बार जैसे ही आपको कोई पसंद आ जाता है फिर आप क्या करोगे, एक offer letter roll out करोगे उस इंसान के लिए, और finally जब वो accept कर लेगा offer letter, तो आपको उसका पूरा on boarding देखना पड़ेगा, right, तो ये आपका task है right, जो आपको execute करना है, और अब हम क्या करेंगे इस पूरे task को execute करने के process में Gen AI implement करेंगे, हम ये देखेंगे कि इस पूरे task को execute करने में Gen AI अब Gen AI कैसे लगाएंगे हम इस पूरे process में, बहुत simple है, थोड़ी दिर के लिए हम लोग ये imagine कर लेंगे कि हमारी company ने हमें एक chatbot दे रखा है, ठीक है, और वो chatbot is basically a LLM based chatbot, जहांपर मैं जा करके chatting कर सकता हूँ, मुझे जो भी doubts हैं, मैं वो जा करके chatbot से पूछ सकता हूँ, अगर मुझे कोई help चाहिए, तो वो जा करके मैं chatbot से मांग सकता हूँ, it's a simple chatbot जो मेरी company ने मुझे provide कर रखा है, ठीक है, तो अब हम अपना hiring का पूरा process start करते हैं, step number one is कि मुझे एक JD draft करना है, right, तो मैं क्या मैं इस chatbot के पास जाओंगा, और मैं इसको बोलूंगा कि, देखो वाई, I want to hire a backend engineer with a 2 to 4 years of experience, ठीक है, तो chatbot बोलेगा, तो बताओ, फिर मैं आपको कैसे help करूं, तो आप बोलोगे कि मुझे इस particular job के लिए एक JD बना करके दो, तो since it's a LLM based chatbot, वो जट से आपके लिए एक JD जेनेरेट कर देगा, ठीक है, जैसे कि यहाँ पे लिखा हुआ है, we are looking for a remote backend engineer with 2 to 4 years of experience in backend development, बाकि जो भी details आप प्रोवाइड करोगे, वो सारा detail, आपका chatbot यहाँ पे डालता चला जाएगा, salary कितनी है, requirements क्या-क्या है, everything will be placed in this JD, right, तो step 1 complete करने में हमारे chatbot ने हमारी help कर दी, अब move करते हैं अगले step पे, अगला step है कि JD है हमारे पास, उसको हमें किसी job portal पे डालना है, तो मैं जा करके अपने chatbot से पूछूंगा, कि यह JD मैं कहां डाल सकता हूँ, तो chatbot can reply based on its training knowledge कि there are certain platforms जहां पे आपको अच्छा response मिलेगा, for example, try LinkedIn और नौकरी, तो I will say कि ठीक है, चलो, thank you, मैं यह कर लेता हूँ, फिर मैं manually जाओंगा, LinkedIn पे उस JD को post करूँगा, manually जाओंगा, नौकरी.com पे उस JD को paste करूँगा, अब आता है step number 3, step number 3 है shortlisting, कुछ time हो गया, कुछ applications भी आ गए हमारे job portal के उपर, तो अब, मालों हमारे पस 8 applicants ने apply किया, तो now I can go to my chatbot and I can say कि देखो भाई, मुझे 8 applications आए हैं, थोड़ा help कर सकते हूँ, उनको screen करने में, मेरा जो chatbot है, वो JD के basis पे और थोड़ा सा generic advice मुझे दे सकता है, कि आप ऐसे लोगों को hire करो, जिनके पास python और cloud का experience है, और ऐसे लोगों को hire करो, जिनके पास startup में काम करने का experience है, और ऐसे लोगों को hire करो, जिनके पास project को lead करने का experience है, तो वो generic सा मुझे एक advice दे देगा, based on the JD that I have created, तो again I will say कि thank you for the guidance, मैं करता हूँ, और फिर मैं इस पूरे चीज को execute करूँगा, मैं जाके एक-एक resume को देखूँगा, और JD के basis पे, मैं candidates को shortlist करूँगा, अब shortlisting का अगला step है, कि मुझे interview schedule करना है, right, तो बिर से chatbot के पास जाओंगा, और मैं बोलूंगा कि देखो आठ में से दो लोग मुझे पसंद आए हैं, और मुझे इन दो लोग का interview लेना है, can you draft an email, जिस से मैं उन लोगों को interview के लिए invite कर पहूँ, तो again chatbot आपके लिए जट से एक email draft कर देगा, और आप उस email को उठा करके उन दो candidates के पास भेज दोगे, right, scheduling का step भी हो गया, this is a sample email, ठीक है, अब आता है अगला step, जहांपे आपको उन candidates को interview करना है, अब interview करने के लिए आपको obviously उन से questions पूछने पड़ेंगे, तो यहांपे भी आपका chatbot आपको help कर सकता है, आप chatbot के पास जाओगे, और आप बोलोगे कि ये JD देखो, और इसके basis में मुझे बताओ, कि किस तरह के questions पूछे जा सकते हैं, तो again, जो आपका chatbot है, based on its training data, आपको थोड़ा बहुत guidance दे देगा, कि भाई, back-end development में उनका experience के बारे में पूछना, कौन-कौन से framework पर उनने काम किया, उसके बारे में पूछना, problem solving की around आप questions पूछ सकते हो, तो आप जट से बोलोगे कि, आर एक काम करो, आप मुझे जट से question bank generate करके दे दो, तो आपका chatbot आपको जट से back-end का एक question bank generate करके दे देगा, अब आप क्या कर सकते हो, बहुत आसानी से ये exact question, candidate से पूछ सकते हो, right, तो interviewing का step भी हो गया, अब वहाँ पे आपको कोई पसंद आ गया, और अब आपको क्या करना है, उस बन्दे को एक offer देना है, तो फिर से आप chatbot के पास जाओगे, और आप बोलोगे कि देखो, I have finalized one candidate, can you help me draft an offer letter, again आपका chatbot जट से आपके लिए एक offer letter generate करके दे देगा, और आप उस offer letter को उठाओगे, और अपने candidate को mail कर दोगे, right, and that's it, I guess आप देख पारे हो कि कैसे इस पूरे task के हर step में आपका chatbot आपको असिस्ट कर पार है, अगर आप pre-generative AI एरा में जाओ, मालो 2015-2018 की हम बात करें, तो उस time पे यह सारी चीज़े आपको खुझ से करनी पड़ती थी, आपको JD खुझ से बनाना पड़ता था, आपको interview questions खुझ से figure out करने पड़ते थे, जितना भी mail आपको करना है, उसका content आप खुझ से लिखते थे, बट अब इन सारी चीज़ों में, Gen AI गुज़ गिया है, और इन सारी steps को उसने बहुत आसानी से refine कर दिया है, जिससे हमें थोड़ा सा कम काम करना पड़ रहा है, और जो output है, वो थोड़ा और better तरीके से आ रहा है, तो Gen AI is clearly helping us solve this problem, बट क्या ये solution सबसे best solution है, या फिर इस पूरे approach में अभी भी कुछ problems है, the answer is yes, there are certain problems, जिनको हम solve कर सकते हैं, क्या हैं वो problems, one by one discuss करते हैं, सबसे पहली problem ये है, कि ये जो पूरा chatbot और human का interaction हो रहा है, जहांपे human बार बार आके बता रहा है कि अब मुझे ये करना है, और chatbot पलक्ट के उन queries को solve कर रहा है, ये पूरा का पूरा जो process है, ये reactive है, reactive का मतलब क्या है, कि जब मैं chatbot को prompt कर रहा हूँ, तब वो react करके मुझे solution provide कर रहा है, it's not proactive, वो खुद से समझ नहीं पा रहा है, flow क्या होना चाहिए, next क्या करना चाहिए, इतनी समझ नहीं है उस chatbot के अंदर, वो reactive है, तो ये एक problem है, काफी सारा flow मुझे handle करना पड़ रहा है as a human being, और फिर कुछ जगों पे chatbot मुझे help कर रहा है, this is problem number 1, problem number 2 is कि हमारे chatbot के पास अभी कोई memory नहीं है, इसका मतलब वो context aware नहीं है, अगर मैं ने आज उससे jd बनवाया, और 3 दिन बाद आ करके मैं उससे, उस jd कुछ पूछूं, तो उसको याद नहीं रहेगा, मुझे दुबारा से jd का content उसको दिखाना पड़ेगा, right, तो memory का issue है, उसके बाद जो भी

当我规划这个课程大纲时，在这个大纲里首先我...（这是一类软件，模型，你们可以在 JNII 里面看到）。


第四是TTS模型，即文本转语音模型。这些模型的工作原理是，你输入一段描述或文本，模型就会将这些描述转换成语音，而且听起来就像真人说话的声音一样，对吧？一个很好的例子就是11 Labs，我相信你肯定在某个地方听说过这个名字。最后是像Sora这样的视频生成模型，你同样提供一个文本描述，模型就能反过来为你生成一个短视频片段，对吧？

那么所有这些产品都是过去三年里推出的，它们各自在自己的领域都相当成功。那么你屏幕上看到的这张幻灯片，非常准确地告诉你什么是Gen AI，以及Gen AI在过去三年的历程是怎样的？现在如果你想了解Gen AI的真正力量，我们为此能做些什么呢？

我们可以将Gen AI与传统AI系统进行比较，对吧？现在你可能在想，我所说的传统AI指的是什么？我在AI领域已经工作了相当长的时间，大概有8-9年了，所以在我看来，我们在前生成AI时代所做的工作，我称之为传统AI。我的意思是，如果你过去曾经在经典机器学习上工作过，或者你构建过深度学习模型，那么我把它们统称为传统AI。那么我们要做的是，为了真正理解Gen AI有多么强大，或者它有何不同，我们将把它与我们过去构建的传统AI系统进行比较——不，不仅是过去，现在也在构建。

但我们将对这两者进行比较，那么首先来谈谈传统的人工智能系统。在传统人工智能中，你会做什么呢？你拥有数据，数据中有一些输入和一些输出，而你拥有的模型——传统的人工智能模型——它们的任务是找出模式，或者换句话说，识别输入和输出之间的关系。这样，未来如果有新的输入，我们就可以根据它生成一个输出。

例如，在传统人工智能中，我们主要处理分类问题。如果我要给你一个分类问题的例子，比如说我们正在构建一个系统，它的任务是查看一封新收到的邮件，并判断这封邮件是否是垃圾邮件。这就是一个分类问题的例子。或者再举一个例子，通过检查患者的X光片，我们能够判断该患者是否患有癌症，这也被称为分类问题。

现在，传统的AI系统会如何处理这类问题呢？首先，它们会收集数据，数据中既包含输入，也包含输出，比如胸部影像，还会标注患者是否患有癌症。那么，我们的传统AI模型会做什么呢？它会研究数据，寻找模式，并试图基于这些模式理解输入和输出之间的关系。一旦理解了这种关系，模型就能轻松地为任何新的给定输入预测输出。

同样地，如果你在处理回归问题——回归问题是指你不将数据分类到某个类别中——但相反，你预测的是一个连续的输出，例如，基于过去的数据，你需要预测今天的温度会如何，或者基于过去的数据，你需要预测某家给定公司的股票价格今天会是多少。对于这类问题，当你构建传统的AI模型时，它的工作方式完全相同：它会查看数据，尝试理解其中的模式，试图找出输入和输出之间的数学关系，然后基于这种关系，当有新的输入时，我们的模型会预测并给出一个输出。

那么这就是传统人工智能系统的工作原理，相比之下，生成式人工智能从根本上就不同，因为生成式人工智能所做的是，当你给它提供数据时，它不会试图找出输入和输出之间的关系，相反，它会尝试理解整个数据的分布。理解分布意味着尝试理解数据的本质，或者可以说，它试图理解数据的性质。

例如，如果你有一个生成式AI模型，并且你给它大量猫的图片，那么你的生成式AI模型会做什么呢？它会尝试理解现实生活中的猫是什么样子，猫的分布情况如何。一旦生成式AI模型理解了你的数据的分布情况，一旦它理解了现实世界中猫的样子，它就可以很容易地从相同的分布中生成一个新的样本给你。生成新样本的意思就是可以生成一张新的图片，里面有一只猫，明白吗？所以这里写的是，生成式AI就是学习数据的分布。

这样它就能从中生成一个新的样本，我希望你能通过这件事明白，从根本上来说，我们之前学习的传统AI系统与生成式AI是不同的，对吧？而且，生成式AI有一个非常大的优点，那就是它能提供如此精致和完美的输出，以至于它的输出感觉完全像是人类创造的。

由于这一事实，生成式AI在当今的许多领域中得到了应用，并且我们看到了非常好的结果。那么接下来我们将讨论，生成式AI在哪些领域被广泛应用。首先，生成式AI的第一个应用案例是创意和商业写作。

正如我们刚才讨论的那样，虽然生成式人工智能可以生成多种形式的内容，但最先出现的用例是关于文本数据的。当ChatGPT问世时，它能够像人类一样生成文本，因此从那时起，生成式人工智能工具在创意和商业写作中被广泛使用。比如说，如果你想写一篇博客，你可以很容易地做什么呢？你可以定义一个博客的大纲，然后使用像ChatGPT这样的工具，生成完整的博客，对吧？



या फिर...














## 概述

LangChain 是开始使用大型语言模型（LLM）进行开发的最简单方式，只需不到 10 行代码，就能让你开始基于 OpenAI、Anthropic、Google 等平台构建智能代理。

LangChain 代理构建在 LangGraph 之上，旨在提供持久执行、流式处理、人工干预、持久化等功能。对于基本的 LangChain 代理使用，您无需了解 LangGraph。


### 核心优势

* 不同的提供商拥有独特的 API 与模型交互，包括响应格式。LangChain 标准化了您与模型的交互方式，使您能够无缝切换提供商并避免被锁定。
* LangChain 的代理抽象设计得易于上手，让您用大约 10 行代码就能构建一个简单的代理。但它也提供了足够的灵活性，让您随心所欲地进行上下文工程。
* LangChain 的代理构建在 LangGraph 之上，这使我们能够利用 LangGraph 的持久执行、人在环路支持、持久化等功能。
* 通过可视化工具深入洞察复杂代理行为，追踪执行路径、捕捉状态转换并提供详细的运行时指标。



--------

原始 LLMs 应用：

* 需要人类提供大量的指令，被动响应式回答问题
* 没有记忆
* 给出的建议都非常通用，如不能结合公司内部规则给出针对性策略
* 不能做 actions，如发送邮件

RAG 改进：

* 仍然是反应式（Reactive）被动的，仍然缺乏上下文感知能力
* 仍然没有记忆
* 可以给出针对性具体意见（主要改进点）
* 还是不能做动作

工具增强：例如引入一些外部 API 等，可以解析 PDF，可以自动发邮件等

* 聊天机器人仍然是被动的，是我在告诉它该做什么，而不是它在指导我
* 仍然缺乏上下文意识，没有记忆功能
* 可以给出针对性具体意见（RAG 改进）
* 可以执行某些操作（工具增强改进）
* 不能自适应某些特殊情况，如果中间出现任何问题，我们的聊天机器人无法适应

所以简而言之，我们需要以这样的方式改进我们的聊天机器人：

1. 首先，它应该是主动的而不是被动的，意味着它应该采取一些主动行动，
2. 并且具备上下文意识，这意味着它应该记住之前做了什么以及接下来需要做什么。
3. 同时，它还应具备适应性，这意味着当一个行动流程无法正确执行时，它能够选择替代路径。

*AI Agent：具有主动的、具备上下文意识的和适应性的，你只需要告诉它一个最终目标*，比如我需要招聘一个后端工程师。

**生成式 AI 和代理式 AI 的区别：**

1. 任何内容生成式 AI 的最终目标是让你获得一些生成的内容，而代理式 AI 则完全不同。在代理式 AI 中，最终目标是给你一个目标，你必须不惜一切代价实现这个目标。你获得目标，为其制定计划，然后逐步执行这些计划。所以这是最大的区别。

2. 第二个区别是生成式 AI 是被动的，你作为人类在每一步指导生成式 AI 该做什么，而生成式 AI 做出反应；而代理式 AI 是主动的、自主的。一旦你给它设定了一个目标，它就会自动完成所有后续工作。它甚至会将人类纳入循环中，但人类的工作大多围绕审批展开。

3. 第三点也是最重要的一点是，生成式 AI 是代理 AI 的基础构件。代理 AI 是一个更广泛的术语，涵盖了许多正在进行的元素，包括工具的概念、规划和推理等。为了实现这些功能，代理 AI 应运而生。生成式 AI 是一种能力，而代理 AI 是一种行为

----

代理型 AI 是一种能够从用户那里接受任务或目标，然后在最少人为指导下自行完成任务的 AI。它会进行规划、采取行动、适应变化，并且只在必要时寻求帮助。简单来说，代理型 AI 是一种软件范式，在这种范式中，你向系统提供一个目标，然后系统开始自行思考如何实现这个目标，在实现该目标的过程中，所有需要的规划和执行工作都由代理型 AI 系统自动完成。

代理式 AI 系统的特征：

* 自主的；
* 目标导向的；
* 能够进行一些规划；
* 能够进行一些推理；
* 能够自适应；
* 是情境感知的。


任何代理型 AI 系统的核心高级组件：

* 代理型 AI 系统的大脑；（LLMs）
* 编排器（orchestrator）；（决定什么时候、哪个步骤、如何执行等，指的是框架，如 langgraph）
* 工具；
* 记忆；
* 监督者（让你的代理和人类一起工作的组件）

---------

### LangChain vs LangGraph

LangChain 是一个开源库，旨在简化基于 LLM 的应用程序的构建过程。

核心组件：
* model 组件，它提供了一个统一的接口，借助该接口可以与任何 LLM 提供商的 LLM 进行交互。这样就不需要在代码中做太多修改了。
* prompt 组件，通过提示的帮助，可以进行任何类型的提示工程。
* 检索器组件，能帮助从任何向量存储或知识库中获取相关文档。

LangChain 最大的优势、最突出的特点正是它的“链”（chain），LangGraph 是一个编排框架，它利用LLM 提供有状态的、多步骤和事件驱动的工作流程。它非常适合设计单智能体和多智能体的 AI 应用。


现在LLM工作流中可以有很多任务。一个任务可能是调用LLM，第二个任务可能是调用某个工具，第三个任务可能是做决策。所以基本上，Langraph在这里做了什么？它理解了你的工作流，然后将这个工作流转化为一个图的形式。这个图的构建方式是，每个节点都是你整个工作流中的一个子任务。最棒的是，所有这些节点都通过边相互连接，而这些边告诉我们，在执行完一个特定节点或任务后，接下来应该执行哪个任务。简而言之，Lang Graph 正在做什么？它为您提供了一个功能，通过这个功能的帮助，您可以将任何 LLM 工作流以流程图的形式先表示出来，然后再执行。一旦您创建了这个图表，接下来您需要做的就是为第一个节点提供输入，并触发这个工作流或图表。然后，所有节点将按照正确的顺序自动执行，您的工作流就完成了。这里确切地写着：Lang Graph 是一个用于构建智能的编排框架。

stateful and multi-step LLM workflows 好吧，现在Lang Graph不仅仅局限于创建图表，它还为您提供了额外的功能。比如在这里，如果您愿意，可以并行执行任务，正如您在这里看到的，一个节点之后，接下来的两个节点会同时执行。您还可以实现循环的概念，在这个节点之后，您可以回到前面的节点，并且可以在循环中完成这个操作。您还可以进行分支，在这个节点之后，根据某个条件，要么这个节点会执行，要么那个节点会执行。同时，您还可以获得记忆功能，可以记录这里正在执行的所有任务和发生的所有对话。此外，您还可以获得恢复能力的功能，如果将来某个任务中您的整个工作流程中断了，您可以从那个点恢复。因此，结合所有这些核心功能，您可以说...


Language Graph is an ideal candidate for building agentic and production grade AI applications ठीक है? तो यही हमने last वीडियो में discuss किया था अगर आपने last वीडियो नहीं देखा है I would recommend कि आप please एक बार जाके वो वीडियो देखो because वहाँ पे हमने एक real world use case की help से यह समझने की कोशिश कियी थी कि Language Graph की जरूरत क्यूं है और मैंने वहाँ पे आपको 7 core features बताये थे Language Graph के तो वह सब कुछ दुबारा से cover करना possible नहीं है बट अगर आप वीडियो देखोगे तो आपको सब कुछ clear हो जाएगा So now that you know, you understand what Language Graph is अब हम क्या करेंगे कि एक एक करके Language Graph के कुछ core concepts study करेंगे जिनको study करने के बाद आप किसी भी तरह का workflow लिख पाओगे So guys, सबसे पहला जो concept हम discuss करने वाले है वो है LLM workflows का अब थोड़ी दिर पहले मैंने आपको Language Graph को define करने के process में यही बताया था कि Language Graph is an orchestration framework जिसकी help से आप किसी भी तरह का LLM workflow बना लेते हो तो मुझे लगता है एक बाद थोड़ा सा इस particular term के उपर focus करते हैं कि LLM workflows exactly होते क्या है सबसे पहले बात करते हैं workflows की workflow क्या होता है So workflow को आप define कर सकते हो as a series of tasks जो आप execute करते हो in order to achieve a goal For example हमने last video में जो automated hiring वाला example देखा था वहाँ पे हमें एक बंदे को hire करने के लिए कुछ series of steps execute करने थे सबसे बहले JD बनानी थी फिर उसको post करना था फिर shortlisting करना था फिर interview करना था फिर onboarding करनी थी तो जब ये पूरा series of steps आपने execute किया in the right order तब ही जा करके आपका पूरा hiring का workflow execute हुआ right तो simple शब्दों में workflow को आप series of tasks मान सकते हो जिसको सही order में execute करके आप एक goal achieve करते हो यही होता है workflow अब LLM workflow क्या होता है LLM workflow एक ऐसा workflow होता है जहांपे आपके पूरे series of tasks में बहुत सारे tasks ऐसे होते हैं जो LLMs के उपर depend करते हैं जैसे हमारा automated hiring वाला जो example था वो एक LLM workflow था why, because उसमें multiple tasks ऐसे थे जहांपे आपको LLM की ज़रूरत पड़ेगी जैसे कि JD को लिखने के process में आपको LLM की ज़रूरत पड़ेगी हो सकता है short listing करने के process में आपको LLM की ज़रूरत पड़े हो सकता है interviews conduct करने के process में आपको LLMs को use करना पड़े, तो in short कोई भी workflow अगर अपने execution के state में LLMs को use करता है तो फिर हम उसको LLM workflow बुलाते हैं, ठीक है यहाँ पर देखो मैंने चीज़े लिख रखी हैं आप go through कर सकते हो LLM workflows are step by step process using which we can build complex LLM applications each step in a workflow performs a distinct task such as prompting, reasoning tool calling, memory access or decision making, ठीक है और workflows can be linear parallel, branched or looped, allowing for complex behaviors like retries multi-agent communication or tool augmented reasoning ठीक है तो I really hope आपको थोड़ा idea लग गया कि LLM workflows क्या होते हैं अब honestly हर application का अपना खुद का workflow होगा right, आपका automated hiring का अलग workflow होगा call center को automate करने जाओगे उसका अलग workflow होगा, तो workflows हमेशा अलग अलग ही होते हैं but there are certain workflows जो आपको अलग अलग जगहों पे देखने को मिलेंगे which are kind of common workflows तो मैं आपको कुछ common workflows बताता हूँ, जो आपको बहुत जगहों पे देखने को मिलेंगे और इस particular land graph playlist में भी मैं आपको यह common workflows बना के दिखाऊंगा, ठीक है तो स्टार्ट करते हैं पहले common workflows से जो सबसे पहला common LLM workflow है, उसका नाम है prompt chaining, यह LLMs की दुनिया में एक बहुत common workflow है हर जगह आपको देखने को मिलेगा इसमें basically आप क्या करते हो कि आप multiple times सीरीज में LLM से बात करते हो या LLM को call करते हो जैसे कि आपको इस flow diagram में दिख रहे है इस पूरे के पूरे workflow में आप एक बार, दो बार, तीन बार LLM से बात कर रहे हो in sequence इस तरह के workflow का example हो सकता है मानलो आप एक ऐसा application मना रहे हो जहांपे user आपको एक topic का नाम देगा और आपको उस topic के उपर एक report as in detailed report बनानी है अब आप directly topic से detailed report नहीं बनाओगे instead आप क्या करोगे आप इस पूरे task को break down करोगे पहले आप क्या करोगे आप topic से एक outline prepare करोगे और फिर आप outline की help से report prepare करोगे तो अब यहांपे आप क्या कर रहे हो आप एक तरह से prompt chaining कर रहे हो आपका topic आया आप उसको first LLM के पास भेज रहे हो और आप बोल रहे हो outline draw करो जब outline draw हो गई तो फिर उस outline को आप second LLM के पास भेज रहे हो और आप बोल रहे हो कि इस outline के basis फिर एक detailed report print करो तो prompt chaining का concept आप वहाँ use करते हो जहांपे आपके पास complex task होता है और आप उसको sub tasks में divide करना चाहते हो और अच्छी जीज़ क्या है कि इस पूरे process में बीच-बीच में आप checks लगा सकते हो कि आपका जो process है वो सही से काम कर रहा है यह नहीं जैसे यहाँ पे आप देख सकते हो कि इस LLM call के output के उपर हमने एक check लगा दिया ठीक है जैसे हमारे use case में एक check हो सकता है कि हमारा report should not be greater than 5000 words अगर 5000 से जादा words है तो हम exit कर जाएंगे ठीक है तो यह एक बहुत common workflow है जो आपको कई जगों पे देखने को मिलेगा I really hope आपको prompt chaining समझ में आ गई second एक और बहुत famous LLM workflow है जिसको हम routing बुलाते है so routing में क्या होता है कि आप basically एक task को समझते हो और फिर यह decide करते हो कि उस task को कौन execute करेगा ठीक है थोड़ा abstract करीके से मैंने बोला एक example के थूँ मैं आपको समझाता हूँ माललो आप एक customer support के लिए chart board बना रहो तो इसको एक query मिलेगी customer की तरफ से अब query कुछ भी हो सकती है query हो सकती है कुछ technical platform के बारे में या फिर refund से related या फिर sales से related किसी भी तरफ की query हो सकती है तो ये query हमारे LLM के पास आई अब हमारा LLM ये decide करेगा कि ये refund related query है या technical doubt related query है या sales related query है अगर refund related query है तो वो इस particular LLM के पास route कर देगा आपके request को अगर technical doubt है तो second वाले के पास भेज देगा अगर sales related doubt है तो third वाले के पास भेज देगा तो basically ये जो LLM है ये एक decision maker की तरह काम कर रहा है जो ये decide कर रहा है कि इन तीनों में से कौन सा LLM इस query को solve करने के लिए सबसे capable है ठीक है तो in a way this particular LLM call is working as a router ठीक है तो ये भी एक pattern है जो आगे चल के बहुत देखने को मिलेगा अलग अलग workflows जब आप बिल्ड करोगे तो इसमें ये छोटा सा routing pattern आपको use करना पड़ सकता है तो I hope आपको अभी तक के दो LLM workflows समझ में आगे prompt chaining and routing अब बात करते हैं next workflow की next LLM workflow है paralyzation नाम से भी आपको समझ में आगा होगा इस particular workflow में आप क्या करते हो कि आप एक given task को break down कर देते हो into multiple sub tasks और फिर आप उन सारे के सारे sub tasks को एक साथ execute करते हो और उन सब के result को फिर आप merge करके final outcome निकाल के देते हो ठीक है so एक example लेते हैं मालो आप YouTube जैसे platform के लिए एक content moderation workflow बना रहो content moderation workflow का मतलब है कि YouTube पे जैसे ही कोई वीडियो publish होती है तो YouTube पहले उस वीडियो को चेक करता है कि क्या वो वीडियो appropriate है कि उसको लोगों के सामने live किया जाए क्या उसमें कुछ गडबर तो नहीं है तो हम YouTube के लिए वही content moderation platform बना रहे हैं ठीक है तो content moderation के लिए आपको सेम वीडियो को multiple angle से चेक करना पड़ता है जैसे कि आप सबसे पहले चेक करते हो कि क्या वो वीडियो YouTube की community guidelines को follow कर रहा है या नहीं second angle यह हो सकता है कि आप ये क्या उस वीडियो में किसी तरीके का misinformation तो नहीं है और third angle हो सकता है कि आप ये चेक करो कि क्या उस में कुछ sexual content तो नहीं है अगर ये तीनो checks वीडियो पास कर लेगा तब ही हम उस वीडियो को live करेंगे otherwise हम उसको flag कर देंगे ठीक है तो यहाँ पर हमने क्या किया कि अपने content moderation task को तीन sub task में डिवाइड कर दिया हमें ये चेक करना है कि वीडियो live करना चाहिए कि नहीं और ये चेक करने के लिए हमें ये तीन चीज़े चेक करनी है अब मज़े की चीज़ क्या है कि ये तीनो चीज़ो को आपको पहले से पता होना चाहिए कि मिस इंफोरमेशन है या नहीं ये तीनो task पैरलिली किये जा सकते हैं तो इस case में आप क्या करोगे माललो अगर आप ये task खुझ से कर रहे हो तो आप वीडियो का content उठाओगे उसका transcription generate करोगे और उसको first llm के पास अगला आपको पता चेक करेगा कि sexual content है कि नहीं और फिर ये तीनो अपने-अपने result इस aggregator को भेजेंगे और फिर ये aggregator उन तीनो result के basis पे decide करेगा कि वीडियो publish होना चाहिए या फिर नहीं तो ये एक बहुत अच्छा example है और थर्ड वाला LLM sexual content के basis पे judge करेगा तो ये पहले से pre-defined है बट, Orchestrator worker वाले में पहले से पता नहीं होता कि first LLM क्या काम करेगा, second क्या काम करेगा, third क्या काम करेगा for example, आप एक research assistant बना रहे हो जिसका काम होगा कि एक given query के उपर एक detailed research report बनाना ठीक है अब इस research report को बनाने के process में सबसे पहले हमारे system को क्या करना पड़ेगा कि multiple जगहों पे, multiple platforms पे जा करके उस term को search करना पड़ेगा और फिर जितना information आ रहा है उसको aggregate करके एक report generate करनी पड़ेगी बट, search कहां पे करना है और क्या search करना है, ये इस बात पे depend करेगा कि आपकी query क्या है for example, अगर आपकी query कोई scientific term है या फिर कोई technical term है तो ऐसा हो सकता है कि आप अपने first LLM को जा के बोलो google scholar पे जा के search करने जहाँ पे आपको research papers मिलते हैं right, whereas अगर आपका search term कोई social phenomena है या फिर कोई political incident है तो फिर there is a chance कि आप अपने LLM को बोलो कि जा करके google news पे जा के search करो right, तो यहाँ पे क्या हो रहा है कि based on the input query क्या search करना है, कहां search करना है ये बहुत vary कर जा रहा है ये sub task है, ये बहुत vary कर जा रहा है तो ये जो decision making है ये करने के लिए यहाँ पर एक orchestrator बोलके LLM होता है तो ज़ैसे ही search query आती है तो orchestrator उसको analyze करता है और वो decide करता है कि हर जो sub LLMs है मतलब जो उसके अंदर के workers है orchestrator के अंदर के workers है उनको क्या काम मिलेगा so depending on the input query orchestrator हर worker LLM को अलग task assign कर सकता है तो यही सबसे बड़ा difference है यहाँ पे भी चीज़े parallely हो रही हैं end में जाके उनका result aggregate हो रहा है बट पहले से हमें नहीं पता है कि task का nature क्या होगा वो depending on the input query vary कर सकता है तो ये भी एक बहुत important pattern है बहुत important workflow है जो future में आपको देखने को मिलेगा और hopefully इस playlist में हम इसको भी cover करेंगे और जो last common workflow है उसका नाम है evaluator optimizer यह एक बहुत interesting workflow है यहाँ पे क्या होता है कि आपको एक task दिया जाता है और इस task में सबसे बड़ी problem यह होती है कि इस task को एक बार में perfectly execute नहीं किया जा सकता for example आप चाहते हो कि आपका system आपके लिए एक email draft करे but there is a good chance कि first time में आपको आपका perfect email ना मिले या फिर आप चाहते हो कि आपका system आपके लिए एक blog बना के दे किसी topic के उपर कोई guarantee नहीं है कि one go में जब आप अपने LLM को बताओगे कि मुझे इस topic के उपर ब्लॉग चाहिए तो वो आपको best ब्लॉग बना के दे देगा because इस तरह की जो चीज़े हैं जहां पे आप email draft कर रहे हो या blogs लिख रहे हो या poems लिख रहे हो या stories लिख रहे हो ये थोड़ा सा creativity का काम है और इसमें iteration लगता है मतलब खुछ सोचो न कोई जो poet होता है या कोई writer होता है जब वो कुछ लिखता है न तो वो iteration में लिखता है वो पहला draft लिखता है फिर उसमें देखता है कि क्या कमी रह गई फिर उस कमी को feedback बना करके दूसरा draft बनाता है फिर ये process वो loop में करता चला जाता है तो 5-6 steps के बाद उसको final अपना अच्छा product मिलता है तो ये same workflow आप execute कर सकते हो with the help of evaluator optimizer workflow यहाँ पे आपके बास दो LLMs होते हैं एक होता है आपका generator LLM और एक होता है आपका evaluator LLM so आप यहाँ से अपना task बताते हो कि मुझे ब्लॉग लिखना है या email लिखना है तो ये first वाला जो LLM है ये आपको एक ब्लॉग generate करके देगा जिसको हम solution बुलाते हैं अब इस solution को हम evaluator के पास भेजते हैं और evaluator को हम एक concrete evaluation criteria बताते हैं और उस criteria के basis पे वो क्या करता है आपके solution को या तो accept करता है या तो reject करता है अगर reject करता है तो एक feedback भी देता है तो अगर आप reject हो गए और आपको एक feedback मिला तो आपका generator क्या करेगा उस feedback के basis पे फिर से नया solution generate करेगा और ये पूरी चीज लूप में होते जाती है until evaluator satisfy हो जाए उसको लगे कि हाँ भाई अब जो solution आया है ये सही है और वो उसको accept कर ले तो फिर ये loop break हो जाता है और आपको आपका output मिल जाता है तो ये एक बहुत interesting workflow है और जब मैं आपको loops के बारे में पढ़ाओंगा lang graph में उसके ठीक बाद मैं आपको ये particular workflow बना के दिखाओंगा it's very interesting ठीक है तो I hope आपको nutshell में समझ में आगया LLM workflows क्या होते हैं और जो common workflows हैं वो मैंने आपको सारे के सारे बता दिए 5 अलग लग workflows and in this playlist I will try to cover all of these ठीक है अगला core concept जो हम discuss करने जा रहे हैं वो है graphs, nodes और edges का concept and trust me guys ये तीनो मिला करके आप कह सकते हो कि lang graph का सबसे important core concept है ठीक है तो अगर आपको याद होगा वीडियो के शुरुवात में जब मैंने define किया था कि lang graph क्या है तो वहाँ पर मैंने आपको बताया था कि lang graph is an orchestrator framework जो किसी भी LLM workflow को graph के form में represent करता है that is why आपको ये समझना बहुत ज़रूरी है कि कैसे lang graph किसी भी workflow को किसी भी LLM workflow को graphs के form में represent करता है ये पुरीचे समझाने के लिए let's take an example, example बहुत interesting है, so अगर आपको UPSC exam के बारे में पता होगा तो शायद आपको ये भी पता होगा कि UPSC में mains exam के time पे जो candidates होते हैं उनको एक या दो essays लिखने होते हैं और ये essay actually बहुत weightage carry करते हैं उस mains exam में और इसको crack करना बहुत important माना जाता है in order to crack UPSC तो what we are doing is let's say we are building a website जहाँ पे हम जो भी UPSC aspirants हैं उनको ये essay लिखने का practice कर वा रहे हैं ठीक है so we have a website जहाँ पे जैसे ही कोई user आएगा हमारा website उसको एक essay topic generate करके देगा उसके बाद वो बन्दा क्या करेगा उस topic के ओपर essay लिखेगा हमारी website के उपर essay लिखेगा टाइप करके वो अपना essay submit करेगा और हमारी website उस essay को multiple perspective से analyze करेगी evaluate करेगी और एक score generate करेगी अगर score cut off से जादा हुआ तो हम उसको congratulate करेंगे अगर score उसका cut off से कम हुआ तो हम उसको feedback provide करेंगे और फिर हम उसको option देंगे कि feedback के basis पे अगर वो चाहे तो दुबारा से essay लिख सकता है और फिर हम उसको दुबारा evaluate करेंगे यह पूरी चीज बेसिकली हम iteration में perform कर रहे हैं तो माल लो ये LLM workflow आपको बनाना है अब इसमें LLMs की ज़रूरत पड़ेगी multiple जगों पे तो माल लो हमें ये LLM workflow बनाना है तो हम कैसे बना सकते हैं using land graph सबसे पहले तो आपको इस high level goal को कि आपको इस तरह की एक website बनानी है उसको first of all actionable steps में convert करना पड़ेगा actionable steps क्या है step 1 topic generate करना step 2 जो essay उसने लिखा है student ने वो आप collect कर लो तो आपने result को aggregate करना उसके बाद बताना कि उसका result उसका essay अच्छा था या खराब था उसके बाद feedback देना उसके बाद अगर वो चाहे तो दुबारा revised ऐसे लिख सकता है ये पूरा flow हमें सबसे पहले copy pen पर लिखना पड़ेगा एक बार पूरा जब आप लिख लो तो अब आप इस flow को अच्छी लैंग ग्राफ के help से एक ग्राफ के form में represent कर सकते हो ठीक है तो मैं आपको दिखाता हूँ मैंने already ये flow बना रखा है so this is the flow the same flow जो हमने अभी discuss किया but this time it is in the form of a graph ठीक है so you can see टॉपिक generate हो रहा है सबसे पहले उसके बाद user essay लिख रहा है हम उस essay को collect कर रहे हैं और इस step में हम उसको evaluate कर रहे हैं तीन चीजों के basis पे clarity of thought कितना है essay में depth of analysis कितना है fact check वगरा कर रहे हैं और language कैसा है essay का vocabulary कितना strong है grammatical mistakes तो नहीं है tonality कैसा है यह सब पुछ हम चेक कर रहे हैं और तीनों चीजों के basis पे हम उसको normalize score दे रहे हैं पाँच के उपर तो टोटल हम 15 marks पे उसको evaluate कर रहे हैं और मालो threshold हमने रखा है दस number का तो final evaluation यह रहेगा कि अगर आपका score दस से जादा है तो successful हम congratulate करेंगे हमारा तीनों चीजों के basis पे क्या गलती हुई और फिर उसको option देंगे कि तुम दुबारा ऐसे लिखना चाहते हो अगर वो बोलेगा no तो फिर से flow end हो जाएगा अगर वो बोलेगा yes तो हम वापस यहाँ पे आ जाएँगे और यह पूरा flow फिर से execute होगा अब सबसे पहले आप यह देख सकते हो कि इस तरह के किसी भी flow को आप बहुत आसानी से graph के form में represent कर सकते हो this is the first observation that you should have second आप इस graph को अगर देखो तो इस graph में आपको दो चीज़े दिखाई देंगी first दिखाई देगा node as in nodes और second आपको दिखाई देगा edges अब मज़ेदार चीज़ क्या है कि यहाँ पे हर जो node है वो actually आपके workflow का एक single task को represent करता है तो exactly यही कर रहा है जब वो graph बनाता है तो graph बनाने के process में हर node एक single task को represent करता है अब आप सोचोगे कि behind the scenes यह node है क्या तो लैंग ग्राफ में हर node behind the scene एक python function है that's it उससे ज़ाधा कुछ भी नहीं है अगर आपको python function लिखना आता है तो आप यह node भी create कर सकते हो तो essentially अगर आप देखो तो land graph में जो graph बनता है it is essentially a set of python functions जो आपस में interconnected है with the help of edges edges हमें यह बताते है कि किसी particular node के execute होने के ठीक बाद next कौन सा node execute होगा तो in short nodes हमें बता रहे हैं कि करना क्या है और edges हमें बता रहे हैं कब क्या करना है when to execute a node अब edges भी आपके कई तरीके के हो सकते हैं आपके sequential edges हो सकते हैं जहांपे एक के बाद दूसरा आ रहा है आपके parallel edges हो सकते हैं जहांपे एक साथ तीनो चीजे दोनो चीजे जितनी भी हैं execute हो रही हैं आपके पास conditional edges भी हो सकते हैं जहांपे आप branching perform कर रहे हो मतलब या तो इस direction में flow जाएगा या तो इस direction में flow जाएगा या फिर आप loop भी करवा सकते हो so you can see flow of execution कैसा होगा ये edges represent कर रहे हैं और उसमें भी आप अलग अलग टाइप का flow express कर पा रहे हो sequential flow भी express कर पा रहे हो parallel flow भी express कर पा रहे हो branching भी express कर पा रहे हो looping भी express कर पा रहे हो यह सारी चीज आपको land graph provide कर पा रहा है because graph का structure है so i hope मैं आपको समझा पाया कैसे land graph किसी भी LLM based workflow को बहुत असानी से graph में convert कर पाता है और कैसे उस graph में हर node एक task को represent करता है और edges flow of execution को represent करते है वो बहुत practical चीज है और इसको आप truly तब appreciate कर पाओगे जब आप code लिखोगे और खुद के workflows बनाओगे I really hope ये particular part clear है next video में हम लोग अपना first workflow बनाएंगे वहाँ पर आपको दिखाई देगा ये जो भी आपने पढ़ा अभी उसको आप कितनी आसानी से land graph में express कर सकते हो जो अगला core concept हम discuss करने जा रहे हैं उसका नाम है state and trust me ये बहुत important core concept है तो सबसे पहले समझते हैं कि state होता क्या है so अगर आप किसी भी LLM workflow की बात करो तो उस workflow को अपना execution complete करने के process में कुछ pieces of data का requirement होता है जो उसको throughout execution guide करता है help करता है for example हमारा ये जो UPSC वाला LLM workflow है यहाँ पे इस workflow से related कुछ data points ऐसे हैं जो आपको throughout the execution जरूरी मतलब required है for example आपका candidate जो essay लिख रहा है ये एक ऐसा piece of information या data है जो आपको throughout the execution चाहिए होगा it's required सोच के देखो आपको जब evaluation perform करना है तो आप evaluation किस चीज़ में perform करोगे इसी essay text के उपर similarly जो आप score calculate कर रहे हो यहाँ पे यहाँ पे और यहाँ पे ये भी ऐसा piece of information है जिसके basis पे आगे का execution डिपेंड करता है because इन scores के basis पे आप एक final score calculate कर रहो और फिर उस