
## 26、二叉树

在上节课中，我们介绍了树形数据结构。我们将树作为一种逻辑模型进行了讨论，并简要介绍了树的一些应用。在本节课中，我们将更详细地讨论二叉树。正如我们在上节课中所看到的，二叉树是一种具有以下特性的树：树中的每个节点最多可以有两个子节点。我们将首先讨论二叉树的一些一般特性，然后可以讨论一些特殊类型的二叉树，比如二叉搜索树，它是一种非常高效的结构，用于存储有序数据。在二叉树中，正如我们所说，每个节点最多可以有两个子节点。

在我画的这棵树中，节点要么没有子节点，要么有两个子节点，但也可以有一个子节点。我在这里又添加了一个节点，现在就有了一个只有一个子节点的节点。由于二叉树中的每个节点最多只能有两个子节点，我们把其中一个子节点称为左子节点，另一个称为右子节点。

对于根节点来说，这个特定节点是左子节点，而这个则是右子节点。一个节点可以同时拥有左子节点和右子节点，这四个节点就都同时具备左右子节点；或者一个节点可以仅拥有左子节点或右子节点中的一种。比如这个节点拥有左子节点，但没有右子节点。

我会在这里再添加一个节点。现在，这个节点有一个右子节点但没有左子节点。在程序中，我们会将左子节点的引用或指针设置为空。因此，我们可以说对于这个节点，左子节点为空；同样地，对于这个节点，我们可以说右子节点为空。对于所有没有子节点的叶子节点（即零个子节点的节点称为叶子节点），我们可以说这些节点的左右子节点都为空。

根据属性，我们将二叉树分为不同的类型。我在这里再画一些二叉树。如果一棵树只有一个节点，那么它也是二叉树。这种结构也是二叉树。这也是二叉树。记住，唯一的条件是节点不能有两个以上的子节点。如果每个节点要么有两个子节点，要么没有子节点，那么这棵二叉树就被称为严格二叉树或真二叉树。我现在展示的这棵树不是严格二叉树，因为有两个节点只有一个子节点。我去掉这两个节点后，现在这就是一棵严格二叉树了。

我们称一棵二叉树为完全二叉树，当且仅当除了最后一层外，其他所有层都被完全填满，并且所有节点都尽可能地向左靠拢。除了最后一层外，其他所有层无论如何都会被填满。因此，如果最后一层没有被完全填满，那么该层的节点必须尽可能地向左靠拢。

目前，这棵树还不是一棵完全二叉树。深度可以称为同一层级的节点。树中的根节点深度为0。节点的深度定义为从根节点到该节点的路径长度。在这张图中，假设深度为0的节点是第0层节点。我可以简单地用L0表示第0层。现在这两个节点位于第1层。这四个节点位于第2层，最后这两个节点位于第3层。树中任何节点的最大深度为3。树的最大深度也等于树的高度。

如果我们像L0、L1、L2这样对树中的各个层级进行编号，那么在某一层级i上，我们最多可以拥有的节点数等于2的i次方。在层级0，我们可以有1个节点。2的0次方是1。然后在层级1，我们最多可以有2个节点。在层级2，我们最多可以有2的2次方个节点，也就是4个。因此，一般来说，在任何层级i上，我们最多可以有2的i次方个节点。

你应该能很清楚地看到这一点，因为每个节点可以有两个子节点。所以，如果我们某一层有x个节点，那么这x个节点中的每一个都可以有两个子节点。因此，在下一层，我们最多可以有2x个子节点。在这个二叉树中，第二层有4个节点，这是第二层的最大值。现在，这些节点中的每一个都可能有两个子节点。我在这里只是画出了箭头。因此，在第三层，我们最多可以有2乘以4，也就是8个节点。

现在，对于一个完全二叉树来说，所有层级都必须完全填满。我们可以对最后一层或最深层给予例外。它不必完全填满，但节点必须尽可能靠左。我这里展示的这棵特定树并不是一个完全二叉树，因为左边有两个空缺位置。我将对这个结构稍作调整。现在，这就是一棵完全二叉树了。

我们可以在第三层拥有更多节点，但左侧不应有空缺位置。我在这里又添加了一个节点，这仍然是一棵完全二叉树。如果所有层都完全填满，这样的二叉树也可以称为完美二叉树。在完美二叉树中，所有层级都会被完全填满。如果h是完美二叉树的高度，记住二叉树的高度是从根节点到任意叶节点的最长路径的长度，或者更准确地说，是从根节点到任意叶节点的最长路径中的边数。二叉树的高度也等于最大深度。

对于这棵二叉树，其高度或最大深度为3。一棵高度为h的树中，最大节点数等于：第0层有2的0次方个节点，第1层有2的1次方个节点，以此类推直到高度h层，最深层将有2的h次方个节点。这个总和等于2的h+1次方减1（这里的h+1代表层数）。也可以表述为2的层数次方减1。在本例中，总层数为4（从L0到L3）。

因此，节点数量，最大节点数量将是2的4次方减1，也就是15。所以，一个完美二叉树在给定高度下会拥有最大可能的节点数量，因为所有层级都会被完全填满。嗯，我应该说是高度为h的二叉树中的最大节点数量。好的，我也可以问你这个问题。一个具有n个节点的完美二叉树的高度是多少？假设n是完美二叉树中的节点数。为了求出高度，我们需要解这个方程：n等于2的h加1次方减1。因为如果高度是h，节点数就是2的h加1次方减1。我们可以解这个方程，结果将是这样的。

记住，这里的n代表节点数量。具体数学推导就留给你自己理解了。树的高度等于以2为底的对数（n加1）再减1。在我展示的这个完美二叉树中，节点数是15。因此n等于15。n加1等于16。那么h就等于以2为底的16的对数减1。以2为底的16的对数是4。所以最终结果是4减1等于3。一般来说，对于完全二叉树，我们也可以用取整函数计算高度：以2为底的n的对数取整数部分。完美二叉树也属于完全二叉树的一种。

这里n是15。以2为底15的对数是3.906891。如果我们取整数部分，那么就是3。我不会深入探讨为什么完全二叉树的高度是以2为底n的对数。我们稍后会尝试理解这一点。所有这些数学知识在我们分析二叉树各种操作的成本时将非常有用。树操作的许多时间复杂度取决于树的高度。例如，在二叉搜索树（一种特殊的二叉树）中，搜索、插入或删除元素的时间复杂度与树的高度成正比。因此，在这种情况下，我们希望树的高度尽可能小。

如果树的密度较高，或者接近完美二叉树或完全二叉树，那么树的高度就会较低。当树是完全二叉树时，具有n个节点的树的最小高度可以是log n（以2为底）。如果我们有这样的排列方式，那么树的高度将达到最大值。对于n个节点，最小可能高度是log₂n的向下取整或整数部分，而最大可能高度是n-1，此时我们会得到一个像这样的稀疏树，几乎等同于链表。现在，思考一下。如果我说某个操作所需的时间与树的高度成正比，或者换句话说，如果某个操作的时间复杂度是O(H)，其中H是二叉树的高度，那么对于一个完全或完美二叉树，我的时间复杂度将是O(log₂n)，而对于这种稀疏树的最坏情况，我的时间复杂度将是O(n)。O(log n)的阶数几乎是可能的最佳运行时间。

当n高达2的100次方时，以2为底的对数log n仅为100。如果采用时间复杂度为n的算法，即便n等于2的100次方，即使使用人类制造过的最强大计算机，我们也需要数年时间才能完成计算。这就是问题的关键所在。我们常常希望将二叉树的高度保持在最小可能值，或者更常见地说，我们努力保持二叉树的平衡。如果对于每个节点，其左右子树的高度差不超过某个数k（通常k为1），我们称该二叉树为平衡二叉树。因此可以说，对于每个节点，其左右子树的高度差不应超过1。关于树的高度，我想补充一点：之前我们将高度定义为从根节点到叶子节点的最长路径上的边数。

仅有一个节点的树的高度为0，该节点本身即为叶节点。我们可以将空树定义为没有节点的树，并认为空树的高度为-1。人们常常将高度计算为从根节点到叶节点的最长路径上的节点数量。在此图中，我绘制了一条从根节点到叶节点的最长路径。这条路径上有3条边。因此，树的高度为3。如果计算路径上的节点数，高度则为4。这看起来非常直观，我在很多地方都见过这种高度的定义。如果计算节点数，仅有一个节点的树的高度等于1，那么我们可以说空树的高度为0。但这不是正确的定义，我们不会采用这种假设。我们将认为空树的高度为-1，而仅有一个节点的树的高度为0。节点左右子树的高度差可以计算为左子树高度减去右子树高度的绝对值，在这个计算中，子树的高度也可以是-1。

对于图中这个叶子节点，其左右子树均为空。因此，左子树高度h_left和右子树高度h_right均为-1。但整体差值仍为0。在完美二叉树中，所有节点的平衡因子差值均为0。我已移除该树的部分节点，现在每个节点旁标注了其平衡因子diff值。这仍是一棵平衡二叉树，因为所有节点的最大平衡因子差值为1。让我们再移除一些节点，此时这棵树不再平衡，因为其中一个节点的平衡因子差值达到2。对于这个特定节点，其左子树高度为1，而右子树高度为-1（因为右子树为空）。

因此，差值的绝对值为2。我们尽量保持树的平衡，以确保其紧张度和高度最小化。如果高度最小化，那么依赖于高度的各种操作的成本也会最小化。好的，接下来我想简单谈谈如何在内存中存储二叉树。

在我们之前的课程中，最常见的一种实现方式是动态创建节点，并通过指针或引用相互连接。对于整型的二叉树，在C或C++中，我们可以这样定义一个节点：数据类型为整型，因此有一个字段用于存储数据，还有两个指针变量，一个用于存储左子节点的地址，另一个用于存储右子节点的地址。这当然是最常见的方式——节点在内存中随机位置动态创建，并通过指针相互链接。但在某些特殊情况下，我们也会使用数组。数组通常用于完全二叉树。我这里画了一棵完美二叉树。

假设这是一棵整数树。我们可以做的是，从根节点开始，按从左到右的顺序逐层为这些节点编号，从0开始。因此，我们会得到0、1、2、3、4、5和6这样的编号。现在，我可以创建一个包含7个整数的数组，这些编号就可以作为这些节点的索引。所以，在第0个位置我会填入2，第1个位置填入4，第2个位置填入1，以此类推。我们已经填满了数组中的所有数据，但如何存储关于链接的信息呢？我们如何知道根节点的左子节点值为4，右子节点值为1？

那么，在完全二叉树的情况下，如果我们这样给节点编号，那么对于索引为i的节点，其左子节点的索引将是2i加1，右子节点的索引将是2i加2。请记住，这仅适用于完全二叉树。对于节点0，当i等于0时，左子节点是2i加1即1，右子节点是2i加2即2。对于节点1，左子节点位于索引3，右子节点位于索引4。当i等于2时，2i加1将是5，2i加2将是6。当我们讨论一种称为堆的特殊二叉树时，我们将详细讨论我们的实现。

数组用于实现堆。今天就讲到这里。下节课我们将讨论二叉搜索树，它也是一种特殊的二叉树，为我们提供了一种非常高效的存储结构，可以快速搜索和更新数据。本节课就到这里。感谢观看。

## 27、二叉搜索树

在上节课中，我们总体讨论了二叉树。现在，在这节课中，我们将讨论二叉搜索树，这是一种特殊的二叉树，它是一种高效的数据结构，可以快速组织和搜索数据，同时也能快速更新。但在开始讲解二叉搜索树之前，我想请大家思考一个问题：你会使用哪种数据结构来存储一个可修改的集合？假设你有一个集合，它可以是任何数据类型的集合。

集合中的记录可以是任何类型。现在，您希望将这个集合以某种结构存储在计算机的内存中，然后希望能够快速搜索集合中的记录，并且还能够修改该集合。您希望能够向集合中插入一个元素或从集合中移除一个元素。

那么，你会使用哪种数据结构呢？你可以选择数组或链表。这两种众所周知的数据结构都能用来存储集合。现在，如果我们使用数组或链表，这些操作（搜索、插入或删除）的运行时间会是多少呢？我们先来讨论数组，为了简单起见，假设我们要存储的是整数。

要存储一个可修改的整数列表或集合，我们可以创建一个足够大的数组，并将记录存储在数组的某一部分。我们可以标记列表的末尾。在我展示的这个数组中，我们有从0到3的整数，记录从0到3，数组的其余部分是可用的空间。

现在，要在集合中搜索某个x，我们必须从索引0开始扫描数组直到末尾，在最坏的情况下，可能需要查看列表中的所有元素。如果n是列表中元素的数量，所需时间将与n成正比，换句话说，我们可以说这个操作的时间复杂度为O(n)。好的，那么插入的成本是多少呢？假设我们想在这个列表中插入数字5。如果有可用的空间，这些黄色的单元格都是可用的，我们可以通过增加这个标记end来添加一个单元格，并填入要添加的整数。

此操作所需时间将是恒定的。运行时间不会依赖于集合中的元素数量。因此，我们可以说时间复杂度为O(1)。好的，那删除操作呢？假设我们想从集合中删除1。我们需要做的是将所有位于1右侧的记录向左移动一位，然后就可以减少end的值。在最坏情况下，删除操作的成本再次为O(n)。在最坏情况下，我们需要移动n-1个元素。如果数组中有可用空间，插入操作的成本将为O(1)。因此，数组必须足够大。如果数组填满了，我们可以创建一个更大的新数组。通常，我们会创建一个大小为已填满数组两倍的数组。

因此，我们可以创建一个新的更大的数组，然后将已填满的数组内容复制到这个新的大数组中。复制操作的时间复杂度为O(n)。我们在之前的课程中已经多次讨论过动态数组这个概念。所以，如果数组未填满，插入操作的时间复杂度为O(1)；如果数组已填满，插入操作的时间复杂度则为O(n)。目前，我们暂且假设数组总是足够大。现在，如果我们使用链表，让我们来讨论这些操作的成本。如果使用链表，我在这里画了一个整数链表。

数据类型可以是任何类型。搜索操作的成本再次为O(n)，其中n是集合中的记录数或链表中的节点数。在最坏的情况下进行搜索时，我们将不得不遍历整个列表。我们需要查看所有节点。在链表中，头部插入的成本是O(1)，尾部插入的成本是O(n)。我们可以选择在头部插入以降低成本。因此，插入的运行时间可以说是O(1)，换句话说，我们将花费恒定的时间。删除操作同样会是O(n)。我们首先需要遍历链表并搜索记录，在最坏的情况下，可能需要查看所有节点。好的，这就是如果我们使用数组或链表进行操作的成本。

插入操作确实很快，但对于像搜索这样的操作，O(n)的时间复杂度表现如何呢？你怎么看？如果我们要搜索一条记录x，在最坏的情况下，我们不得不将这条记录x与集合中的所有n条记录进行比较。假设我们的机器每秒可以执行一百万次比较。那么可以说，这台机器每秒能进行10的6次方次比较。

因此，一次比较的成本将是10的负6次方秒。当今世界的机器处理的是真正庞大的数据。现实世界的数据完全有可能达到1亿或10亿条记录。世界上有许多国家的人口超过1亿。有两个国家的人口超过10亿。如果我们拥有一个国家所有居民的数据，那么记录数很容易就会达到1亿条。

好的，如果我们假设一次比较的成本是10的负6次方秒，那么当n达到1亿时，所需时间将是100秒。对于搜索这种可能频繁执行的操作来说，100秒显然不合理。我们能否做得更好？能否突破O(n)的时间复杂度？实际上，在数组中，如果数据已排序，我们可以采用二分查找算法——其运行时间为O(log n)，这正是最优的时间复杂度。

我在这里画了这个整数数组。数组中的记录已排序。这里的数据类型是整数。对于其他数据类型，特别是复杂数据类型，我们应该能够根据记录的某个属性或键来对集合进行排序。我们应该能够比较记录的键，而且对于不同的数据类型，比较逻辑也会有所不同。例如对于一个字符串集合，我们可能希望记录按字典或字母顺序排序。因此，我们将进行比较，看看哪个字符串在字典顺序中排在前面。现在，这就是我们对二分查找的要求。数据结构应该是一个数组，并且记录必须是有序的。

好的，如果我们使用排序数组，搜索操作的成本可以降到最低，但在插入或删除时，我们必须确保数组之后仍然保持有序。在这个数组中，如果我想在这个阶段插入数字5，我不能简单地把5放在索引6的位置。我需要做的是，首先找到在有序列表中插入5的位置。我们可以使用二分查找在log n的时间复杂度内找到这个位置。

我们可以通过二分查找来找到列表中第一个大于5的整数。这样，我们就能快速定位到该位置。在这个例子中，索引是2，但之后我们需要将所有从该位置开始的记录向右移动一位，然后才能插入5。因此，尽管我们可以在O(log n)的时间内快速找到记录应该插入的位置，但在最坏情况下，这种移位操作会消耗O(n)的时间。所以，插入操作的总体运行时间将是O(n)，同样地，删除操作的成本也是O(n)，因为我们也需要移动一些记录。

好的，当我们使用排序数组时，搜索操作的成本被最小化了。在二分查找中，对于n条记录，最多需要进行以2为底的对数n次比较。因此，如果我们每秒能进行百万次比较，那么当n等于2的31次方（即超过20亿）时，我们只需要31微秒。因为以2为底的2的31次方的对数就是31。

好的，我们现在已经解决了查找的问题。对于任何实际的n值，我们都能很好地处理。但是插入和删除操作呢？它们的时间复杂度仍然是O(n)。我们能否在这方面做得更好呢？如果我们使用一种叫做二叉搜索树的数据结构（我简写为BST），那么这三个操作的时间复杂度都可以降低到O(log n)。在平均情况下，所有操作的时间复杂度都是O(n)。在最坏情况下，但我们可以通过确保树始终保持平衡来避免最坏情况的发生。

我们在之前的课程中讨论过平衡二叉树。二叉搜索树只是二叉树的一种特殊形式。为了确保这些操作的时间复杂度始终为O(log n)，我们应该保持二叉搜索树的平衡。我们稍后会详细讨论这个问题。首先，让我们看看什么是二叉搜索树，以及当我们使用二叉搜索树时，这些操作的成本是如何被最小化的。二叉搜索树是一种二叉树，其中对于每个节点，左子树中所有节点的值都小于该节点的值，右子树中所有节点的值都大于该节点的值。我在这里将二叉树画成一个递归结构。我们知道，在二叉树中，每个节点最多可以有两个子节点。我们可以将其中一个子节点称为左子节点。

如果我们将树视为一种递归结构，左子节点就是左子树的根节点，同理右子节点就是右子树的根节点。那么，对于一棵被称为二叉搜索树的二叉树来说，左子树中所有节点的值都必须更小。或者为了处理重复值，我们可以说小于或等于，而右子树中所有节点的值都必须更大，并且这一规则必须适用于所有节点。因此，在这个递归结构中，左右子树也必须都是二叉搜索树。我将画一个整数的二叉搜索树。现在，我已经在这里画好了一个整数的二叉搜索树。

让我们看看这个性质是否成立：对于每个节点，左子树中所有节点的值都必须小于或等于该节点，而右子树中所有节点的值都必须大于该节点。首先来看根节点。左子树中的节点值为10、8和12。所以，它们都小于15，而在右子树中，我们有17、20和25。它们都大于15。因此，根节点的情况是良好的。现在，让我们来看这个值为10的节点。在左边，我们有8，它较小。在右边，我们有12，它较大。

所以，我们没问题。这个节点值为20也没问题，我们不需要担心叶子节点，因为它们没有子节点。所以，这是一棵二叉搜索树。那么，如果我把这个值12改成16，现在这还是二叉搜索树吗？对于值为10的节点来说，没有问题。值为16的节点位于其右侧。所以，这不是问题。但是，对于根节点来说，现在左子树中有一个值更高的节点。因此，这棵树不是二叉搜索树。

我会重新调整，把数值改回12。刚才我们说到，在平均情况下，二叉搜索树的搜索、插入或删除操作时间复杂度为O(log n)。这究竟是怎么实现的呢？我们先来谈谈搜索操作。如果我在树中的这些整数存在于一个已排序的数组中，我们就可以进行二分查找。那么，二分查找是怎么做的呢？假设我们要在这个数组中查找数字10。在二分查找中，我们首先将整个列表定义为我们的搜索空间。

这个数字只能存在于搜索空间内。我将用这两个指针——起始和结束——来标记搜索空间。现在，我们将要搜索的数字或元素与搜索空间的中间元素或中位数进行比较。并且，如果正在搜索的记录中，被搜索的元素较小，我们就在左半边继续搜索；否则，就在右半边继续搜索。如果相等，就说明找到了该元素。在这个例子中，10比15小。

因此，我们将向左继续搜索。现在我们的搜索空间缩小了一半。再次与中间元素进行比较，这次我们找到了匹配项。在二分查找中，我们从包含n个元素的搜索空间开始。如果中间元素不是我们要找的元素，就将搜索空间缩小为n/2，并继续将搜索空间减半，直到找到目标记录或搜索空间只剩下一个元素为止。在整个缩小过程中，如果搜索空间从n缩小到n/2，再到n/4，再到n/8，依此类推，那么总共需要进行以2为底的对数log₂n次步骤。

如果我们进行k步操作，那么n除以2的k次方将等于1，这意味着2的k次方等于n，而k将等于以2为底的n的对数。因此，这就是为什么二分查找的运行时间是O(log n)。现在，如果我们使用这个二叉搜索树来存储整数，搜索操作将会非常相似。假设我们要查找数字12。我们将从根节点开始，然后将要查找的值（即整数）与根节点的值进行比较。如果相等，则查找完成。

如果值更小，我们就知道需要去左子树查找，因为在二叉搜索树中，左子树的所有元素都更小，右子树的所有元素都更大。现在，我们将查看值为15的节点的左子节点。我们知道要找的数字12只能存在于这个子树中，除此之外的其他子树都可以被排除。因此，我们将搜索范围缩小到仅剩这三个节点，其值分别为10、8和12。现在，我们再次将12与10进行比较，发现它们并不相等。

12更大。因此，我们知道需要在这个值为10的节点的右子树中继续查找。现在，我们的搜索范围缩小到仅剩一个节点。再次比较该节点的值，我们发现匹配成功。因此，在二叉搜索树中查找元素本质上就是这样的遍历过程：在每一步中，我们会选择向左或向右移动，从而在每一步中舍弃其中一个子树。如果树是平衡的，我们称一棵树为平衡树的条件是：对于所有节点，左右子树的高度差不超过1。因此，如果树是平衡的，我们将从n个节点的搜索空间开始，当我们舍弃其中一个子树时，我们将舍弃n/2个节点。

因此，我们的搜索空间将先缩小到n/2，然后在下一步缩小到n/4。我们会持续这样缩小搜索空间，直到找到目标元素，或者搜索空间缩小到仅剩一个节点时结束。所以，这里的搜索也是一种二分查找，这也是为什么它被称为二叉搜索树。我现在展示的这棵树是平衡的。

事实上，这是一棵完美的二叉树，但由于记录相同，我们可能会得到这样一棵不平衡的树。这棵树具有与之前结构相同的整数值，也是一棵二叉搜索树，但它是不平衡的。这几乎等同于一个链表。

在这棵树中，没有任何节点拥有右子树。每一步都只有一个节点。从搜索空间中的n个节点开始，我们会依次访问n-1个节点、n-2个节点，直到最后访问1个节点，总共需要n步。在二叉搜索树中，平均情况下，搜索、插入或删除操作的时间复杂度是O(log n)，而最坏情况下（也就是我现在展示的这种排列方式），运行时间会达到O(n)。我们总是试图通过保持二叉搜索树的平衡来避免最坏情况的发生。

树中相同的记录可以有多种排列方式。对于这棵树中的这些整数，另一种排列是这样的。对于所有节点，在搜索时左子树中没有需要丢弃的内容。这是另一种排列方式。这仍然是平衡的，因为对于所有节点来说，左右子树的高度差不超过1。但当我们有一个完美二叉树时，这是最佳的排列方式。在每一步，我们都会有正好n除以2的节点被丢弃。

好的，现在要在二叉搜索树中插入一些记录，我们首先需要找到可以插入的位置，我们可以在O(log n)的时间内找到这个位置。假设我们想在这棵树中插入19。我们要做的是从根节点开始。如果要插入的值小于或等于当前节点，且没有左子节点，则作为左子节点插入；否则向左移动。如果值大于当前节点且没有右子节点，则作为右子节点插入；否则向右移动。在本例中，19大于当前节点，因此我们将向右移动。

现在我们位于20。19更小，且左子树不为空。我们有一个左子节点，所以我们将向左移动。现在我们位于17。19比17大，所以它应该放在17的右侧。17没有右子节点。因此，我们将创建一个值为19的节点，并将其作为右子节点链接到这个值为17的节点上。因为我们在这里使用的是指针或引用，就像链表一样，所以不需要进行任何移位操作。与数组类似，创建一个链接只需要常数时间。

因此，总体而言，插入操作和搜索操作的成本是相似的。删除操作也需要先搜索节点。搜索的时间复杂度仍然是O(log n)，而删除节点只需调整一些链接。因此，删除操作的平均时间复杂度也将与搜索类似，为O(log n)。二叉搜索树在插入和删除过程中可能会失去平衡。因此，我们经常在插入和删除操作后恢复其平衡性。

有几种方法可以实现这一点，我们将在后面的课程中详细讨论所有这些内容。下一节课，我们将详细讨论二叉搜索树的实现。这节课就到这里。感谢观看。

## 28、二叉搜索树的实现

在上一课中，我们了解了什么是二叉搜索树。现在，我们将在这节课中实现二叉搜索树。我们将编写一些关于二叉搜索树的代码。学习本课程的前提是，你必须理解C/C++中指针和动态内存分配的概念。如果你已经跟随这个系列，并看过我们关于链表的课程，那么实现二叉搜索树或一般的二叉搜索树不会有太大不同。

我们这里也会有节点和链接。好的，让我们开始吧。二叉搜索树（BST）是一种二叉树，其中对于每个节点，左子树中所有节点的值都小于或等于该节点的值，而右子树中所有节点的值都大于该节点的值。我们可以将二叉搜索树（BST）表示为这样的递归结构：左子树中所有节点的值必须小于或等于当前节点，右子树中所有节点的值必须大于当前节点，并且这一性质必须适用于所有节点，而不仅仅是根节点。因此，在这个递归定义中，左右子树本身也必须是二叉搜索树。

我在这里画了一个整数的二叉搜索树。现在的问题是，我们如何在计算机的内存中创建这种非线性逻辑结构。在我们讨论二叉树时，我已经简要地提到过这一点。最流行的方法是动态创建节点，并使用指针或引用将它们相互连接。就像我们处理链表的方式一样。因为在二叉搜索树或一般的二叉树中，每个节点最多可以有两个子节点。

我们可以将节点定义为一个包含三个字段的对象，就像我在这里展示的这样。我们可以用一个字段来存储数据，另一个字段来存储左子节点的地址或引用，还有一个字段来存储右子节点的地址或引用。如果节点没有左子节点或右子节点，引用可以设置为空。在C或C++中，我们可以这样定义节点。有一个字段用于存储数据。

这里的数据类型是整数，但它可以是任何类型。有一个字段是指向节点的指针。Node asterisk 表示指向节点的指针。这个用于存储左子节点的地址，另一个用于存储右子节点的地址。这个节点的定义与双向链表中节点的定义非常相似。还记得在双向链表中，每个节点也有两个链接。

一个指向前一个节点，另一个指向下一个节点。但双向链表是一种线性排列。这个节点的定义是针对二叉树的。我们也可以将其命名为BST节点。但节点这个名称也没问题。我们就用节点吧。

现在在我们的实现中，就像链表一样，所有的节点都将通过C语言中的malloc函数或C++中的new操作符在应用程序内存的动态内存或堆区中创建。在C++中我们也可以使用malloc函数。众所周知，任何在应用程序内存的动态内存或堆区中创建的对象都不能拥有名称或标识符。

必须通过指针来访问它。malloc或new运算符会返回指向堆中创建的对象的指针。如果你想复习这些动态内存分配的概念，可以查看本视频描述中的课程链接。理解应用程序内存中栈和堆的概念非常重要。对于链表来说，我们始终需要记住的是头节点的地址。只要知道头节点，我们就可以通过链接访问所有其他节点。

对于树结构，我们始终保存的信息是根节点的地址。只要知道根节点，我们就可以通过链接访问树中的所有其他节点。要创建一棵树，首先需要声明一个指向二叉搜索树节点的指针。我宁愿在这里称它为二叉搜索树节点。BST即二叉搜索树。因此，要创建一棵树，我们首先需要声明一个指向BST节点的指针，该指针将始终存储根节点的地址。

我在这里声明了一个指向节点的指针，命名为rootptr，ptr代表指针。在C语言中，你不能直接写BST node星号rootptr。你必须写成struct空格BST node星号。这里你也必须写上struct。我打算在这里写C++代码。不过无论如何，现在我在尝试解释逻辑。

我们不必纠结于具体实现的新细节。在我展示的这个树形逻辑结构中，每个节点如你所见包含三个字段，即三个单元格。最左侧的单元格用于存储左子节点的地址，最右侧的单元格则用于存储右子节点的地址。假设根节点在内存中的地址是200，其他节点的地址我也随机假设一下。现在我可以为每个节点的左右单元格填入左右子节点的地址。在我们的定义中，数据是第一个字段，但在这个逻辑结构中，我把数据显示在中间。

好的，对于每个节点，我已经填写了左子节点和右子节点的地址。如果没有子节点，地址为零或空。正如我们之前所说，树的标识是根节点的地址。我们需要有一个指向节点的指针，以便在其中存储根节点的地址。我们必须有一个类型为指向节点的指针变量来存储根节点的地址。所有这些带有三个单元格的矩形都是节点。

它们是通过malloc或new操作符创建的，并存在于应用程序内存的堆区。我们无法为它们命名或标识，总是通过指针来访问。这个根指针（root ptr）必须是一个局部或全局变量。稍后我们会更详细地讨论这一点。通常，我们喜欢将这个根指针命名为root。我们可以这样做，但不要混淆，这是指向根的指针，而不是根本身。正如我所说的，要创建一个二叉搜索树（BST），我们首先需要声明这个指针。最初，我们可以将这个指针设为null，表示树为空。没有节点的树可以称为空树，对于空树，根指针应设为null。我们可以在程序的主函数中进行此声明并将根指针设为null。

其实，我们直接在真正的编译器里写这段代码吧。我这里在写C++。如你在main函数中所见，我声明了这个指向节点的指针，它将始终存储我的树的根节点地址，我最初将其设为null，表示树是空的。通过这段代码，我们创建了一棵空树，但空树有什么意义呢？我们需要往里面添加一些数据。所以，我现在想做的是编写一个函数来向树中插入节点。我将编写一个名为insert的函数，该函数将接收根节点的地址和要插入的数据作为参数，并在树的适当位置插入一个包含该数据的节点。在主函数中，我将调用这个insert函数，传入根节点的地址和要插入的数据。假设我先要插入数字15，然后是数字10，接着是数字20。我们还可以插入更多数据，但让我们先编写insert函数的逻辑。

在我为插入函数编写逻辑之前，我想先编写一个函数来在动态内存或堆中创建一个新节点。这个获取新节点的函数应该接收一个整数（即要插入的数据）作为参数，使用new或malloc在堆中创建一个节点，并返回这个新节点的地址。我在这里使用new操作符来创建新节点。

操作员将返回新创建节点的地址，我正在将其收集到这个指向BST节点的指针变量中。在C语言中，我们需要使用malloc而不是new操作符。在C++中也可以使用malloc。C++只是C的一个超集。在这里使用malloc也是可以的。现在，动态内存或堆中的任何内容总是通过指针来访问。现在，通过这个新节点的指针，我们可以访问新创建节点的字段。

我必须使用星号运算符来解引用这个指针。所以我写了星号new node，现在可以访问这些字段了。节点中有三个字段：data和两个指向左右节点的指针。我已经在这里设置了数据。我们可以使用这种替代语法，而不是写星号新节点点数据。我们可以简单地写新节点箭头数据，这表示相同的意思。

我们在链表课程中大量使用了这种语法。现在对于新节点，我们可以将左右子节点设为null，最后返回新节点的地址。好的，回到插入函数。插入操作可能会出现几种情况。首先，树可能是空的。当我们第一次插入数字15时，树将是空的。

如果树为空，我们可以简单地创建一个新节点并将其设为根节点。通过这条语句 root 等于获取新节点，我将根节点设置为新节点的地址，但这里有些地方不太对劲。这个根节点是插入函数的局部变量，其作用域仅限于该函数内部。我们希望修改的是主函数中的根节点。这个根节点是主函数的局部变量。有两种方法可以实现这一点：我们可以返回新根节点的地址，这样插入函数的返回类型将是指向二叉搜索树节点的指针，而不是void。

在主函数中，我们需要编写类似"root等于插入函数及其参数"这样的语句。因此，我们必须收集返回值并在主函数中更新root。另一种方法是，我们可以将主函数中这个root的地址传递给插入函数。这个root已经是一个指向节点的指针，所以它的地址可以被收集在一个指向指针的指针中。因此，在插入函数中，第一个参数将是一个指向指针的指针，这里我们可以传递地址。


我们将使用“&根”来传递地址。我们可以将这个参数命名为root，也可以命名为root ptr，或者随便取什么名字。现在我们需要做的是，用星号运算符解引用这个指针，以访问main函数中root的值，同时也可以设置main函数中root的值。因此，通过这条语句，我们设置了值，现在返回类型可以是void。这个指向指针的指针有点复杂。

我会选择前一种方法。实际上，还有另一种方式。我们不必在main函数中将root声明为局部变量，而是可以将其声明为全局变量。众所周知，全局变量必须在所有函数之外声明。如果root是全局变量，那么所有函数都可以访问它，我们就不需要传递存储在其中的地址作为参数了。

无论如何，回到插入的逻辑，正如我们所说的，如果树是空的，我们可以简单地创建一个新节点并将其设置为根节点。在这个阶段，我们想要插入15。如果我们调用插入函数，根的地址是0或null。Null只是0的宏定义，第二个参数是要插入的数字。

在这个插入函数的调用中，我们将调用获取新节点的函数。假设我们在地址200处获得了这个新节点。获取新节点函数将返回给我们地址200，我们可以在这里将其设置为根节点。但这个根节点是一个局部变量。我们将把这个地址200返回给主函数，在主函数中，我们实际上是将这个根节点等同于插入操作。因此，在主函数中，我们正在建立这个链接。

好的，接下来在主函数中我们要插入数字10。此时，根节点是200。根节点的地址是200，要插入的值是10。现在，树不是空的。那么，我们该怎么做呢？如果树不为空，基本上有两种情况。如果要插入的数据小于或等于根节点的值，我们需要将其插入到根节点的左子树中；如果要插入的数据大于根节点的值，则需要将其插入到根节点的右子树中。

因此，我们可以以一种自相似的方式，即递归的方式，来减少这个问题。在处理树结构时，递归是我们几乎随时都会用到的一种方法。在这个函数中，我会说如果要插入的数据小于或等于根节点的数据，那么就递归调用将数据插入左子树。

左子树的根节点将成为左孩子。因此，在这个递归调用中，我们传递左孩子的地址和数据作为参数，当数据插入左子树后，左子树的根节点可能会发生变化。插入函数将返回左子树新根节点的地址，我们需要将其设置为当前节点的左孩子。

在这个示例树中，目前左右子树均为空。我们正尝试插入数字10。因此，我们调用了这个插入函数。从主函数中，我们通过传递地址200和数值（或数据）10来调用插入函数。现在，由于10小于15，程序控制将转到这一行，并调用在左子树中插入数据的函数。

现在，左子树为空。因此，左子树的根地址为0。传递的数据，要插入的数据作为参数传递的是10。现在，第一个插入调用将等待下面的插入完成并返回。在最后一次插入调用中，根节点为空。假设我们在地址150处获得了这个节点。现在，这个插入调用将返回150，第一个插入调用的执行将在此行恢复，现在这个特定地址将被设置为150。

所以，我们将建立这个链接，现在这个插入调用可以结束了。它可以返回当前的根节点。实际上，这个返回根节点的操作应该适用于所有情况。所以，我把它取出来，在所有这些条件之后我得到了它。当然，我们这里还有一个else。如果数据更大，我们需要插入到右子树中。在插入函数的第三次调用中，我们插入数字20。这次，我们将执行else语句。假设else语句中的新节点地址为300。所以，这个节点会返回300。对于这个200的节点，右子节点会被设置为300，现在这个插入调用就可以结束了。返回值将是200。

好的，在这个阶段，如果调用插入数字25的操作会怎样。我们现在处于根节点，也就是地址为200的节点。25更大，所以我们需要向右子树插入。这次右子树不为空。因此，对于这次调用，我们再次来到这个else分支，最后的else，因为25大于20。现在，在这次调用中，我们将进入第一个if语句。将创建一个节点。假设我们在堆中得到了这个节点，地址为500。

这个特定的调用插入025将返回500并结束。现在，对于节点300，其右子节点将被设置为500。因此，这个链接将被建立。现在，这个人将返回300。这个子树的根没有改变，第一次调用插入也将结束。它将返回200。所以，在所有情况下我们都表现得很好。这个插入函数适用于所有情况。我们也可以在不使用递归的情况下编写这个插入函数。

我鼓励你这样做。你需要使用一些临时指针和循环。递归在这里非常直观，而且在我们处理树结构的几乎所有操作中，递归都很直观。因此，我们真正理解递归是非常重要的。好的，我现在再写一个函数来在二叉搜索树中搜索一些数据。在主函数中，我又进行了一些插入操作的调用。

现在，我想写一个名为search的函数，该函数应以根节点的地址和要搜索的数据作为参数。如果数据存在于树中，该函数应返回true，否则返回false。我们再次需要考虑几种情况。如果根节点为空，则可以返回false。如果根节点的数据等于我们要查找的数据，那么我们可以返回true。否则，我们有两种情况。要么我们需要去左子树中搜索，要么我们需要去右子树中搜索。

所以，我在这里再次使用了递归。在这两种情况下，我对搜索函数进行了递归调用。如果你理解了之前的递归，那么这个非常相似。现在来测试这段代码。我在这里所做的是让用户输入一个要搜索的数字，然后调用这个搜索函数。如果函数返回true，我就打印“找到”，否则打印“未找到”。让我们运行这段代码，看看会发生什么。

我把多条插入语句放在一行是因为这里空间有限。假设我们要搜索数字8。8被找到了，现在假设我们要搜索22。22没有被找到。所以，我们进展顺利。我就讲到这里。你可以查看本视频描述中的链接获取所有源代码。在接下来的课程中，我们将深入探讨树结构的更多应用。下节课中，我们会更深入一些，看看应用程序内存各个部分中的数据是如何移动的——当我们执行这些函数时，数据如何在内存的栈区和堆区之间流动。这会让你对概念有更清晰的认识。本节课就到这里。感谢观看。



In our previous lesson, we wrote some code for binary search tree. We wrote functions to insert and search data in BST. Now in this lesson, we will go a little deeper and try to understand how things move in various sections of application's memory when these functions get executed and this will give you a lot of clarity.

This will give you some general insight into how memory is managed for execution of a program and how recursion which is so frequently used in case of trees works. The concepts that I am going to talk about in this lesson have been discussed earlier in some of our previous lessons but it will be good to go through these concepts again when we are implementing trees. So, here is the code that we had written.

We have this function get new node to create a new node in dynamic memory and then we have this function insert to insert a new node in the tree and then we have this function to search some data in the tree and finally this is the main function. You can check the description of this video for link to this source code. Now in main function here, we have this pointer to BST node named root to store the address of root node of my tree and I am initially setting it as null to create an empty tree and then I am making some calls to insert function to insert some data in the tree and finally I am asking user to input a number and I am making call to search function to find this number in the tree.

If the search function is returning me true, I am printing found else I am printing not found. Let's see what will happen in memory when this program will execute. The memory that is allocated to a program or application for its execution in a typical architecture can be divided into these four segments.

There is one segment called text segment to store all the instructions in the program. The instructions would be compiled instructions in machine language. There is another segment to store all the global variables.

A variable that is declared outside all the functions is called global variable. It is accessible to all the functions. The next segment stack is basically scratch space for function call execution.

All the local variables, the variables that are declared within functions live in stack and finally the fourth section heap which we also call the free store is the dynamic memory that can grow or shrink as per our need. The size of all other segments is fixed. The size of all other segments is decided at compile time but heap can grow during run time and we cannot control allocation or deallocation of memory in any other segment during run time but we can control allocation and deallocation in heap.

We have discussed all of this in detail in our lesson on dynamic memory allocation. You can check the description for a link. Now what I am going to do here is I am going to draw stack and heap sections as these two rectangular containers.

I am kind of zooming into these two sections. Now I will show you how things will move in these two sections of applications memory when this program will execute. When this program will start execution, first the main function will be called.

Now whenever a function is called, some amount of memory from the stack is allocated for its execution. The allocated memory is called stack frame of the function call. All the local variables and the state of execution of the function call would be stored in the stack frame of the function call.

In the main function we have this local variable root which is pointer to BST node. So I am showing root here in this stack frame. We will execute the instructions sequentially.

In the first line in main function, we have declared root and we are initializing it and setting it as null. Null is only a macro for address 0. So here in this figure, I am setting address in root as 0. Now in the next line, we are making a call to insert function. So what will happen is execution of main will pause at this stage and a new stack frame will be allocated for execution of insert.

Main will wait for this insert above to finish and return. Once this insert call finishes, main will resume at line 2. We have these two local variables root and data in insert function in which we are collecting the arguments. Now for this call to insert function, we will go inside the first if condition here because root is null.

At this line, we will make call to get new node function. So once again execution of this insert call will pause and a new stack frame will be allocated for execution of get new node function. We have two local variables in get new node, data in which we are collecting the argument and this pointer to BST node named new node.

Now in this function, we are using new operator to create a BST node in heap. Let's say we got a new node at address 200. New operator will return us this address 200.

So this address will be set here in new node. So we have this link here and now using this pointer new node, we are setting value in these three fields of node. Let's say the first field is to store data.

So we are setting value 15 here and let's say this second cell is to store address of left child. This is being set as null and the address of right child is also being set as null and now get new node will return the address of new node and finish its execution. Whenever a function call finishes, the stack frame allocated to it is reclaimed.

Call to insert function will resume at this line and the return of get new node address 200 will be set in this root which is local variable for insert call and now insert function, this particular call to insert function will return the address of root, the address stored in this variable root which is 200 now and finish. And now main will resume at this line and root of main will be set as 200. The return of this insert call, insert root 15 will be set here.

Now in the execution of main, control will go to the next line and we have this call to insert function to insert number 10. Once again, execution of main will be paused and a stack frame will be allocated for execution of insert. Now this time for insert call, root is not null.

So we will not go inside the first if. We will access the data field of this node at address 200 using this pointer named root in insert function and we will compare it with this value 10. 10 is lesser than 15 so we will go to this line and now we are making a recursive call here.

Recursion is a function calling itself and a function calling itself is not any different from a function A calling another function B. So what will happen here is that execution of this particular insert call will be paused and a new stack frame will be allocated for execution of this another insert call to which the arguments passed are address 0 in this local variable root, left child of node at address 200 is null. So we are passing 0 in root and in data we are passing 10. Now for this particular insert call, control will go inside first if and we will make a call to get new node function at this line.

So execution of this insert will pause and we will go to get new node function here. We are creating a new node in heap. Let's say we got this new node at address 150.

Now get new node will return 150 and finish. Execution of this call to insert will resume at this line. Return of get new node will be set here and now this call to insert will return address 150 and finish.

Insert below will resume at this line and now in this insert call, left child of this node at address 200 will be set as return of the previous insert call which is 150.


ds-13

