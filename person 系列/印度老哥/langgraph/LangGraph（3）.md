
大家好，我叫 Nitesh，欢迎来到我的 YouTube 频道。在这个视频中，我们将继续我们的 “使用 LangGraph 的 Agentic AI” 播放列表。今天的视频将是这个播放列表的第三个视频。在此之前，我已经在这个播放列表中上传了两个视频。在第一个视频中，我向大家介绍了 Agentic AI 和生成式 AI 之间的关键区别。第二个视频则详细概述了 Agentic AI 是什么。在那里，我向大家解释了定义，我曾用一个实际场景向您解释过 Agentic AI 如何解决问题。我们当时举了一个自动化招聘的例子，并逐步可视化地向您展示了 Agentic AI 将如何解决该问题。看完那个例子后，我还向您介绍了 Agentic AI 的特性和特点，最后讲解了 Agentic AI 的组成部分。您已经对 Agentic AI 有了初步讨论，并了解了它是什么以及为何存在。

现在让我们稍微转移一下焦点，探讨如何实际开发 Agentic AI 应用程序。开发 Agentic AI 应用程序有些难度，您无法从头开始编写所有代码。要开发应用程序，你可以直接在 Python 中编写完整代码。对你来说，构建任何代理 AI 应用程序有点困难。你可以告诉 LangGraph，它是构建代理 AI 的最佳框架之一。好的，那么在这个完整的播放列表中，我们将创建的所有代理 AI 应用程序都将使用 LangGraph。

好的，现在我们今天的视频重点是理解 LangGraph。那么，我来告诉你确切的目标，我们在这个视频中要实现什么。具体来说，我有三个目标：首先，我想给你一个非常深入的直觉，为什么 LangGraph 存在，LangChain 无法解决什么问题，以至于需要 LangGraph。这一点我想让你明白。一旦你理解了这些，我会尝试给你稍微技术性地概述一下 LangGraph 是什么。然后我们会重点指出 LangChain 也是一个库，LangGraph 也是一个库，两者之间有什么区别。好的，在学完所有这些之后，你最大的收获将是，当你看到任何应用程序时，你能轻松地理解为了构建该应用程序，你应该使用 LangChain 还是应该使用 LangGraph。这种直觉会在你内心形成，如果你完整观看这个视频的话。

在开始视频之前我还想说两件事。第一，这个视频可能会有点长——虽然我所有的视频都很长，但这个可能比平时还要长一些。我现在也不确定，因为我正在拍摄，但直觉告诉我这个视频会有点长。说实话，我本可以在 10-15 分钟内就给你们讲清楚 Langchain 和 Langgraph 的区别，但我决定通过一个完整的实例演示，带你们深入理解，这需要花些时间。不过我保证，如果你看完整个视频，你会非常清楚地理解 Langraph 和 Langchain 之间的关键区别。你能在任何面试中回答任何问题，所以这是一件重要的事情。其次，在观看这个视频之前，有一些先决条件是你应该具备的，而最大的先决条件是你应该对 Langchain 有所了解。Langchain 是什么，你能用 Langchain 做什么，如何在 Langchain 中编写基础级别的代码，所有这些事情。如果你对 Langchain 的了解还不够，那么我建议你先去观看我的 Langchain 播放列表，如果可能的话，先看前两个视频：Langchain 的介绍以及 Langchain 中有哪些组件。如果你看了这两个视频，那么今天这个视频你就不会有任何理解上的困难。好了，就讨论到这里。

在开始之前，我真的希望我已经把我的观点都讲清楚了。现在我们要开始我们的视频了。伙计们，在继续视频之前，我们先快速回顾一下。我知道你们已经读过了，但可能已经过了一段时间了。那么 Langchain 到底是什么，以及通过 Langchain 的帮助你能做什么？我在这里写了一个定义，我们来看一下。这里写着：Langchain 是一个开源库，旨在简化基于 LLM 的应用程序的构建过程。这是对 Langchain 最准确的描述。自从 LLMs 出现以来，你可能已经注意到一种文化现象，即几乎所有软件都在尝试集成 LLMs。比如 Swiggy，他们就在应用中加入了聊天机器人；如果您在浏览器上观看 YouTube 视频，Chrome 插件就能让您与视频内容进行互动。目前市场上涌现出大量这类应用，我们称之为基于 LLM 的应用程序。我在 Langchain 的播放列表中曾向您介绍过这类应用。

制作基于 LLM 的应用程序有点困难，因为你需要将许多不同的东西组合起来才能构建这些应用程序。这就是 Langchain 的用武之地，它简化了整个流程。因此，对 Langchain 最简单的描述就是：它是一个开源库，帮助你构建基于 LLM 的应用程序。那么，Langchain 是如何做到这一点的呢？在 Langchain 中，你会得到一些模块化的构建块，借助这些模块化构建块的帮助，你可以创建任何类型的基于 LLM 的工作流程，对吧？

我来告诉你什么是模块化组件。首先 *第一个组件叫做模型*——在 Langchain 中有一个模型组件，这个组件为你提供了一个统一的接口，借助它你可以与任何 LLM 提供商的 LLM 进行交互。如果你想与 OpenAI 的 LLM 交流，也可以使用这个组件；如果你想与 Anthropic 的 Claude 模型对话，同样可以使用这个接口；如果你想使用开源模型，也可以与 Hugging Face 上的模型进行交互。所以这个组件能帮助你和任何类型的 LLM 进行对话。如果你想替换成其他 LLM，你不需要对你的代码做太多改动，因为有一个统一的接口可以在不同的 LLM 中以相同的方式工作。所以这是第一个也是最重要的组成部分。

之后还有 *另一个构建块或组成部分，我们称之为提示*。通过提示的帮助，你可以进行任何类型的提示工程，对吧。LLMs 完全基于提示工作，然后提示可以通过多种方式设计，因此整个设计过程对你非常有帮助。

这个提示组件之后是 *检索器组件*。检索器组件的特点是，通过它的帮助，你可以从任何向量存储或知识库中获取相关文档。在这里，你有不同的策略和不同的算法，通过这些帮助，你可以从任何规模和多样化的向量存储或知识库中获取你所需的信息。通过它的帮助，你可以构建基于 RAG 的应用程序，这在你之前看过的 LangChain 播放列表中已经介绍过。

但您提供的最大的东西是 LangChain 的最大特点，那就是它的链条，这就是为什么 Langchain 的名字中也含有 chain。那么链条的概念是什么呢？在 Langchain 中，您可以将不同的组件连接起来形成一个链条，明白吗？比如，您可以将提示组件与模型组件连接起来，再将模型组件与输出解析器组件连接起来，这样您就可以构建任意长度的链条。这些链条的特点是，第一个块的输出会自动成为第二个块的输入，第二个块的输出会成为第三个块的输入，以此类推。

你不需要手动完成这些操作，LangChain 会为你代劳。现在借助这个简单的抽象概念，你可以创建任意长度的链结构。没错，这就是 LangChain 最核心的功能。我已为此制作了详细视频教程，若您还不了解，请务必观看。通过这些基础模块和链式概念，您可以在 LangChain 中构建多种应用场景——无论是创建简单的对话工作流（如聊天机器人或文本摘要器），还是实现"用户输入→大语言模型处理→结果返回"的闭环交互。您甚至可以将整个流程设置为循环模式，这样就能轻松获得一个聊天机器人或文本摘要工具。在 LangChain 中构建这类工作流非常简单。

其次，如果你想的话，你也可以创建多步骤的工作流程。假设你有一个这样的用例，你需要先从用户那里获取一个主题，然后基于该主题创建一个详细的报告。当详细报告完成后，再从该报告中生成一个摘要。这就是你的一个多步骤工作流程。那么你可以非常轻松地做什么呢？将不同的组件（比如提示组件）与 LLM 组件连接起来，然后再将这个 LLM 组件与一个新的提示连接起来。将从这个新提示中得到的提示再与另一个 LLM 连接起来，最后将其与你的输出解析器连接起来。

所以在这里你给出了你的主题，这个 LLM 生成了详细的报告。在这个提示中，你写道要为这个详细报告生成一个摘要。你将这个提示发送给这个 LLM，LLM 生成了摘要。然后你将这个摘要展示给用户。所以这个多步骤的工作流程，你也可以非常容易地在 LangChain 内部构建，因为在 LangChain 中你可以构建任意长度的链。

第三，如果你想轻松构建基于 RAG（检索增强生成）的应用程序，假设你已经有一个向量存储库，里面存放了你公司的所有文档、PDF 等，以嵌入形式存储。现在你希望能够基于这些文档进行对话，比如询问公司的休假政策是什么，或者公司的通知期是多少天这类问题。那么你可以简单地设计一个工作流程：用户提供一个提示，这个提示会被发送到一个检索器，检索器会搜索与提示相关的文本，并将其提取出来，我们称之为上下文。然后，这个上下文和提示会被一起发送到一个 LLM，LLM 会理解问题，并结合从上下文中提取的相关信息，生成一个回答给你。因此，在 LangChain 框架内构建基于 RAG 的应用程序也非常简单。

最后，LangChain 还提供了让你可以构建简单级别代理的功能，我之前也向你展示过。在 LangChain 中，有一个工具的概念，这基本上意味着你可以将你的 LLM 与某些工具连接起来。这些工具可以是 API，也可以是 Python 函数，你可以与它们连接，并且你的 LLM 可以决定何时调用哪个工具，以及使用什么样的输入。所以，由于可以与工具集成，你也可以在 LangChain 中构建基本级别的代理。

例如，你做了什么？你给你的 LLM 提供了一个天气 API 工具，对吧？那么现在会发生什么呢？如果我的用户在某次提示中问我：“告诉我古尔冈的天气怎么样？”显然，LLM 并不知道今天古尔冈的天气如何。那么 LLM 可以做什么呢？它可以触发这个工具。这个工具会返回古尔冈的天气信息，然后 LLM 会将这些天气信息适当格式化后显示在响应中。这就是这类基本的代理工作流程。

不完全是有代理性的，但像这样的基于代理的工作流你也可以非常轻松地使用 Langchain 构建。好吧，简而言之，我并没有告诉你什么新东西，所有这些内容我们已经在我们的 Langchain 播放列表中非常详细地涵盖了。如果你觉得这些内容都是新的并且感到困惑，我建议你先去看那个播放列表，然后你就会开始理解这一切了。所以，我们刚刚快速回顾了一下 Langchain 的内容，现在我们的视频从这里开始。

接下来我们要做的是，我们将采用另一个稍微复杂一些的工作流。事实上，我们将采用我们在上一个视频中讨论过的工作流程，即自动化招聘流程。首先，我们会理解这个工作流程具体是如何运作的，然后我们将尝试在 LangChain 中构建它。我不会编写具体的代码，但我们会尝试在概念层面上稍微理解一下，如果我们要在 LangChain 中构建那个自动化招聘的工作流程，我们会如何构建，以及在构建过程中会遇到哪些挑战。那么，接下来我们将要做这件事。

那么，伙计们，我在这里所做的是，针对我们在上一个视频中讨论的自动化招聘的具体例子，我制作了一个非常详细和全面的流程图。事实上，它如此详细，以至于你看到我必须缩小才能让它适应整个屏幕。好吧，现在我要快速告诉那些没有看上一个视频的人，我们在上一个视频中讨论了一个实际场景，关于如何创建一个代理 AI 应用程序，借助它你可以进行自动化招聘。所以，我为同一个例子在这里制作了一个完整的流程图。

好吧，现在我们要做什么？我们将研究这个完整的流程图，好吗？然后我们将尝试理解是否可以在 LangChain 中实现这个流程图，如果不能，如果我们尝试的话，会面临哪些挑战。好吧，所以这是我们讨论的主题。在开始讨论之前，在向您解释这个流程图之前，我想在这个关键点上指出一个非常重要的区别：您现在在屏幕上看到的这个流程图，并不是一个代理式 AI 应用程序，正如我在上一个视频中告诉您的那样，相反，它是一个工作流程。

现在您可能会想，*代理式 AI 应用程序和工作流程之间有什么区别呢*？为了理解这个区别，我建议您去 Anthropic 的博客上查看，了解工作流程和代理之间的区别。这里写着：工作流程是系统，其中 LLM 和工具通过预定义的代码路径进行编排，而关于代理，他们写道：另一方面，智能体是 LLM 动态指导自身流程和工具使用的系统，保持对任务完成方式的控制权。所以在上个视频中，当我给你们举这个例子时，我曾说明：人类招聘人员会告诉系统"我需要一名后端工程师"，之后所有工作都由这个自主应用程序完成——它会自行规划实现该任务需要哪些步骤，然后逐步自主执行所有步骤。现在这些步骤是什么，以及按什么顺序执行，所有这些决策都由代理来完成。

但在我们的案例中，如果你看的话，这个流程图是预先制定好的，并且每次都会按照这个顺序执行。这个流程图是谁制定的呢？这个流程图是由开发者制定的，这就是为什么我们称它为工作流，而不是代理。我希望你能理解两者之间的区别。在代理的情况下，整个流程图将由代理动态生成，第一次运行时可能是一个流程图，第二次运行时可能是另一个流程图。但你现在在屏幕上看到的这个（流程图）则不同。

这是静态的，静态的意思是无论你运行一次还是运行一百次，信息流都会以完全相同的方式显示在你的屏幕上。那么，代理应用程序和工作流之间有一个很大的区别，尽管两者都使用了 LLMs，但一个是更加自主的，另一个是由人类创建的。我希望你理解了这一点。那么现在让我们非常仔细地理解整个流程图，看看我们如何自动化招聘流程。请注意，这不是代理在做这项工作。这是我们开发者团队。首先我们正在制作流程图，然后我们会将这个应用程序编码到链中，这就是计划。好的，那么我先放大一点，这样我可以一步步向你们展示细节。

好的，那么首先流程图开始了，流程启动了。首先我们的系统收到了一份招聘请求，这里通过提示告诉我们，我们需要招聘一名后端工程师，他将远程工作，并且需要有 2-4 年的工作经验。好的，那么接下来是什么任务呢？我们要基于这个提示，让一个 LLM 来创建一份职位描述（JD）。一旦有了详细的职位描述，我们会将其发送给我们的上级主管审批。无论谁在使用这个系统，我们都会回到创建 JD 的步骤，收集一些反馈，然后重新设计 JD。

如果 JD 被认可，我们就会将其发布到某个招聘平台上。在这里，我们可以访问一些工具，比如 LinkedIn 和 Naukri.com 的 API，通过这些 API 和工具的帮助，我们将发布这个 JD。一旦 JD 发布后，我们的系统会等待 7 天。因为我们想等待尽可能多的申请者申请这个职位。一旦 7 天过去，我们的系统会做什么呢？它会去检查申请的数量，看看到目前为止有多少人申请了这个职位。这里我们使用的是 LinkedIn 的工具，通过 LinkedIn API，我们检查 7 天前发布的职位到目前为止收到了多少申请。假设我们的门槛是 20 份申请，在达到 20 份申请之前，我们不会开始面试流程。因此，我们在系统中设置了一个检查点：如果有足够的申请，就执行某些操作；如果没有，就执行其他操作。

首先，假设 7 天过去了。之后当我们的系统运行并检查时，它只显示了 10 个申请，这低于阈值，因此我们将转到 9 的分支。在这里，我们要做的是修改我们的 jd，以增加机会，吸引更多申请。例如，我们可以降低资格标准，将 2-4 年的经验要求改为也包括应届毕业生，或者将后端工程师的职位改为全栈工程师，或者将薪资从 2 万提高到更高，诸如此类。于是我们修改了 jd，并再次等待 48 小时。好的，48 小时后，我们将再次监控申请数量，看看现在有多少申请。我们再去检查一下是否超过 20 个，如果没有的话，现在又来了 15 份申请，我们就又回到 9 个的分支去，然后再次修改 jd，再等待 48 小时，再去监控。这就像一个循环，直到出现一个退出条件。

现在，某天我们注意到来了 25 份申请，那我们就不再进入 9 个的分支，而是进入 yes 的分支。好的，那么在 yes 的分支里我们的工作是什么呢？首先，对于这 25 个人，我们会研究他们的简历。这里我们有一个简历解析工具，它会为我们下载所有简历并解析它们，然后用一个 llm 为每份简历生成一个分数。好的，所以我们在这里进行筛选。这是我们进行筛选的步骤。筛选之后，我们有五个人比较满意，他们的分数都超过了某个阈值。那么，我们会为这五个人安排面试。在这里，我们有一些工具可以使用：我们有日历 API 和邮件 API。我们会检查日历，看看面试官是否有空，然后给所有人发送邮件。

接下来就是进行面试的过程。在面试过程中，会有多个环节。首先，你会给面试官提供问题库，发送提醒邮件等等。然后面试就会进行。面试结束后，我们会再次询问是否有任何人被选中。假设我们面试了五个人，我们会逐一询问这个人是否被选中，那个人是否被选中，依此类推。有个人叫 Nitesh，如果他没被选中，我们就走“no”分支，给他发一封拒绝邮件说“抱歉，您未被录用”。然后如果来了另一个人，比如 Rahul，他被选中了，我们就走 “yes” 分支，给他发录用通知。发录用通知时，我们需要一些工具，比如一个能生成录用通知的 LLM，还有邮件 API 用来发送邮件。之后我们会跟踪对方是否接受了录用。如果对方没接受，我们会重新协商。当然，这得由真人来做，他会说“兄弟，不满意薪资的话我们可以再涨点”。

等重新协商完，我们会再发一封新的录用通知。我们会再次发送录用通知书，然后等待他是否接受。如果他接受了，那我们就开始他的入职流程。现在，在入职流程中我们也会有自己的工具。基本上，我们的人力资源管理系统会与之集成，所以从这里我们会给他发送一封欢迎邮件，安排他的知识转移会议，我们会为他提供笔记本电脑等等。这样，我们的招聘流程就完成了。所以你可以看到，如果你能正确地编码这个工作流程，你就可以进行招聘活动，对吧。

现在在概念层面上我们已经理解了，我们画了流程图，所以在概念层面上我们已经明白了。现在来了一个大问题，我们需要在整个过程中用代码实现，而且还要使用 LangChain。现在你们当中那些在 LangChain 工作过的人会知道，在 LangChain 中创建基本级别的工作流相当容易，尤其是线性工作流。你现在在屏幕上看到的并不是那么基础级别，事实上，你可以说这是一个稍微复杂的工作流，你可能已经有点直觉，在 LangChain 中创建这个不会那么容易。那么我们现在要做什么呢？我们将逐点讨论，如果你要在 LangChain 中构建这个系统，你会面临哪些困难。我将精确地为你讨论超过 8 个点。

我会让你明白为什么在像库或框架这样的 LangChain 中构建这个系统很困难，然后我们还将讨论 LangGraph 如何解决这些挑战。通过整个讨论，你将非常清楚地了解 LangChain 和 LangGraph 之间的共同差异，以及为什么需要 LangGraph。好的，所以我真的希望你能理解这节课的流程。所以，朋友们，如果你们要在 LangChain 中构建这个复杂的自动化招聘流程，那么你们面临的第一个挑战就是控制流程的复杂性。这意味着我已经告诉过你们，或许你们也知道，大多数情况下你们使用 LangChain 来创建链。链本质上是一个线性工作流，但在这里，如果你们看的话，我们的整个流程图是高度非线性的。

在这里，你们会看到三种导致非线性特性的东西。

1. 第一个是*条件分支*，也就是说基于某个条件，你们的整个控制流程可能会朝一个方向走，也可能朝另一个方向走。比如在这里看，如果你们收到了足够的申请，你们就会这样移动；如果没有收到，你们就会那样移动。这就是导致非线性的原因。
2. 由于 *循环* 导致的第二个非线性即将出现。在我们的工作流程中，您会注意到多个地方存在循环，例如如果 JD 未被批准，我们将重新创建 JD；如果仍未批准，我们将继续创建 JD。我们会一直创建 JD，直到它被批准为止。这就是一种导致非线性的循环。
3. 第三，在我们的控制流程中，存在多处 *跳跃*。跳跃意味着您的控制流程突然从某处跳到前面某个地方，或者又跳回后面某个地方。比如你看这里，你在等待 48 小时后，回到你的控制逻辑中，正在往后走

好吧。现在由于这些原因，在 LangChain 中实现整个这个流程图变得非常困难。事实上，为了展示这一点，我会为你制作一个流程图的子集，在 LangChain 中展示，我们会尝试在 LangChain 中编码这么多部分，看看它是如何工作的，好吗？所以在这里，你首先需要创建一个循环和一个条件语句，如果 jd 没有被批准，循环就会运行；如果已经被批准了，那么你就会很容易理解这段代码。否则，我也会一直指导你。

所以，我们在这里做什么？首先，我们正在写一个招聘提示。这将由我们的用户提供。我们需要为我们的后端团队招聘一名软件工程师。这基本上是这一步。我们正在创建一个提示。然后在这个步骤中我们做什么？我们正在创建一个LLM。我们正在创建一个提示模板，上面写着：根据招聘请求创建一个职位描述。在这里，我们提供我们的招聘请求。所以基本上现在我们处于“创建JD”的步骤中，在这里我们基本上是从我们的招聘提示中创建一个 JD，并且为了创建 JD，我们正在使用这个链。首先是 JD 提示，我们将其发送到 LLM 中。

我们正在将输出发送到字符串输出解析器。明白吗？之后，我们在这里创建了一个用于审批的函数。基本上，我们为此创建了一个函数，然后我们还创建了一个用于发布的函数。基本上这些都是虚拟函数，为此也有一个函数，为此也有函数，你可以看到这些都是虚拟函数。明白吗？以后你在这里会写正确的代码。但你明白了流程，招聘请求有一个函数或逻辑，创建 JD 有一个逻辑，批准 JD 有一个逻辑，发布 JD 有一个逻辑。明白吗？

现在我们需要把整个流程串联起来。看，这个流程会是怎样的？我们运行一个循环，只要 approved 为false，只要 approved 变量的值是false，我们在做什么？借助 JD 链的帮助创建一个新的 JD。明白吗？然后把它发送到 approve 函数中，并检查是否已批准。如果没有，这个循环会继续运行。如果批准了，我们就跳出这个循环并发布。我希望你能理解。所以我们用非常简单的方式在 LangChain 中构建了这个流程图的这一部分。现在问题是什么，我来告诉你。到目前为止还好，你在使用 LangChain，

但是在这一部分你看，这里你需要写很多自定义代码。这些不是 LangChain 的代码，而是 Python 代码。而且你需要写所有这些代码，因为 LangChain 没有提供运行循环的逻辑。所以为了运行这个循环，你必须自己写代码。所以每当你从库中出来，自己写代码来拼接整个流程时，我们称这种代码为“胶水代码”，胶水代码越少越好。你自己想想看，现在我们画了流程图的一部分，现在我们要画一个完整的，有多处循环、条件语句和跳转语句。

那么你自己想想，当这个应用程序慢慢构建完成时，会有多少胶水代码进入我们的代码库，而胶水代码越多，维护起来就越困难。这就是为什么使用 LangChain 构建非常庞大、非线性的复杂应用程序会变得非常困难。所以我真的希望我能让你明白第一个挑战，也是最大和首要的挑战，那就是如果你需要在 LangChain 中构建一个非常复杂、非线性的工作流，LangChain 本身甚至没有这样的结构。

如果没有条件分支、循环、跳转语句这些结构可用，那么你就得自己用 Python 构建这些结构。但所有这些代码都是胶水代码，你写的胶水代码越多，其可维护性就越差。这就是为什么维护大型复杂项目变得困难，调试变得困难，团队协作也变得困难。这也是 LangChain 最大的缺陷——它只在线性工作流和链式结构中运行良好。

一旦非线性进入系统，LangChain 就会变得严格起来。现在我们来讨论一下，如果我们需要在 LangGraph 中构建相同的工作流程，我们该如何处理。我知道你现在还不了解 LangGraph，但我会给你一个简单的介绍。在 LangGraph 中，你可以将整个工作流程表示为图，这就是这个库被称为 LangGraph 的原因。所以，本质上你所做的是将每个任务表示为图的一个节点。

好的，比如说招聘请求是一个节点，创建职位描述（JD）是一个节点，JD 获批是一个节点，发布 JD 是一个节点。所以本质上你正在做的是创建这些节点，对吧？这是招聘请求的，这是创建 JD 的，这是检查 JD 是否正确无误的，这是发布 JD 的。你创建了这些节点，并在这些节点之间绘制边，通过这些边的帮助来控制执行流程。所以基本上你所做的就是借助这些边来连接这些节点。现在，这些边决定了控制流程的走向，明白了吗？

由于我们将整个工作流程表示为图形，而图形本质上是一种非线性数据结构，因此您可以使用 LangGraph 轻松表示任何复杂类型的工作流程。我来给您看一个小代码示例，比如这里，这是 LangGraph 的代码。在这里，我们创建了一个图形，并在图形内部添加节点。我们的第一个节点是招聘请求，第二个节点是创建职位描述，第三个节点是检查审批。

而我们的小节点是 post jd，现在这些节点本身就是简单的 Python 函数，比如看这个，这是创建 jd 的函数，我们正是引用了这个函数。这是进行审批检查的函数，这是发布 jd 的函数。所以基本上，我们在这里创建节点，而这些节点中我们传递的就是我们的 Python 函数。一旦你所有的节点都创建好了，然后你就在这些节点之间绘制边，比如你的第一条边是在 hiring request 和 create jd 之间。基本上就是这个，之后你在 create jd 和 check approval 之间创建这条边。现在问题来了，关于循环和条件分支的，好吧，如果 jd 被批准了，那么就走 yes 那条路。

就像在发布职位描述（post jd）时需要前往，如果未获批准（approve），则需返回创建职位描述（create jd）的步骤。在这里，您还可以选择创建条件边（conditional edges），基于给定条件检查审批——我们的这个功能会判断职位描述是否被接受。如果被接受，我们会将其发送到发布职位描述的步骤；如果不被接受，我们会将其退回创建职位描述的步骤。本质上，我们是在循环处理。最后，我们添加了最后一条边——发布职位描述。现在您可以看到这段代码的精妙之处在哪里。

在这里，你不需要写任何自定义的Python代码，完全没有胶水代码，所有的逻辑实现都可以在 Lang Graph 中完成。你不需要运行 while 循环，不需要写 if-else 语句，所有这些逻辑结构都会自动在 LangGraph 中处理。你需要运行循环时，LangGraph 会帮你运行；你需要执行 if-else 时，LangGraph 会帮你执行；你需要在逻辑中进行跳转时，LangGraph 会帮你完成。所以我知道在这一点上，你可能还不熟悉 LangGraph。

你不懂如何在 LangGraph 中编写代码，但至少你可能已经明白 LangGraph 最棒的部分在于它能够将任何复杂的整个工作流程首先以图形的形式呈现出来。每个任务都变成一个节点，它们之间的执行控制则成为边。现在，你可以在这些边上运行循环，也可以进行分支，这就是为什么代码的可维护性非常高。没错，你的代码中不会有胶水代码，而且你可以非常精确地构建任何复杂的应用程序。

那么，我真心希望你们理解了第一个挑战，明白了 langchain 在这方面会遇到困难，而 langgraph 却能大放异彩。好了，朋友们，现在我们来谈谈第二个挑战。如果你试图在langchain中构建如此复杂的工作流，那么你将面临的另一个重大挑战是什么呢？第二个挑战就是状态管理。现在，你们脑海中可能会浮现一个问题：状态到底是什么？首先，让我来解释一下，在复杂工作流中状态的概念是什么。如果我把这个工作流展示给你们看，并且问你们——既然你们已经理解了它——那么我想问你们：你们能告诉我这个工作流中...

哪些数据是重要的，那么我想你可以指出一些东西，这里有几个重要的数据点，比如一个数据点是JD，这是我们工作流程中非常关键的一部分，对吧，同样的JD首先被批准，然后被发布，人们看到它后申请，所以JD是一个非常重要的数据点，第二个非常重要的数据点是JD是否被批准，因为后续流程依赖于它，同样另一个重要的数据点是JD是否已经被发布。

因为接下来的流程取决于这一点，之后还有一个重要的数据点，即到目前为止有多少人申请了我们的职位，对吧，同样还有一个重要的数据点，即为了开始面试流程，至少需要多少份申请，同样可能还有一个重要的数据点，即有多少候选人入围，以及我们拥有他们的哪些联系方式，还可能有一个重要的数据点，即我们向多少人发送了录用通知，还有一个数据点可能是录用通知的状态是什么。

可能还有一个数据点，那就是入职状态是什么，所以我希望你能理解，我们建立的这个复杂工作流程，为了让这个工作流程正常运行，有一些数据点和它们的值需要我们持续维护，对吧？有趣的是，这些数据点和它们的值会不断更新。比如，当你刚开始处于招聘请求阶段时，与职位描述相关的数据点的值会是空的，也就是“无”。但一旦你到达创建职位描述的步骤，职位描述的值就会被设置。同样，当你到达批准职位描述的步骤时，根据条件的不同，这些值也会相应更新。

JD的状态将变为true或false。同样，当你到达post JD时，你的JD posted的值将变为true。当你到达这里的monitor applications时，你将去检查minimum applications需要多少，5、20，无论阈值是多少，你将基于此做出决策。然后你将进行short listing，所以在这里你将告诉有多少候选人被你short list了。所以基本上，我想说的是，首先，您有一些与工作流程相关的数据点，这些数据点的值会随着时间的推移而演变。随着您逐步完成工作流程中的各个步骤，这些数据点的值会不断更新，对吧？所以，这一整套数据点集合就是我们所说的状态，这是我们工作流程的状态。整个工作流程正是借助这个状态才能正常运作，也正是通过它，我们才能了解应用程序的当前状态以及下一步该往哪里走。所以，首先，

我希望你能明白，当我们谈论任何工作流程时，state是什么，以及为什么它如此重要。如果你不能正确跟踪它的状态，任何工作流程都无法执行，对吧？现在我们来谈谈为什么在Lang chain中，当你创建这个工作流程时，处理这种状态会很困难。所以，问题是，首先，这个与任何工作流程相关的状态，所有的数据点及其值，都是以键值对的形式存在的，对吧？

但是，Lang chain并没有提供任何选项来存储和跟踪这样的键值对。Lang chain有记忆的概念，但这种记忆是对话记忆。也就是说，你可以存储与LLM的聊天记录，作为对话记忆，并且可以在链中前后传递这些信息，这样你的LLM就能始终知道我们过去聊了什么。但是，要存储和跟踪这类数据，Lang chain并没有这样的机制。所以我想说的是，当你在Lang chain中创建这类工作流时，它们是无状态的，因为Lang chain并没有跟踪这种状态。如果你需要在Lang chain中实现这种状态，

那么你必须手动操作，意思是你需要做什么呢，你必须在代码顶部创建一个字典，然后你需要一直处理这个字典，随着链的推进，你需要手动去改变这里的值，如果有需要删除的内容，你就得去删除它。所以基本上，链非常长，而且在每一步中，你都必须回过头来手动修改这个全局字典，这是一项非常繁琐的工作。如果你的工作流程非常复杂，出错的几率就会大大增加。这就是使用LangChain的第二个最大挑战，即如果你正在构建一个复杂的工作流程。

这意味着默认情况下，它的状态也会很复杂，里面会有很多字段，而LangChain并没有提供任何内在机制来存储和跟踪这个状态。你唯一的选择是，要么把整个状态当作对话记忆来处理，就像处理文本一样；第二个选择是手动创建一个字典，将其在链中从这里传递到那里，并更新其值，这是一项非常繁琐的工作。所以，我希望我能正确地呈现这个挑战给你。现在，让我们来谈谈。

关于 LangGraph 如何处理这个问题，现在如果你谈到 LangGraph，那么 LangGraph 中的执行是围绕状态的，我们可以称之为有状态的。那么Lang Graph中会发生什么呢？当你创建自己的图时，在同一时间你会创建一个状态对象，这个对象也可以在Pydantic中创建，或者通过类型化字典的帮助来创建，基本上就是一个字典。而这个字典的特点是，它可以被你图中的每个节点访问，这意味着你图中的任何节点都可以访问这个状态对象。

可以访问这个字典，即可以读取它，而且不仅仅是读取，这个状态对象或字典也是可变的，这意味着任何节点都可以对其进行编辑。所以基本概念是，当执行图形时，你首先来到这里，你创建了一个jd，那么这个节点可以访问你的状态，它会做什么呢？在创建jd的同时，它也会更新jd的值状态。然后我们来到jd批准的节点，现在这个节点也可以访问你的整个状态，那么它又会做什么呢？



जट से जा करके jd approved वाला जो आपका field है, उसकी value को true कर देगा, फिर आप इस वाले post jd वाले node में आए, तो again आपके पास पूरे state का access है, तो आप jd posted वाले जो field है, उसकी value true कर दोगे, तो जैसे जैसे आपका execution आगे बढ़ रहा है, हर node के पास, पूरा का पूरा state हर time पे available है, और आप उसमें changes करते जा रहे हो, और वो changes सभी को दिखाई दे रहे हैं, हर node को दिखाई दे रहे हैं, right, in fact, मैंने आपको code दिखाया था थोड़ी दर पहले, तो पढ़ा नहीं, आपने notice किया या नहीं, जो भी आप यहाँ पे nodes बना रहे हो, तो आप notice करो, कि हर node को input में एक state मिल रहा है, और हर node का जो output है, वो एक state ही है, तो basically हो क्या रहा है, कि जबी भी हम execution करवा रहे हैं, अपने graph का, तो node by node basis पे हम नीचे की तरफ move कर रहे हैं, हर node के पास हम जैसे ही पहुंच रहे हैं, हम उसको state वाल object दे दे रहे हैं, और हम उसको बता दे रहे हैं, कि देखो भाई, अभी यह situation है, उसके बहुत बढ़िया है, lang graph के अंदर तो आपके बास कितना भी complex state है, उसमें कितनी भी fields है कोई problem नहीं है, आप उसको एक dictionary के form में create कर दो, और फिर lang graph का काम है, कि उसको हर node तक पहुंचाएगा, और उसमें अगर कुछ update हो रहा है, तो उस update को सही से करके dictionary में changes भी कर देगा तो इस तरीके से जो पूरा का पूरा execution है, lang graph के अंदर वो state full है, बहुत important term है ये, lang chain stateless होता है lang graph state full होता है and that is why अगर आप complex applications बना रहो, complex workflows बना रहो, तो lang graph is much more suited because वहाँ पे state का concept है it's state full अब हम लोग बात करेंगे तीसरे challenge अब आप सोच रहोगे कि ये क्या होता है तो मैं आपको explain करता हूँ so कभी भी आप कोई workflow बनाओ, simple बनाओ, या फिर complex बनाओ, वो दो तरीके से execute हो सकता है पहला होता है sequentialential और दूसरा होता है event driven मैं दोनों का मतलब आपको समझाता हूँ, मानलो आप Lang chain यूज़ करके multistep chain बना रहो, जहांपे आपके पास पहला block है, जहांपे आपने user से एक prompt लिया, उसको आपने एक LLM के पास भेजा, उस LLM से जो response आया, उससे आपने एक second prompt बनाया, उसको आपने एक second LLM के पास भेजा, और finally आपके पास एक response आया, जो आप user को दिखा रहो, मानलो ये chain आपने बनाई, ये भी एक तरह का workflow है, अब इसकी खासियत क्या है, कि ये पूरा का पूरा workflow, left से right, sequentially execute होगा, without stopping, without stopping का मतलब क्या है, कि जैसे ही इस block का काम ख़तम होगा, ये start हो जाएगा, second वाले का काम ख़तम होगा, third start हो जाएगा, third से fourth पे चले जाओगे, fourth से fifth पे चले जाओगे, कहीं भी बीच में आपका जो execution flow है, वो रुकेगा नहीं, pause नहीं होगा, right, whereas, एक second model क्या है, कि आपने जो workflow बनाया, वो बीच में जा करके कहीं पे pause हो गया, और वो अब किसी external trigger का wait कर रहा है, जब ये external trigger आएगा, तब आपका workflow resume होगा, और आगे बढ़ेगा, इसको बोला जाता है event driven execution, अब हमारा workflow है, automated hiring वाला, वहां पे आप notice करोगे कि multiple nodes ऐसे हैं, जहाँ पे event driven execution हो रहा है, मैं आपको समझाता हूँ, देखो, यहाँ पे multiple जगहें ऐसे हैं, जहाँ पर आपको pause करना है अपने execution को, wait करना है, किसी trigger के होने का, और जब वो trigger होगा, तब आपको resume करना है अपना execution, जसे यहाँ पे देखो, आपने JD को post किया, उसके बाद आप monitor application तब करोगे, जब आप 7 दिन का wait complete करोगे, which basically means, आपने आज अगर job डाली LinkedIn के उपर, तो आपको 7 days तक कुछ नहीं करना है, you have to pause the workflow, जैसे ही आपको एक trigger मिलेगा, कि 7 दिन हो गए, तो आपको यहाँ से resume करना है, और पर आप यहाँ पर भी देखो, जब आप modify कर रहे हो, उसके बाद फिर से आपको pause करना है, अपने workflow को, और फिर 2 दिन के बाद resume करना है, सेम जगे से, similarly यहाँ पर देखो, आपने offer letter भेजा, candidate को, अब आगे का काम तब होगा, जब वो offer letter accept करेगा, या reject करेगा, right, तो यहाँ पर भी आपको अपना workflow को pause करना है, और wait करना है, एक external trigger का, इस case में external trigger क्या है, जो भी candidate reply कर रहा है, yes, I accept the offer, no, I reject the offer, वो trigger मिलने के बाद ही हमारा workflow resume होगा, तो जबी भी आप थोड़ा complex, agentic AI systems बनाते हो, तो वहाँ पर आप notice करोगे कि बहुत बार आपको event driven execution perform करना पड़ता है, अब event driven execution क्या होता है, वो तो आपको समझ में आ गया, अब मैं आपको बताता हूँ कि problem क्या है, problem यह है कि Lang chain is not built for event driven execution, Lang chain को बनाये गया था sequential execution के लिए, कि एक बार अगर chain शुरू हुई, तो वो अपना काम खतम करके ही रुकेगी, हमने कभी भी Lang chain को इसलिए नहीं बनाया कि एक chain स्टार्ट हुई है, अब वो रुख जाएगी, साथ दिन बाद continue करेगी, ऐसा functionality Lang chain में है ही नहीं, तो इसका simple मतलब यह है, कि आपको क्या करना पड़ेगा, अगर ये workflow आपको Lang chain में बनाना है, तो आपको सबसे पहले क्या करना पड़ेगा, कि दो chains बनाने पड़ेगे, पहला chain होगा, ये, ये अपना काम करके खतम हो जाएगी, उसके बाद आप 7 days तक wait करोगे, basically आप external python code लिखोगे, जहां पे आप track करोगे कि कितना time हो गया है, और फिर आप उसके आगे का एक second chain trigger करोगे, और फिर इनके बीच में state transfer भी आपको manually code करके लिखना पड़ेगा, again the same problem, आपको बहुत सारा glue code लिखना पड़ेगा, event handling के लिए और state transfer के लिए which is again not a good thing but अगर आप बात करो lang graph की, तो lang graph आपको inherently provide करता है event driven execution का option यहां पे since state full है हमारा पूरा का पूरा execution, what you can do is, कि किसी भी particular node पे पहुँचके, मालो आप यहां पे पहुँचके, what you can do is, कि जो भी आपका current state है, उसको आप कहीं पे store कर सकते हो, यहाँ पर एक feature होता है, check pointer बोलके, आप वो use करते हो, to save your state आप in memory भी कर सकते हो, external database में भी कर सकते हो, basically आपने अभी तक का progress save कर लिया और आब आप pause कर लिये और आब आप wait कर रहे हो जैसे ही वो external trigger आता है, आप जट से जा करके देखते हो कि आपका current state क्या है और वही से resume करते हो, यह feature आपको lang graph प्रोवाइड करता है, and that is why, lang graph में event driven execution is quite possible, यह lang graph की design में ही available है, ठीक है, तो यह एक और बड़ा challenge है, जो आप face करोगे, अगर आप इतना complex workflow बनाओगे, lang chain में, but at the same time, अगर यह same काम आप lang graph में करते हो, तो lang graph आपको out of the box solution प्रोवाइड करता है, guys, अब बात करते हैं fourth challenge के बारे में, हमारा fourth challenge है fault tolerance, अब fault tolerance क्या होता है, fault tolerance का मतलब होता है कि, basically, अगर किसी system में कोई गडबर हो जाए, उसके बाद भी क्या वो system recover करके वापस properly चल पा रहा है कि नहीं, इस ही को fault tolerance बोलते है, और fault tolerance बहुत important होता है, ऐसे workflows में, जो बहुत long running होते हैं, अब खुद सोच के देखो, हमारा यह जो workflow है, hiring वाला, यह एक long running workflow है, खुद सोच के देखो, पहले हम GD बना रहे हैं, उसके बाद post कर रहे हैं, फिर हम साथ दिन तक wait कर रहे हैं, ठीक है, फिर उसके बाद कुछ enough applications नहीं आने पर हम modify करके, फिर दो दिन तक wait कर रहे हैं, फिर यहाँ पर हम schedule कर रहे हैं, उसके बाद interview का खुद process चल रहा है, उसके बाद offer letter भेजा है, तो कब वो accept करेगा, on-boarding में multiple days लग सकते हैं, तो you can see, यह एक ऐसा workflow है, जो long running है, multiple days तक चल सकता है, even months तक चल सकता है, तो इस तरह के workflows में fault होने का chance भी जादा होता है, दो तरह के faults हो सकते हैं, पहला fault होता है, small, as in, किसी node level पे कोई fault आ जाए, जैसे कि आपने JD बना ली, अब आप उसको post करने जा रहे थे, but LinkedIn का API काम नहीं कर रहा, now that is a small fault, right, second is big fault, जिस server पे आपने अपना ये workflow deploy कर रखा था AWS पे, वो server ही down हो गया, तो ideally होना क्या चाहिए, कि इन दोनों तरह के faults से आप recover कर पाओ, ऐसा system in place होना चाहिए, अब problem ये है, कि अगर आप ये पूरा का पूरा complex workflow LinkedIn में बनाओ, तो LinkedIn में fault tolerance नहीं होता, इसका मतलब ये है, कि अगर आपने एक chain बनाया, जो कि five steps का है, और third step पे आते आते, आपका system down हो गया, कुछ भी problem आ गई, तो अब आपको क्या करना पड़ेगा, वापस शुरू से chain को execute करना पड़ेगा, because LinkedIn के अंदर कोई fault tolerance का concept नहीं है, right, और fault tolerance का ideally मतलब ये होता है, कि जहांपे आपका system break हुआ, वहीं से resume हो, ये चीज़ आपको LinkedIn में नहीं मिलती, LinkedIn assume करके चल रहा है, कि उसकी जो chains है, वो short lived है, मतलब एक बार trigger हुई, जट से अपना काम करके execution खतम, तो फिर यहाँ पे उनको लगा, कि fault tolerance उतना important नहीं है, वेराज अगर आप Langrath की बात करो, तो Langrath में आपको built-in fault tolerance मिलता है, कैसे, मैं आपको बताता हूँ, Langrath आपको दोनों तरीके के situation में fault tolerance देता है, अगर आपकी कोई चोटी problem आ जाये, या फिर अगर आपकी कोई बड़ी problem आ जाये, so, चोटी problem के case में, Langrath आपको option देता है, retry करने का, so, basically, funda यह है, कि माललो, आपने यहाँ पे, अपना GD बना लिया, अब आप उसको LinkedIn के API पे post कर रहे हो, और LinkedIn का API down है, तो, आप ऐसा code लिख सकते हो, Langrath में, कि अगर कोई error आ रहा है, तो आप उसको catch करके, थोड़ी दिर के बाद, फिर से try करो, इसी को हम retry logic बोलते हैं, और retry logic के help से, आप क्या कर सकते हो, कोई भी small level fault को handle कर सकते हो, right, अब बात करते हैं, big level fault की, system level fault की, कि आपका server ही down हो गया, आपकी machine ही बंद हो गया,

तो इस तरके सिच्वेशन में क्या होता है लैंग्राफ में रिकवरी का कौंसेप्ट है। रिकवरी का फंडा ये है कि मालो आपका इस तरह का एक वर्कफलो है और आप यहाँ पर पहुँचे थे अपने execution में तब ही आपका सर्वर डाउन हो गया और आपका वर्कफलो है वो रुख गया तो इस सिच्वेशन में आप क्या कर सकते हो आप exactly इस जगे से resume कर सकते हो और फिर अगला जो node execute होगा वो यही वाला होगा ना कि first वाला कैसे implement होता है ये पूरा चीज? I guess आपको आईडिया लग चुका होगा यहाँ पर फिर से आपका चेक पॉइंटर वाला concept यूज़ होता है so since यह पूरा का पूरा execution state full है मतलब आप पूरे time state को track कर रहो save कर रहो यहाँ तो memory में यहाँ फिर external database में basically आपके बास यहाँ पर persistence layer होता है हम पढ़ेंगे इसके बारे में आप चाहो तो एक external database में state को save करते चल सकते हो या फिर in memory भी कर सकते हो जो भी है आपका जो state है continuously track हो रहा है save हो रहा है in some memory और आपका lang graph क्या करता है कि हर node के execution के बाद एक check pointer create करता है और उस node के execution के बाद state का जो भी हालेत है उसका snapshot लेके memory में store कर लेता है अब अगर at किसी भी moment कुछ भी बड़ी problem हुई जैसे system bad गया तो आप जट से क्या कर सकते हो अपने graph को resume कर सकते हो in fact resume बोलके function होता है वहाँ पर बस आपको बता देना होता है कि आपका previous state क्या था जब system bad गया वो automatically identify कर लेगा state को और साथ ही साथ वो ये भी identify कर लेगा कि किस node में problem हुई थी और उसका next node क्या है और वो accordingly उसी point से execution को restart कर देगा तो fault tolerance बहुत high है lang graph का इस तरीके से design किया गया है because उनको पता है कि जो भी complex workflows होंगे वो long running भी होंगे और long running workflows में fault definitely आ सकता है तो retry और recovery दोनों का logic built in आपको lang graph में मिलता है guys अगला बड़ा challenge है human in the loop so human in the loop क्या होता है कि मानलो आपने एक workflow बनाया और उस workflow में किसी particular stage पे आपको human से किसी तरीके का decision making चाहिए जैसे कि हमारे workflow में अगर आप देखो तो जब हम JD बनवा रहे हैं उसके ठीक बात हम JD को approve करवा रहे हैं अब ये approval किसका है ये approval है किसी human का जो भी इस agent को drive कर रहे है जब तक उसका approval नहीं आएगा हम इस workflow में आगे नहीं बढ़ सकते और भी बहुत examples हो सकते हैं इसके for example हमारा agent या हमारा workflow हम से पूछ रहा है कि क्या मैं JD को post कर दू website पे तो यहां पे भी आप चाहो तो human approval add कर सकते हो कि without मुझसे पूछे आप किसी भी website पे कुछ भी post नहीं करोगे तो you can understand कि in a real world scenario जबी भी आप इस तरह के workflows design करोगे बहुत जगों पे ऐसा scope आएगा जहां पे आप चाहोगे कि पूरा control agent के पास नहों human के पास हो because बहुत सारे risky चीज़ों में जो accountability है वो human की होनी चाहिए तो यह जो human के लिए pause लिया जाता है workflow के बीच में इसी को बोला जाता है human in the loop अब इसको भी implement करना एक challenge है किसी भी workflow में और अगर आप lang chain में workflow को बना रहे हो तो फिर यह बहुत बड़ा problem बन जाता है because lang chain में आपका कोई ऐसा default mechanism नहीं है जिसके लिए lang chain की chains pause हो जाए human के लिए wait करें और human जब approve करें उसके बाद resume करें आप ऐसा कर सकते हो कि आपके पास एक लंबी सी chain है और वहाँ पर बीच में कहीं पे आप human से एक input मांग लो but since यह synchronous sequential chain है तो यह input short duration के लिए मांगना सही है but अगर long duration के लिए आपको चाहिए for example ऐसा हो सकता है कि manager का approval मिलने में 24 घंटे लग जाए तो problem क्या होगी कि ये आपका जो script है ये 24 hours तक इसी state में चल रहा होगा यही पे रुका हुआ होगा आपके compute resources खा रहा होगा और हो सकता है कि बीच में कुछ गडबड हो जाए और crash कर जाए तो basically फिर से वही problem है कि long chain is not designed for long running workflows, short running workflow में आप human से input मांग सकते हो बट अगर आपका human approval बहुत time के बाद आ सकता है तो उस तरह के situation में आप long chain में इस चीस को implement नहीं कर पाओगे एक तरीका ये है कि आप अपनी बड़ी सी chain को दो parts में divide कर दो मानलो ये बड़ी सी chain है और आपको इस step में human का approval चाहिए था और आपको पता है कि human का approval एक दो दिनों के बाद मिलेगा because जो human है वो पुरा analyze करेगा और उसके बाद decision making करेगा तो एक तरीका क्या है कि आप अपनी पूरी chain को दो parts में divide कर दो एक हो हो जाएगी आपकी ये chain और दूसरी हो जाएगी आपकी ये chain तो यहां तक ज़ासी execution पहुँचा आप इस chain को break कर दोगे ठीक है और फिर आप human का approval माँगने चले जाओगे okay फिर human का जब approval आएगा एक दो दिन के बाद तो आप इस नई chain को start करोगे आगे के process को अगेन बहुत सारा glue code और बहुत सारी problems हो सकती है maintainability की problem हो सकती है ठीक है तो in short human in the loop by default लांग chain में present नहीं है short term workflows के लिए आप input मांग सकते हो बट ऐसा long running possible नहीं है बट अगेन लांग ग्राफ में आप ऐसा कर सकते हो लांग ग्राफ में human in the loop is actually a first class citizen which means कि जब ये framework बनाया जा रहा था तब उन्होंने इस feature को add किया है explicitly in fact अगर आप लांग ग्राफ के documentation पे जाओ तो उनके documentation में explicitly एक section है human in the loop बोलके जहांपे अगर आप जाके key capabilities पढ़ो तो यहांपे लांग ग्राफ आप के लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके � लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके � क्योंकि अपने मेकानिजम के लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके ल लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके लिए आपके � अब gadget workflows क्याता है हुमने एक सिंगल donner पंज़ हो। आपकी हजीदोलना आपके वर्कफलो के ह Нач सकते हैं अपकी हजीदोलना आपके youtube world ऑच्छान ब्यूंक हाँ ROBIN कैसे मैं आपको समझाते हूँ तो खुदयास आकिा हमने एक सीखा वरक्षा नीव नने? हमने यार सीखा टूबियोप के जुर्ण में छ़का कुछ क्योचि यह रीफ्रेसेंट कर सकते हैं जॉन खड़ नोड को ही वर्क्षा इयास की पसादंा का पिताफ़की हुआ राज़ा ये ग्राफ आ गया या फिर इसको ऐसे प्रेजन्ट कर सकते हैं कि ये नोड खुद में एक ग्राफ है तो एसेंचिली आप यहाँ पे सब ग्राफ्स बना सकते हो और सिंस आप सब ग्राफ्स बना सकते हो तो आप किसी भी तरह का nested workflow भी बना सकते हो अब आप सोच रहे होगे कि nested workflow कहा एक बहुत useful concept है अगर आप हमारा ही example देखो जहाँ पर हमने एक automated hiring का workflow बनाया यहाँ पर अगर आप conduct interview वाले section में जाओ तो यहाँ तो हमने simply लिख दिया कि भाई interview conduct कर दो बट ये खुद में एक बहुत complex task है सोच के देखो यहाँ पर बहुत सारी चीज़े हो रही हैं सबसे पहले आप क्या कर रहे हो आप हर candidate के हिसाब से अलग questions generate कर रहे हो right that is one task फिर आप multiple rounds of interview ले रहे हो round 1 उसके बाद फिर evaluation फिर round 2 उसके बाद फिर evaluation फिर round 3 फिर evaluation यह सब कुछ हो रहा है सिर्फ एक single conduct interview के अंदर तो don't you think conduct interview को हम एक अलग workflow की तरह treat कर सकते हैं और उस अलग workflow को हम अपने बड़े workflow में connect कर सकते हैं सो यही basic idea है कि आप एक workflow के अंदर कितने भी और workflows बना सकते हो और हम हर workflow को एक node की तरह represent करते हैं अपने actual बड़े ग्राफ में ठीक है I hope आपको थोड़ा समझ में आ रहा है मैं आपको एक बार documentation दिखाता हूँ again यह एक ऐसा feature है जो अलग से land graph के documentation में आपको दिखाई देगा इतना important feature है यहां पे देखो लिखा हुआ है a sub graph is a graph that is used as a node in another graph एकदम simple definition है sub graph एक ऐसा graph होता है जो दूसरे graph के अंदर as a node use होता है जैसे कि ये एक बड़ा graph है उसके अंदर ये चीज एक single node है बट इस node के अंदर खुद का एक graph है ठीक है this is a concept of encapsulation applied to land graph sub graphs allow you to build complex systems with multiple components that are themselves graphs ठीक है I hope आपको समझ में आ रहा है यहाँ पर जो सबसे बड़ा challenge होता है वो यही होता है कि ये अंदर वाला भी एक graph है बाहर वाला भी एक graph है इन दोनों के अपने-अपने states हैं तो इन states के बीच में interaction कैसे होगा वही आपको समझना होता है जब हम आगे पढ़ेंगे इसको तो हम सीखेंगे यह state में कैसे communication हो रहा है बड़ अभी बस यह समझो कि this is possible in lang graph और इसके दो बहुत बड़े use cases हैं तहला बहुत बड़ा use case है कि आप इस concept को use करके multi agent system बना सकते हो basically एक ऐसा system जिसमें multiple agents साथ में काम कर रहे है मैं आपको एक real world example देता हूँ इसका अच्छा example है self driving car अब self driving car में basic funda यह है कि वो car खुछ से चलती है तो obviously इसको चलाने के लिए एक smart system चाहिए होगा तो यह जो system बनेगा इसमें multiple agents हो सकते हैं जैसे एक agent हो सकता है जो सारे sensors का information लेके आएगा और उसको process करेगा एक दूसरा agent हो सकता है जो पूरा का पूरा driving capability handle करेगा एक तीसरा agent हो सकता है जो पूरा का पूरा entertainment वाला जो part है car का उसको handle करेगा और फिर एक fourth agent हो सकता है जो CEO की तरह काम करेगा वो इन सब से काम करवाएगा बाकी की agent से तो इस तरह के system को multi-agent system बोला जाता है और ये बहुत useful है आप going forward बहुत जगों पर देखोगे कि multi-agent systems deploy किये जाते हैं in order to solve complex problems तो multi-agent systems अगर आप बनाना चाहते हो तो आप land graph का ये feature use करोगे sub graph वाला that is one use case the second use case is कि आप sub graphs re-usability को picture में ला सकते हो basically आप किसी graph को re-usable बना सकते हो और उसी graph को as it is एक बड़े graph में अलग लग जगों पर use कर सकते हो जैसे कि मान लो आपने एक छोटा सा graph बना लिया for approval तो आपके इस workflow में multiple जगों पर approval चाहिए jd approval करने के लिए approval चाहिए jd post करने के लिए approval चाहिए interview schedule करने के लिए approval चाहिए बहुत जगों पर approval चाहिए तो हम क्या करेंगे approval के लिए एक अलग graph एक अलग छोटा सा workflow बना लेंगे और उसको हम re-use करते रहेंगे पूरे के पूरे graph में तो ये re-usability का concept आप implement कर सकते हो with the help of sub graphs और ये बहुत फायदिमन्द है right आप जिस तरीके से functions बनाते थे programming में ताकि वह आप उसको बार बार re-use करो वही same concept आप workflows में भी ला सकते हो आप re-usable workflows बना सकते हो जो आपके एक बड़े system में अलग लग जगों पे use होगा ठीक है तो ये दो बहुत बड़े काम है जो आप nested workflows या फिर sub graphs की help से achieve कर सकते हो पहला to build multi-agentic systems and second re-usability और obviously अगर हम lang chain की बात करें तो lang chain में ये feature आपको नहीं मिलता जब आप यही workflow ये simple simple तो नहीं बोलूंगा बड़ ये workflow आप बनाने में struggle कर रहो lang chain के अंदर तो फिर इसी के अंदर हम एक और workflow बना दे वो तो बिलकोली possible नहीं है तो lang chain की challenge मैंने शुरू में बोला कि इसको challenge नहीं मानते है बड़ या lang chain की challenge है बड़ lang graph में this is a feature that you have जिस last challenge की हम लोग बाद करेंगे वो है observability अब observability क्या होती है मैंने लिखा है observability refers to how easily you can monitor debug and understand what your workflow is doing at runtime so basically जब आप अपने workflow को चलाते हो तो चलने के time पे क्या हो सकता है कि बहुत तरह की problems हो सकती है हो सकता है कि कुछ error आ जाए या आपका workflow crash कर जाए या फिर आपका workflow कुछ ऐसा decision making कर दे जो आपने उस से anticipate नहीं किया था तो इस तरह के situations में it's very important specially in production जब आपने अपने workflow या agent को deploy कर रखा है और users उसको use कर रहे है it's very important कि आप बहुत closely monitor करो कि जब आपका agent या workflow run कर रहा है तो वो कैसे run कर रहा है और ये feature हमें observability के थू मिलता है और ये बहुत important है imagine किसी agent ने कुछ गलत कर दिया मान लो उसने LinkedIn पे job post करके ads चला दिया और ads भी without limit चला दिया और बहुत खर्चा हो गया तो बाद में आपको audit करने के लिए बहुत ज़रूरी है कि आप पीछे जाके देख पाओ कि क्या-क्या reasons थे क्या-क्या steps ऐसे लिए गए जिसकी वज़े से agent को ऐसा लगा कि वो कितने भी पैसे खर्चे कर सकता है तो auditing में बहुत help हो रही है, debugging में बहुत help हो सकती है तो observability on the whole is a very important concept और अच्छी बात यह है कि observability का जो concept है वो आपको lang chain में भी मिलता है, so एक library है langsmith बोलके, यह मैंने अभी तक आपको पढ़ाया नहीं है but I am pretty sure आपने इसका नाम सुना होगा, so langsmith का exactly यही purpose है कि वो LLM based applications को monitor करने के काम आती है ठीक है, तो आप क्या कर सकते हो, langsmith को बहुत आसानी से langchain के साथ integrate कर सकते हो, और जैसे ही आप ये integration करते हो, तो langsmith बहुत closely langchain को monitor करने लग जाता है, जैसे कि अगर आपने chain के अंदर किसी particular step में LLM को call किया तो langsmith इस बात को record कर लेगा, वो ये भी record कर लेगा कि आपने LLM को क्या prompt बेजा, वो ये भी record कर लेगा कि पलट के आपके LLM ने क्या reply दिया, जो reply दिया उसमें कितने tokens थे, reply देने में कितना time लगा हर तरह की चीज वो record करता है, so that आप बाद में आकर के उस chain को monitor कर पाओ, there is only one problem, problem यह है कि langchain सिर्फ, I am sorry, langsmith सिर्फ langchain को ही monitor कर सकता है, आपके glue code को monitor नहीं कर सकता, so अगर आपको याद होगा, मैं ने आपको एकदम शुरू में बताया था, कि अगर आप एक बहुत complex workflow बनाना चाहते हो using langchain, तो फिर आप सिर्फ और सिर्फ langchain में पूरा code नहीं लिख पाओगे, आपको थोड़ा सा अपनी side से glue code add करना पड़ेगा, जैसे कि आपको एक loop चलाना है, तो आप अपना खुद का while loop चलाओगे, अब langsmith की problem क्या है कि वो langchain का code तो track कर लेगा, जैसे LLM को call किया गया, यह code वो track कर लेगा, बट वो यह नहीं समझ पाएगा किस loop के अंदर क्या हो रहा है, यह वो यह नहीं समझ पाएगा कि अभी जो मैंने LLM को message किया है, वो loop का कौन सा iteration है, तो basically problem यह है कि langchain वाला part langsmith track कर रहा है, बट glue code उसको समझ में नहीं आरा, तो इसका मतलब यह है कि जबी भी आप complex application बनाने जाओगे using langchain, आपको partial observability मिलेगी, complete observability नहीं मिलेगी, और इस problem को langgraph अच्छे से solve करता है, langgraph के साथ langsmith का बहुत tight integration है, so जैसा मैंने बताया पूरा का पूरा stateful execution होता है langgraph के अंदर, तो होता क्या है कि हर चीज को track किया जाता है, जैसे कि आप इस node से अब इस node पे गए, ये node execute हुआ, फिर ये node execute हुआ, तो ये पूरी चीज, ये जो पूरा timeline of events है, ये बहुत अच्छे से langsmith में record होता है, in fact langgraph ये बात खुद langsmith को बताता है, ठीक है, basically आपके पास हर चीज का information है, हर node के execution पे क्या हुआ, state में क्या changes आए, state node में घुसने के पहले कैसा था, node से निकलने के बाद कैसा है, what are the messages जो हमने exchange किया है, between the human and the agent, ये भी record होता है, फिर आपका ये भी record होता है कि, जब human loop में आया, approval वगरा दिया, तो वो किस point पे उसने approval दिया, so basically एक पूरा chronological timeline बनती है, आपके runtime की, जब आपका workflow एकदम शुरू से लेकर end तक जा रहा है, step by step, तो वो पूरी चीज को आप backtrack कर सकते हो, using langsmith, तो ये बहुत बड़ा फाइद है, I am sure आपको अभी पूरी तरीके से समझ नहीं आ रहा होगा, because थोड़ा advance लग रहा होगा, but don't worry, मैं बस आपको बताना चाहरा हूँ कि ऐसा कुछ exist करता है, अभी हम इसको बहुत detail में आगे पढ़ेंगे, जब हम इस playlist में थोड़ा और deep जाएंगे, तो मैं आपको ये पूरा observability का concept अच्छे से सिखाऊंगा, मैं आपको दिखाऊंगा कि कैसे आप langsmith को integrate कर सकते हो, lang graph के साथ, और वो integration पूरा कैसे काम करता है, वो सब कुछ मैं आपको समझाओंगा, फिलाल बस ऐसा समझ लो, कि जब आप कोई भी workflow deploy करते हो production में, तो उसको बहुत closely monitor करना बहुत important है, debugging point of view से भी, और auditing point of view से भी, बट अगर आपने अपना complex workflow lang chain में बनाया है, तो आप partially ही observability implement कर सकते हो, पूरे तरीके से आप observability implement नहीं कर पाओगे, because बहुत सारा glue code है, but if you are using lang graph to build your complex application, तो since कोई glue code नहीं है, सारा का सारा code आप lang graph के अंदर ही कर रहो, तो lang graph बहुत अच्छे से बता पाता है, langsmith जैसे tool को, कि देखो मैंने हर point पे यह decision क्यों लिया, तो आपके लिए वो debugging बहुत easy हो जाती है, तो यही point, यही challenge मुझे आपको समझाना था, I really hope मैं समझा पाया, बाकि अगर आपको लग रहा है कि बहुत difficult हो रहा है, don't worry, छोड़ दो, आगे हम इसको बहुत detail में पढ़ेंगे, तो चलो guys, अब हम लोग इस वीडियो को conclude करते हैं, कुछ questions का answer करके, और यह kind of a revision होगा, I'm pretty sure यह सारी चीज़े अब आपको समझ में आ गई हैं, सबसे पहला quick question, Language Graph क्या होता है, यह आपने इस वीडियो में detail में पढ़ा है, यहाँ पर मैं आपके लिए summarize कर देता हूँ, Language Graph is an orchestration framework that enables you to build stateful, multi-step and event-driven workflows using LLMs. It's ideal for designing both single-agent and multi-agent agentic AI applications. I really hope इस पूरे definition में आपको एक भी नया term नहीं दिख रहा है, ठीक है, Think of Language Graph as a flowchart engine for LLMs.You define the steps as nodes, how they are connected using edges and the logic that governs the transition. Language Graph takes care of the state management, conditional branching, looping, pausing and resuming and fault recovery. Features essential for building robust, production-grade AI systems.Trust me, यहाँ पर बहुत सारे heavy-heavy terms used हुए है, but I am pretty sure अगर आपने वीडियो अभी तक पूरा देखा है, तो इसमें से एक भी term आपको alien नहीं लग रहा होगा, ठीक है, तो I hope आपको Language Graph का एक introduction मिल गया. Second, when to use what? Lang chain कब उसकरना चाहिए, Lang graph कब उसकरना चाहिए? Lang chain आप तब उसकरों जब आपको simple linear workflows बनाने हैं, जैसे कि prompt chain हो गया, summarizer हो गया, या फिर एक basic RAG system हो गया, इस तरह के situations में Lang chain अच्छा काम करता है. Lang graph आपको तब उसकरना चाहिए, जब आप complex non-linear workflows बना रहे हो, जहांपे आपको conditional paths की ज़रूरत है, loops की ज़रूरत है, human in the loops टेब की ज़रूरत है, multi-agent coordination या collaboration करवाना है, या फिर आपको asynchronous event driven execution करवाना है, इस तरह के requirements के लिए आपके पास Lang graph है.So, I really hope कल को अगर आप कोई project उठाओ, और उसके requirements समझो, तो साथ ही साथ आप ये भी समझ जाओगे, कि उसमें आपको Lang chain के साथ काम करना चाहिए, या फिर Lang graph के साथ. तो ये मैंने आपको promise किया था वीडियो की शुरुवात में, कि by the end of the video, मैं आपको इतना Lang chain और Lang graph के बीच का difference समझा दूँगा, कि कल को कोई नया project ले ते टाइम, आप automatically समझ जाओगे, कि आपको उसमें Lang chain implement करना है, या Lang graph. तो I really hope ये मैं कर पाया, ठीक है? Last, but एक बहुत valid question, बहुत सारी बुराईयां देखी हमने इस वीडियो में, Lang chain के बारे में, और बहुत सारी तारीफे सुनी हमने, Lang graph के बारे में, तो क्या इसका ये मतलब है, कि हम Lang chain को छोड़ दे, और सिर्फ Lang graph सीखने पर focus करें? The answer is no.Lang chain आपको अभी भी use करना है, So, Lang graph is built on top of Lang chain. Lang graph को इस तरीके से नहीं बनाया गया है, कि वो Lang chain को replace करे, Lang graph को इस तरीके से बनाया गया है, कि वो ज़ाधा complex problems को solve कर सकता है, बट वो Lang chain की help से ही problems को solve करता है, ठीक है? तो अगर आप बहुत complex workflows बना रहे हो, वहाँ पर भी तो आपको LLM से interact करने की ज़रूरत पड़ेगी, वहाँ पर भी तो आपको prompts लिखने पड़ेंगे, वहाँ पर भी तो आपको documents लोड करने पड़ेंगे, तो यह सारे जो components हैं, वो अभी भी आपको Lang chain से ही मिलते हैं, chat open AI हो गया, prompt template हो गया, retriever हो गया, document loader हो गया, text splitter हो गया, tools हो गया, यह सारी चीज़े जो आपने Lang chain में पड़ी थी, वह सारे components आप अभी भी use करोगे, बस उन सारे चीज़ों को जोड़ने के लिए, orchestrate करने के लिए, आप Lang graph use करते हो, तो Lang graph is completely different, Lang chain का अलग purpose है, Lang graph का अलग purpose है, आप complex workflows बनाना चाहते हो, तो आप Lang graph use करो, तो Lang graph is for, you know, chaining or orchestrating a framework, or orchestrating a workflow, it's not for components, तो दोनों hand in hand चलेंगे, आगे भी आप देखोगे इस playlist में, जब हम कोई भी agent या workflow बनाएंगे, हम दोनों चीज़े use कर रहे होंगे, हम Lang chain भी use कर रहे होंगे, हम Lang graph भी use कर रहे होंगे, तो डरो मत आपने जो महनत किये, Lang chain सीखने में, वो कहीं डू भी नहीं है, वो भी काम आएगी, और यह जो नई चीज़ आप सीख रहे हो, यह भी आपको help करेगी, तो I really hope, बहुत time ले करके, जो मैंने आपको differences समझाए, Lang chain और Lang graph के बीच में, वो आपको समझ में आए, साती साथ आपको एक अच्छा introduction भी मिल गया है, Lang graph के बारे में, और आप एक बड़ा picture देख पारे हो, कि यह library exist क्यों करती है, और मेरे इसाब से वो बहुत important है, जब तक आपके बास why का answer नहीं है, आगे के बीडियो में आपको मज़ा नहीं आएगा, तो I really hope, now you are feeling inspired, and you are waiting for upcoming videos, ठीक है, अगर आप कोई बीडियो पसंद आया, please like करना, अगर आपने channel को subscribe नहीं किया है, please subscribe, मिलते हैं next video में, bye.