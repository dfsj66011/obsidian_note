
大家好，我叫 Nitesh，欢迎来到我的 YouTube 频道。我们当时举了一个自动化招聘的例子，并逐步可视化地向您展示了 Agentic AI 将如何解决该问题。看完那个例子后，我还向您介绍了 Agentic AI 的特性和特点，最后讲解了 Agentic AI 的组成部分。您已经对 Agentic AI 有了初步讨论，并了解了它是什么以及为何存在。

现在让我们稍微转移一下焦点，探讨如何实际开发 Agentic AI 应用程序。开发 Agentic AI 应用程序有些难度，您无法从头开始编写所有代码。要开发应用程序，你可以直接在 Python 中编写完整代码。对你来说，构建任何代理 AI 应用程序有点困难。你可以告诉 LangGraph，它是构建代理 AI 的最佳框架之一。好的，那么在这个完整的播放列表中，我们将创建的所有代理 AI 应用程序都将使用 LangGraph。

好的，现在我们今天的视频重点是理解 LangGraph。那么，我来告诉你确切的目标，我们在这个视频中要实现什么。具体来说，我有三个目标：首先，我想给你一个非常深入的直觉，为什么 LangGraph 存在，LangChain 无法解决什么问题，以至于需要 LangGraph。这一点我想让你明白。一旦你理解了这些，我会尝试给你稍微技术性地概述一下 LangGraph 是什么。然后我们会重点指出 LangChain 也是一个库，LangGraph 也是一个库，两者之间有什么区别。好的，在学完所有这些之后，你最大的收获将是，当你看到任何应用程序时，你能轻松地理解为了构建该应用程序，你应该使用 LangChain 还是应该使用 LangGraph。这种直觉会在你内心形成，如果你完整观看这个视频的话。

在开始视频之前我还想说两件事。第一，这个视频可能会有点长——虽然我所有的视频都很长，但这个可能比平时还要长一些。我现在也不确定，因为我正在拍摄，但直觉告诉我这个视频会有点长。说实话，我本可以在 10-15 分钟内就给你们讲清楚 Langchain 和 Langgraph 的区别，但我决定通过一个完整的实例演示，带你们深入理解，这需要花些时间。不过我保证，如果你看完整个视频，你会非常清楚地理解 Langraph 和 Langchain 之间的关键区别。你能在任何面试中回答任何问题，所以这是一件重要的事情。其次，在观看这个视频之前，有一些先决条件是你应该具备的，而最大的先决条件是你应该对 Langchain 有所了解。Langchain 是什么，你能用 Langchain 做什么，如何在 Langchain 中编写基础级别的代码，所有这些事情。如果你对 Langchain 的了解还不够，那么我建议你先去观看我的 Langchain 播放列表，如果可能的话，先看前两个视频：Langchain 的介绍以及 Langchain 中有哪些组件。如果你看了这两个视频，那么今天这个视频你就不会有任何理解上的困难。好了，就讨论到这里。

在开始之前，我真的希望我已经把我的观点都讲清楚了。现在我们要开始我们的视频了。伙计们，在继续视频之前，我们先快速回顾一下。我知道你们已经读过了，但可能已经过了一段时间了。那么 Langchain 到底是什么，以及通过 Langchain 的帮助你能做什么？我在这里写了一个定义，我们来看一下。这里写着：Langchain 是一个开源库，旨在简化基于 LLM 的应用程序的构建过程。这是对 Langchain 最准确的描述。自从 LLMs 出现以来，你可能已经注意到一种文化现象，即几乎所有软件都在尝试集成 LLMs。比如 Swiggy，他们就在应用中加入了聊天机器人；如果您在浏览器上观看 YouTube 视频，Chrome 插件就能让您与视频内容进行互动。目前市场上涌现出大量这类应用，我们称之为基于 LLM 的应用程序。我在 Langchain 的播放列表中曾向您介绍过这类应用。

制作基于 LLM 的应用程序有点困难，因为你需要将许多不同的东西组合起来才能构建这些应用程序。这就是 Langchain 的用武之地，它简化了整个流程。因此，对 Langchain 最简单的描述就是：它是一个开源库，帮助你构建基于 LLM 的应用程序。那么，Langchain 是如何做到这一点的呢？在 Langchain 中，你会得到一些模块化的构建块，借助这些模块化构建块的帮助，你可以创建任何类型的基于 LLM 的工作流程，对吧？

我来告诉你什么是模块化组件。首先 *第一个组件叫做模型*——在 Langchain 中有一个模型组件，这个组件为你提供了一个统一的接口，借助它你可以与任何 LLM 提供商的 LLM 进行交互。如果你想与 OpenAI 的 LLM 交流，也可以使用这个组件；如果你想与 Anthropic 的 Claude 模型对话，同样可以使用这个接口；如果你想使用开源模型，也可以与 Hugging Face 上的模型进行交互。所以这个组件能帮助你和任何类型的 LLM 进行对话。如果你想替换成其他 LLM，你不需要对你的代码做太多改动，因为有一个统一的接口可以在不同的 LLM 中以相同的方式工作。所以这是第一个也是最重要的组成部分。

之后还有 *另一个构建块或组成部分，我们称之为提示*。通过提示的帮助，你可以进行任何类型的提示工程，对吧。LLMs 完全基于提示工作，然后提示可以通过多种方式设计，因此整个设计过程对你非常有帮助。

这个提示组件之后是 *检索器组件*。检索器组件的特点是，通过它的帮助，你可以从任何向量存储或知识库中获取相关文档。在这里，你有不同的策略和不同的算法，通过这些帮助，你可以从任何规模和多样化的向量存储或知识库中获取你所需的信息。通过它的帮助，你可以构建基于 RAG 的应用程序，这在你之前看过的 LangChain 播放列表中已经介绍过。

但您提供的最大的东西是 LangChain 的最大特点，那就是它的链条，这就是为什么 Langchain 的名字中也含有 chain。那么链条的概念是什么呢？在 Langchain 中，您可以将不同的组件连接起来形成一个链条，明白吗？比如，您可以将提示组件与模型组件连接起来，再将模型组件与输出解析器组件连接起来，这样您就可以构建任意长度的链条。这些链条的特点是，第一个块的输出会自动成为第二个块的输入，第二个块的输出会成为第三个块的输入，以此类推。

你不需要手动完成这些操作，LangChain 会为你代劳。现在借助这个简单的抽象概念，你可以创建任意长度的链结构。没错，这就是 LangChain 最核心的功能。我已为此制作了详细视频教程，若您还不了解，请务必观看。通过这些基础模块和链式概念，您可以在 LangChain 中构建多种应用场景——无论是创建简单的对话工作流（如聊天机器人或文本摘要器），还是实现"用户输入→大语言模型处理→结果返回"的闭环交互。您甚至可以将整个流程设置为循环模式，这样就能轻松获得一个聊天机器人或文本摘要工具。在 LangChain 中构建这类工作流非常简单。

其次，如果你想的话，你也可以创建多步骤的工作流程。假设你有一个这样的用例，你需要先从用户那里获取一个主题，然后基于该主题创建一个详细的报告。当详细报告完成后，再从该报告中生成一个摘要。这就是你的一个多步骤工作流程。那么你可以非常轻松地做什么呢？将不同的组件（比如提示组件）与 LLM 组件连接起来，然后再将这个 LLM 组件与一个新的提示连接起来。将从这个新提示中得到的提示再与另一个 LLM 连接起来，最后将其与你的输出解析器连接起来。

所以在这里你给出了你的主题，这个 LLM 生成了详细的报告。在这个提示中，你写道要为这个详细报告生成一个摘要。你将这个提示发送给这个 LLM，LLM 生成了摘要。然后你将这个摘要展示给用户。所以这个多步骤的工作流程，你也可以非常容易地在 LangChain 内部构建，因为在 LangChain 中你可以构建任意长度的链。

第三，如果你想轻松构建基于 RAG（检索增强生成）的应用程序，假设你已经有一个向量存储库，里面存放了你公司的所有文档、PDF 等，以嵌入形式存储。现在你希望能够基于这些文档进行对话，比如询问公司的休假政策是什么，或者公司的通知期是多少天这类问题。那么你可以简单地设计一个工作流程：用户提供一个提示，这个提示会被发送到一个检索器，检索器会搜索与提示相关的文本，并将其提取出来，我们称之为上下文。然后，这个上下文和提示会被一起发送到一个 LLM，LLM 会理解问题，并结合从上下文中提取的相关信息，生成一个回答给你。因此，在 LangChain 框架内构建基于 RAG 的应用程序也非常简单。

最后，LangChain 还提供了让你可以构建简单级别代理的功能，我之前也向你展示过。在 LangChain 中，有一个工具的概念，这基本上意味着你可以将你的 LLM 与某些工具连接起来。这些工具可以是 API，也可以是 Python 函数，你可以与它们连接，并且你的 LLM 可以决定何时调用哪个工具，以及使用什么样的输入。所以，由于可以与工具集成，你也可以在 LangChain 中构建基本级别的代理。

例如，你做了什么？你给你的 LLM 提供了一个天气 API 工具，对吧？那么现在会发生什么呢？如果我的用户在某次提示中问我：“告诉我古尔冈的天气怎么样？”显然，LLM 并不知道今天古尔冈的天气如何。那么 LLM 可以做什么呢？它可以触发这个工具。这个工具会返回古尔冈的天气信息，然后 LLM 会将这些天气信息适当格式化后显示在响应中。这就是这类基本的代理工作流程。

不完全是有代理性的，但像这样的基于代理的工作流你也可以非常轻松地使用 Langchain 构建。好吧，简而言之，我并没有告诉你什么新东西，所有这些内容我们已经在我们的 Langchain 播放列表中非常详细地涵盖了。如果你觉得这些内容都是新的并且感到困惑，我建议你先去看那个播放列表，然后你就会开始理解这一切了。所以，我们刚刚快速回顾了一下 Langchain 的内容，现在我们的视频从这里开始。

接下来我们要做的是，我们将采用另一个稍微复杂一些的工作流。事实上，我们将采用我们在上一个视频中讨论过的工作流程，即自动化招聘流程。首先，我们会理解这个工作流程具体是如何运作的，然后我们将尝试在 LangChain 中构建它。我不会编写具体的代码，但我们会尝试在概念层面上稍微理解一下，如果我们要在 LangChain 中构建那个自动化招聘的工作流程，我们会如何构建，以及在构建过程中会遇到哪些挑战。那么，接下来我们将要做这件事。

那么，伙计们，我在这里所做的是，针对我们在上一个视频中讨论的自动化招聘的具体例子，我制作了一个非常详细和全面的流程图。事实上，它如此详细，以至于你看到我必须缩小才能让它适应整个屏幕。好吧，现在我要快速告诉那些没有看上一个视频的人，我们在上一个视频中讨论了一个实际场景，关于如何创建一个代理 AI 应用程序，借助它你可以进行自动化招聘。所以，我为同一个例子在这里制作了一个完整的流程图。

好吧，现在我们要做什么？我们将研究这个完整的流程图，好吗？然后我们将尝试理解是否可以在 LangChain 中实现这个流程图，如果不能，如果我们尝试的话，会面临哪些挑战。好吧，所以这是我们讨论的主题。在开始讨论之前，在向您解释这个流程图之前，我想在这个关键点上指出一个非常重要的区别：您现在在屏幕上看到的这个流程图，并不是一个代理式 AI 应用程序，正如我在上一个视频中告诉您的那样，相反，它是一个工作流程。

现在您可能会想，*代理式 AI 应用程序和工作流程之间有什么区别呢*？为了理解这个区别，我建议您去 Anthropic 的博客上查看，了解工作流程和代理之间的区别。这里写着：工作流程是系统，其中 LLM 和工具通过预定义的代码路径进行编排，而关于代理，他们写道：另一方面，智能体是 LLM 动态指导自身流程和工具使用的系统，保持对任务完成方式的控制权。所以在上个视频中，当我给你们举这个例子时，我曾说明：人类招聘人员会告诉系统"我需要一名后端工程师"，之后所有工作都由这个自主应用程序完成——它会自行规划实现该任务需要哪些步骤，然后逐步自主执行所有步骤。现在这些步骤是什么，以及按什么顺序执行，所有这些决策都由代理来完成。

但在我们的案例中，如果你看的话，这个流程图是预先制定好的，并且每次都会按照这个顺序执行。这个流程图是谁制定的呢？这个流程图是由开发者制定的，这就是为什么我们称它为工作流，而不是代理。我希望你能理解两者之间的区别。在代理的情况下，整个流程图将由代理动态生成，第一次运行时可能是一个流程图，第二次运行时可能是另一个流程图。但你现在在屏幕上看到的这个（流程图）则不同。

这是静态的，静态的意思是无论你运行一次还是运行一百次，信息流都会以完全相同的方式显示在你的屏幕上。那么，代理应用程序和工作流之间有一个很大的区别，尽管两者都使用了 LLMs，但一个是更加自主的，另一个是由人类创建的。我希望你理解了这一点。那么现在让我们非常仔细地理解整个流程图，看看我们如何自动化招聘流程。请注意，这不是代理在做这项工作。这是我们开发者团队。首先我们正在制作流程图，然后我们会将这个应用程序编码到链中，这就是计划。好的，那么我先放大一点，这样我可以一步步向你们展示细节。

好的，那么首先流程图开始了，流程启动了。首先我们的系统收到了一份招聘请求，这里通过提示告诉我们，我们需要招聘一名后端工程师，他将远程工作，并且需要有 2-4 年的工作经验。好的，那么接下来是什么任务呢？我们要基于这个提示，让一个 LLM 来创建一份职位描述（JD）。一旦有了详细的职位描述，我们会将其发送给我们的上级主管审批。无论谁在使用这个系统，我们都会回到创建 JD 的步骤，收集一些反馈，然后重新设计 JD。

如果 JD 被认可，我们就会将其发布到某个招聘平台上。在这里，我们可以访问一些工具，比如 LinkedIn 和 Naukri.com 的 API，通过这些 API 和工具的帮助，我们将发布这个 JD。一旦 JD 发布后，我们的系统会等待 7 天。因为我们想等待尽可能多的申请者申请这个职位。一旦 7 天过去，我们的系统会做什么呢？它会去检查申请的数量，看看到目前为止有多少人申请了这个职位。这里我们使用的是 LinkedIn 的工具，通过 LinkedIn API，我们检查 7 天前发布的职位到目前为止收到了多少申请。假设我们的门槛是 20 份申请，在达到 20 份申请之前，我们不会开始面试流程。因此，我们在系统中设置了一个检查点：如果有足够的申请，就执行某些操作；如果没有，就执行其他操作。

首先，假设 7 天过去了。之后当我们的系统运行并检查时，它只显示了 10 个申请，这低于阈值，因此我们将转到 9 的分支。在这里，我们要做的是修改我们的 jd，以增加机会，吸引更多申请。例如，我们可以降低资格标准，将 2-4 年的经验要求改为也包括应届毕业生，或者将后端工程师的职位改为全栈工程师，或者将薪资从 2 万提高到更高，诸如此类。于是我们修改了 jd，并再次等待 48 小时。好的，48 小时后，我们将再次监控申请数量，看看现在有多少申请。我们再去检查一下是否超过 20 个，如果没有的话，现在又来了 15 份申请，我们就又回到 9 个的分支去，然后再次修改 jd，再等待 48 小时，再去监控。这就像一个循环，直到出现一个退出条件。

现在，某天我们注意到来了 25 份申请，那我们就不再进入 9 个的分支，而是进入 yes 的分支。好的，那么在 yes 的分支里我们的工作是什么呢？首先，对于这 25 个人，我们会研究他们的简历。这里我们有一个简历解析工具，它会为我们下载所有简历并解析它们，然后用一个 llm 为每份简历生成一个分数。好的，所以我们在这里进行筛选。这是我们进行筛选的步骤。筛选之后，我们有五个人比较满意，他们的分数都超过了某个阈值。那么，我们会为这五个人安排面试。在这里，我们有一些工具可以使用：我们有日历 API 和邮件 API。我们会检查日历，看看面试官是否有空，然后给所有人发送邮件。

接下来就是进行面试的过程。在面试过程中，会有多个环节。首先，你会给面试官提供问题库，发送提醒邮件等等。然后面试就会进行。面试结束后，我们会再次询问是否有任何人被选中。假设我们面试了五个人，我们会逐一询问这个人是否被选中，那个人是否被选中，依此类推。有个人叫 Nitesh，如果他没被选中，我们就走“no”分支，给他发一封拒绝邮件说“抱歉，您未被录用”。然后如果来了另一个人，比如 Rahul，他被选中了，我们就走 “yes” 分支，给他发录用通知。发录用通知时，我们需要一些工具，比如一个能生成录用通知的 LLM，还有邮件 API 用来发送邮件。之后我们会跟踪对方是否接受了录用。如果对方没接受，我们会重新协商。当然，这得由真人来做，他会说“兄弟，不满意薪资的话我们可以再涨点”。

等重新协商完，我们会再发一封新的录用通知。我们会再次发送录用通知书，然后等待他是否接受。如果他接受了，那我们就开始他的入职流程。现在，在入职流程中我们也会有自己的工具。基本上，我们的人力资源管理系统会与之集成，所以从这里我们会给他发送一封欢迎邮件，安排他的知识转移会议，我们会为他提供笔记本电脑等等。这样，我们的招聘流程就完成了。所以你可以看到，如果你能正确地编码这个工作流程，你就可以进行招聘活动，对吧。

现在在概念层面上我们已经理解了，我们画了流程图，所以在概念层面上我们已经明白了。现在来了一个大问题，我们需要在整个过程中用代码实现，而且还要使用 LangChain。现在你们当中那些在 LangChain 工作过的人会知道，在 LangChain 中创建基本级别的工作流相当容易，尤其是线性工作流。你现在在屏幕上看到的并不是那么基础级别，事实上，你可以说这是一个稍微复杂的工作流，你可能已经有点直觉，在 LangChain 中创建这个不会那么容易。那么我们现在要做什么呢？我们将逐点讨论，如果你要在 LangChain 中构建这个系统，你会面临哪些困难。我将精确地为你讨论超过 8 个点。

我会让你明白为什么在像库或框架这样的 LangChain 中构建这个系统很困难，然后我们还将讨论 LangGraph 如何解决这些挑战。通过整个讨论，你将非常清楚地了解 LangChain 和 LangGraph 之间的共同差异，以及为什么需要 LangGraph。好的，所以我真的希望你能理解这节课的流程。所以，朋友们，如果你们要在 LangChain 中构建这个复杂的自动化招聘流程，那么你们面临的第一个挑战就是控制流程的复杂性。这意味着我已经告诉过你们，或许你们也知道，大多数情况下你们使用 LangChain 来创建链。链本质上是一个线性工作流，但在这里，如果你们看的话，我们的整个流程图是高度非线性的。

在这里，你们会看到三种导致非线性特性的东西。

1. 第一个是*条件分支*，也就是说基于某个条件，你们的整个控制流程可能会朝一个方向走，也可能朝另一个方向走。比如在这里看，如果你们收到了足够的申请，你们就会这样移动；如果没有收到，你们就会那样移动。这就是导致非线性的原因。
2. 由于 *循环* 导致的第二个非线性即将出现。在我们的工作流程中，您会注意到多个地方存在循环，例如如果 JD 未被批准，我们将重新创建 JD；如果仍未批准，我们将继续创建 JD。我们会一直创建 JD，直到它被批准为止。这就是一种导致非线性的循环。
3. 第三，在我们的控制流程中，存在多处 *跳跃*。跳跃意味着您的控制流程突然从某处跳到前面某个地方，或者又跳回后面某个地方。比如你看这里，你在等待 48 小时后，回到你的控制逻辑中，正在往后走

好吧。现在由于这些原因，在 LangChain 中实现整个这个流程图变得非常困难。事实上，为了展示这一点，我会为你制作一个流程图的子集，在 LangChain 中展示，我们会尝试在 LangChain 中编码这么多部分，看看它是如何工作的，好吗？所以在这里，你首先需要创建一个循环和一个条件语句，如果 jd 没有被批准，循环就会运行；如果已经被批准了，那么你就会很容易理解这段代码。否则，我也会一直指导你。

所以，我们在这里做什么？首先，我们正在写一个招聘提示。这将由我们的用户提供。我们需要为我们的后端团队招聘一名软件工程师。这基本上是这一步。我们正在创建一个提示。然后在这个步骤中我们做什么？我们正在创建一个LLM。我们正在创建一个提示模板，上面写着：根据招聘请求创建一个职位描述。在这里，我们提供我们的招聘请求。所以基本上现在我们处于“创建JD”的步骤中，在这里我们基本上是从我们的招聘提示中创建一个 JD，并且为了创建 JD，我们正在使用这个链。首先是 JD 提示，我们将其发送到 LLM 中。

我们正在将输出发送到字符串输出解析器。明白吗？之后，我们在这里创建了一个用于审批的函数。基本上，我们为此创建了一个函数，然后我们还创建了一个用于发布的函数。基本上这些都是虚拟函数，为此也有一个函数，为此也有函数，你可以看到这些都是虚拟函数。明白吗？以后你在这里会写正确的代码。但你明白了流程，招聘请求有一个函数或逻辑，创建 JD 有一个逻辑，批准 JD 有一个逻辑，发布 JD 有一个逻辑。明白吗？

现在我们需要把整个流程串联起来。看，这个流程会是怎样的？我们运行一个循环，只要 approved 为false，只要 approved 变量的值是false，我们在做什么？借助 JD 链的帮助创建一个新的 JD。明白吗？然后把它发送到 approve 函数中，并检查是否已批准。如果没有，这个循环会继续运行。如果批准了，我们就跳出这个循环并发布。我希望你能理解。所以我们用非常简单的方式在 LangChain 中构建了这个流程图的这一部分。现在问题是什么，我来告诉你。到目前为止还好，你在使用 LangChain，

但是在这一部分你看，这里你需要写很多自定义代码。这些不是 LangChain 的代码，而是 Python 代码。而且你需要写所有这些代码，因为 LangChain 没有提供运行循环的逻辑。所以为了运行这个循环，你必须自己写代码。所以每当你从库中出来，自己写代码来拼接整个流程时，我们称这种代码为“胶水代码”，胶水代码越少越好。你自己想想看，现在我们画了流程图的一部分，现在我们要画一个完整的，有多处循环、条件语句和跳转语句。

那么你自己想想，当这个应用程序慢慢构建完成时，会有多少胶水代码进入我们的代码库，而胶水代码越多，维护起来就越困难。这就是为什么使用 LangChain 构建非常庞大、非线性的复杂应用程序会变得非常困难。所以我真的希望我能让你明白第一个挑战，也是最大和首要的挑战，那就是如果你需要在 LangChain 中构建一个非常复杂、非线性的工作流，LangChain 本身甚至没有这样的结构。

如果没有条件分支、循环、跳转语句这些结构可用，那么你就得自己用 Python 构建这些结构。但所有这些代码都是胶水代码，你写的胶水代码越多，其可维护性就越差。这就是为什么维护大型复杂项目变得困难，调试变得困难，团队协作也变得困难。这也是 LangChain 最大的缺陷——它只在线性工作流和链式结构中运行良好。

一旦非线性进入系统，LangChain 就会变得严格起来。现在我们来讨论一下，如果我们需要在 LangGraph 中构建相同的工作流程，我们该如何处理。我知道你现在还不了解 LangGraph，但我会给你一个简单的介绍。在 LangGraph 中，你可以将整个工作流程表示为图，这就是这个库被称为 LangGraph 的原因。所以，本质上你所做的是将每个任务表示为图的一个节点。

好的，比如说招聘请求是一个节点，创建职位描述（JD）是一个节点，JD 获批是一个节点，发布 JD 是一个节点。所以本质上你正在做的是创建这些节点，对吧？这是招聘请求的，这是创建 JD 的，这是检查 JD 是否正确无误的，这是发布 JD 的。你创建了这些节点，并在这些节点之间绘制边，通过这些边的帮助来控制执行流程。所以基本上你所做的就是借助这些边来连接这些节点。现在，这些边决定了控制流程的走向，明白了吗？

由于我们将整个工作流程表示为图形，而图形本质上是一种非线性数据结构，因此您可以使用 LangGraph 轻松表示任何复杂类型的工作流程。我来给您看一个小代码示例，比如这里，这是 LangGraph 的代码。在这里，我们创建了一个图形，并在图形内部添加节点。我们的第一个节点是招聘请求，第二个节点是创建职位描述，第三个节点是检查审批。

而我们的小节点是 post jd，现在这些节点本身就是简单的 Python 函数，比如看这个，这是创建 jd 的函数，我们正是引用了这个函数。这是进行审批检查的函数，这是发布 jd 的函数。所以基本上，我们在这里创建节点，而这些节点中我们传递的就是我们的 Python 函数。一旦你所有的节点都创建好了，然后你就在这些节点之间绘制边，比如你的第一条边是在 hiring request 和 create jd 之间。基本上就是这个，之后你在 create jd 和 check approval 之间创建这条边。现在问题来了，关于循环和条件分支的，好吧，如果 jd 被批准了，那么就走 yes 那条路。

就像在发布职位描述（post jd）时需要前往，如果未获批准（approve），则需返回创建职位描述（create jd）的步骤。在这里，您还可以选择创建条件边（conditional edges），基于给定条件检查审批——我们的这个功能会判断职位描述是否被接受。如果被接受，我们会将其发送到发布职位描述的步骤；如果不被接受，我们会将其退回创建职位描述的步骤。本质上，我们是在循环处理。最后，我们添加了最后一条边——发布职位描述。现在您可以看到这段代码的精妙之处在哪里。

在这里，你不需要写任何自定义的Python代码，完全没有胶水代码，所有的逻辑实现都可以在 Lang Graph 中完成。你不需要运行 while 循环，不需要写 if-else 语句，所有这些逻辑结构都会自动在 LangGraph 中处理。你需要运行循环时，LangGraph 会帮你运行；你需要执行 if-else 时，LangGraph 会帮你执行；你需要在逻辑中进行跳转时，LangGraph 会帮你完成。所以我知道在这一点上，你可能还不熟悉 LangGraph。

你不懂如何在 LangGraph 中编写代码，但至少你可能已经明白 LangGraph 最棒的部分在于它能够将任何复杂的整个工作流程首先以图形的形式呈现出来。每个任务都变成一个节点，它们之间的执行控制则成为边。现在，你可以在这些边上运行循环，也可以进行分支，这就是为什么代码的可维护性非常高。没错，你的代码中不会有胶水代码，而且你可以非常精确地构建任何复杂的应用程序。

那么，我真心希望你们理解了第一个挑战，明白了 langchain 在这方面会遇到困难，而 langgraph 却能大放异彩。好了，朋友们，现在我们来谈谈第二个挑战。如果你试图在langchain中构建如此复杂的工作流，那么你将面临的另一个重大挑战是什么呢？第二个挑战就是状态管理。现在，你们脑海中可能会浮现一个问题：状态到底是什么？首先，让我来解释一下，在复杂工作流中状态的概念是什么。如果我把这个工作流展示给你们看，并且问你们——既然你们已经理解了它——那么我想问你们：你们能告诉我这个工作流中...

哪些数据是重要的，那么我想你可以指出一些东西，这里有几个重要的数据点，比如一个数据点是JD，这是我们工作流程中非常关键的一部分，对吧，同样的JD首先被批准，然后被发布，人们看到它后申请，所以JD是一个非常重要的数据点，第二个非常重要的数据点是JD是否被批准，因为后续流程依赖于它，同样另一个重要的数据点是JD是否已经被发布。

因为接下来的流程取决于这一点，之后还有一个重要的数据点，即到目前为止有多少人申请了我们的职位，对吧，同样还有一个重要的数据点，即为了开始面试流程，至少需要多少份申请，同样可能还有一个重要的数据点，即有多少候选人入围，以及我们拥有他们的哪些联系方式，还可能有一个重要的数据点，即我们向多少人发送了录用通知，还有一个数据点可能是录用通知的状态是什么。

可能还有一个数据点，那就是入职状态是什么，所以我希望你能理解，我们建立的这个复杂工作流程，为了让这个工作流程正常运行，有一些数据点和它们的值需要我们持续维护，对吧？有趣的是，这些数据点和它们的值会不断更新。比如，当你刚开始处于招聘请求阶段时，与职位描述相关的数据点的值会是空的，也就是“无”。但一旦你到达创建职位描述的步骤，职位描述的值就会被设置。同样，当你到达批准职位描述的步骤时，根据条件的不同，这些值也会相应更新。

JD的状态将变为true或false。同样，当你到达post JD时，你的JD posted的值将变为true。当你到达这里的monitor applications时，你将去检查minimum applications需要多少，5、20，无论阈值是多少，你将基于此做出决策。然后你将进行short listing，所以在这里你将告诉有多少候选人被你short list了。所以基本上，我想说的是，首先，您有一些与工作流程相关的数据点，这些数据点的值会随着时间的推移而演变。随着您逐步完成工作流程中的各个步骤，这些数据点的值会不断更新，对吧？所以，这一整套数据点集合就是我们所说的状态，这是我们工作流程的状态。整个工作流程正是借助这个状态才能正常运作，也正是通过它，我们才能了解应用程序的当前状态以及下一步该往哪里走。所以，首先，

我希望你能明白，当我们谈论任何工作流程时，state是什么，以及为什么它如此重要。如果你不能正确跟踪它的状态，任何工作流程都无法执行，对吧？现在我们来谈谈为什么在Lang chain中，当你创建这个工作流程时，处理这种状态会很困难。所以，问题是，首先，这个与任何工作流程相关的状态，所有的数据点及其值，都是以键值对的形式存在的，对吧？

但是，Lang chain并没有提供任何选项来存储和跟踪这样的键值对。Lang chain有记忆的概念，但这种记忆是对话记忆。也就是说，你可以存储与LLM的聊天记录，作为对话记忆，并且可以在链中前后传递这些信息，这样你的LLM就能始终知道我们过去聊了什么。但是，要存储和跟踪这类数据，Lang chain并没有这样的机制。所以我想说的是，当你在Lang chain中创建这类工作流时，它们是无状态的，因为Lang chain并没有跟踪这种状态。如果你需要在Lang chain中实现这种状态，

那么你必须手动操作，意思是你需要做什么呢，你必须在代码顶部创建一个字典，然后你需要一直处理这个字典，随着链的推进，你需要手动去改变这里的值，如果有需要删除的内容，你就得去删除它。所以基本上，链非常长，而且在每一步中，你都必须回过头来手动修改这个全局字典，这是一项非常繁琐的工作。如果你的工作流程非常复杂，出错的几率就会大大增加。这就是使用LangChain的第二个最大挑战，即如果你正在构建一个复杂的工作流程。

这意味着默认情况下，它的状态也会很复杂，里面会有很多字段，而LangChain并没有提供任何内在机制来存储和跟踪这个状态。你唯一的选择是，要么把整个状态当作对话记忆来处理，就像处理文本一样；第二个选择是手动创建一个字典，将其在链中从这里传递到那里，并更新其值，这是一项非常繁琐的工作。所以，我希望我能正确地呈现这个挑战给你。现在，让我们来谈谈。

关于 LangGraph 如何处理这个问题，现在如果你谈到 LangGraph，那么 LangGraph 中的执行是围绕状态的，我们可以称之为有状态的。那么Lang Graph中会发生什么呢？当你创建自己的图时，在同一时间你会创建一个状态对象，这个对象也可以在Pydantic中创建，或者通过类型化字典的帮助来创建，基本上就是一个字典。而这个字典的特点是，它可以被你图中的每个节点访问，这意味着你图中的任何节点都可以访问这个状态对象。

可以访问这个字典，即可以读取它，而且不仅仅是读取，这个状态对象或字典也是可变的，这意味着任何节点都可以对其进行编辑。所以基本概念是，当执行图形时，你首先来到这里，你创建了一个jd，那么这个节点可以访问你的状态，它会做什么呢？在创建jd的同时，它也会更新jd的值状态。然后我们来到jd批准的节点，现在这个节点也可以访问你的整个状态，那么它又会做什么呢？

当你从JD Approved对应的字段中将其值设为true后，再到Post JD对应的节点时，你依然拥有整个状态的访问权限。这时，你可以将JD Posted字段的值设为true。随着执行的推进，每个节点在任何时候都能获取完整的状态信息，而你也在持续对这些状态进行修改。这些修改对所有节点都是可见的。事实上，我之前给你展示过一些代码，不知道你是否注意到，在这里创建的每个节点都会接收到一个状态作为输入，而每个节点的输出也是一个状态。

那么基本上是这样的，每当我们执行图形时，我们是在逐个节点向下移动。每到达一个节点，我们就给它一个状态对象，并告诉它：“兄弟，现在的情况是这样的。”这非常好，因为在语言图内部，无论你的状态有多复杂，有多少字段，都没有问题。你只需将其创建为一个字典形式，然后语言图的工作就是将其传递到每个节点。如果在过程中有任何更新，它会正确地执行更新并在字典中进行相应的更改。因此，整个执行过程在语言图内部是状态完整的。

这是一个非常重要的术语，Lang Chain是无状态的，而Lang Graph是全状态的。因此，如果你正在构建复杂的应用程序或复杂的工作流程，Lang Graph更为适合，因为它具有状态的概念，是全状态的。现在我们来讨论第三个挑战。你可能在想这是什么，我来解释一下。无论你构建的是简单还是复杂的工作流程，它都可以通过两种方式执行：第一种是顺序执行，第二种是事件驱动。我来解释一下两者的含义。假设你正在使用Lang Chain构建一个多步骤链，其中第一个块是...当你从用户那里获取了一个提示，你将其发送给一个LLM，然后根据该LLM的响应创建第二个提示，再将其发送给第二个LLM，最终得到一个响应，并将其展示给用户。假设你构建了这样的链条，这也是一种工作流程。现在，这个工作流程的特点在于，整个过程从左到右按顺序执行，不会中断。不会中断的意思是，一旦这个模块的工作完成，下一个模块的工作就会立即开始，第二个模块的工作完成后，第三个模块的工作就会立即开始。

你会从第三到第四，再从第四到第五，无论中间的执行流程如何，它都不会停止或暂停，对吧？然而，第二种模式是，你创建的工作流在中间某个地方暂停了，现在它正在等待某个外部触发。当这个外部触发到来时，你的工作流将恢复并继续前进。这被称为事件驱动的执行。现在，我们有一个自动化招聘的工作流，你会注意到有多个节点正在进行事件驱动的执行。我来解释一下，看，这里有多处地方你需要暂停执行，等待某个触发发生。当那个触发发生时，你需要恢复你的执行。

如你所见，你发布了JD之后，你要监控申请，当你完成7天的等待期后，这基本上意味着，如果你今天在LinkedIn上发布了职位，那么在7天内你不需要做任何事情，你必须暂停工作流程，一旦你收到一个触发信号，即7天已经过去，你就要从这里恢复，然后你看这里，当你修改之后，你又要暂停你的工作流程，然后在2天后恢复，同样地，你看这里，你发送了offer letter给候选人，接下来的工作将在候选人接受或拒绝offer letter后进行，对吧，

所以在这里，你也需要暂停你的工作流程，并等待一个外部触发。在这个案例中，外部触发是什么呢？就是候选人的回复，无论是“是的，我接受这个offer”，还是“不，我拒绝这个offer”。只有收到这个触发后，我们的工作流程才会继续。所以，每当你构建稍微复杂一些的、具有代理功能的AI系统时，你会注意到很多时候你需要执行事件驱动的操作。那么，事件驱动执行到底是什么？我想你现在已经明白了。现在我来告诉你问题是什么。问题是Lang chain并不是为事件驱动执行而设计的，Lang chain是为了顺序执行而构建的。

一旦链条开始运作，它就会一直持续到完成其任务为止。我们从未设计Lang chain的目的是让一条链条启动后暂停，几天后再继续。Lang chain中根本没有这样的功能。所以这意味着，如果你想在Lang chain中构建这样的工作流程，你需要做的是首先创建两条链条。第一条链条会完成它的工作并结束，然后你需要等待7天。基本上，你需要编写外部Python代码来跟踪已经过去的时间，然后触发第二条链条。此外，你还需要手动编写代码来实现这两条链条之间的状态转移。同样的问题再次出现，你需要编写大量的粘合代码。

对于事件处理和状态转移来说，这又不是一件好事。但如果你谈到Lang Graph，Lang Graph会为你提供事件驱动执行的选项。在这里，由于我们的整个执行过程是有状态的，你可以做的是，在任何特定节点到达时，比如你到达这里时，你可以做的是，无论你当前的状态是什么，你都可以将其存储在某处。这里有一个叫做检查点的功能，你可以使用它来保存你的状态，你也可以在内存中保存。

你也可以在外部数据库中操作，基本上你已经保存了到目前为止的进度，现在你暂停了，现在你在等待，一旦那个外部触发器到来，你就去查看你当前的状态是什么，然后从那里恢复，这个功能由lang graph提供，这就是为什么在lang graph中事件驱动的执行是完全可能的，这在lang graph的设计中就已经可用，好的，那么这是另一个大挑战，如果你在lang chain中构建如此复杂的工作流，但同时，如果你在lang graph中做同样的工作，那么lang graph会为你提供一个开箱即用的解决方案，伙计们。

现在我们来谈谈第四个挑战，我们的第四个挑战是容错性。那么容错性是什么呢？容错性的意思基本上是，如果系统中出现任何故障，之后系统能否恢复并继续正常运行，这就是所谓的容错性。容错性在那些长时间运行的工作流中非常重要。现在想想看，我们的这个招聘工作流就是一个长时间运行的工作流。自己想想看，首先我们创建了GD，然后发布，接着我们等待了七天，对吧？如果之后没有足够的申请，我们就进行修改，

然后我们还要再等两天，然后在这里我们安排时间，之后面试过程自己进行，之后发送了offer letter，那他什么时候会接受呢，入职可能需要很多天，所以你可以看到，这是一个长期运行的工作流程，可能会持续很多天，甚至几个月，所以在这种工作流程中出错的几率也更高，可能会出现两种错误，第一种错误是小的，比如在某个节点上出现了错误，比如你已经准备好了JD，现在你要去发布它，

但LinkedIn的API不工作了，现在这是一个小故障，对吧，第二个是大故障，您在AWS上部署这个工作流的服务器本身宕机了，那么理想情况下应该怎样呢，您应该能够从这两类故障中恢复，应该有这样一个系统到位，现在的问题是，如果您在LinkedIn中构建这个完整复杂的工作流，LinkedIn没有容错能力，这意味着如果您创建了一个由五个步骤组成的链，在到达第三步时，您的系统宕机了，出现了任何问题，那么您现在必须做什么，必须从头开始执行链。

因为LinkedIn内部没有容错的概念，对吧，而理想的容错意味着系统在崩溃的地方能够恢复，这一点你在LinkedIn中是找不到的。LinkedIn假设其链是短暂的，即一旦触发，完成工作后执行就结束了。因此他们认为容错不那么重要。但如果你谈到Langrath，Langrath提供了内置的容错机制，我来告诉你，Langrath在两种情况下都提供了容错能力。

如果你遇到任何小问题，或者如果你遇到任何大问题，那么在小问题的情况下，Langrath给你提供了重试的选项。所以，基本上，概念是这样的：假设你在这里创建了你的GD，现在你正在将其发布到LinkedIn的API上，而LinkedIn的API宕机了。那么，你可以在Langrath中编写这样的代码：如果出现任何错误，你可以捕获它，稍等一会儿，然后再次尝试。这就是我们所说的重试逻辑。通过重试逻辑的帮助，你可以处理任何小级别的故障，对吧？现在我们来谈谈大级别的故障，系统级别的故障，比如你的服务器宕机了，你的机器关机了。

那么在这种情况下会发生什么呢？Langraf中有一个恢复的概念。恢复的原理是这样的：假设你有一个这样的工作流程，你在执行过程中到达了这里，就在那时你的服务器宕机了，你的工作流程就停止了。那么在这种情况下你能做什么呢？你可以准确地从这个位置恢复，然后下一个要执行的节点将是这个，而不是第一个。这整个事情是如何实现的呢？我想你已经明白了，这里再次使用了检查点的概念。因为整个执行状态是完整的，意味着你一直在跟踪和保存整个时间状态，无论是在内存中还是外部数据库中。

基本上，你的基础在这里是持久层，我们会学习关于它的内容。如果你愿意，你可以将状态保存在外部数据库中，或者也可以保存在内存中。无论哪种方式，你的状态都会被持续跟踪并保存在某种内存中。你的Lang Graph所做的是，在每个节点执行后创建一个检查点，并在该节点执行后获取状态的快照，并将其存储在内存中。现在，如果在任何时候出现任何大问题，比如系统崩溃，你可以做什么呢？你可以从那里恢复你的图。实际上，有一个叫做“恢复”的函数，你只需要告诉它你之前的状态即可。

当系统出现故障时，它会自动识别状态，同时也能识别出问题发生在哪个节点以及下一个节点是什么，并据此从该点重新开始执行。因此，Lang Graph的容错能力非常高，其设计方式正是基于这一点。因为他们知道，任何复杂的工作流都可能是长时间运行的，而在长时间运行的工作流中，故障是肯定会发生的。因此，Lang Graph内置了重试和恢复的逻辑。伙计们，下一个重大挑战是“人在环路中”。

所以“人在回路”的意思是，假设你创建了一个工作流程，在这个流程的某个特定阶段，你需要人类做出某种决策。比如在我们的工作流程中，如果你看一下，当我们生成职位描述（JD）后，紧接着我们会让JD获得批准。这个批准是由谁来做的呢？这个批准是由驱动这个代理的人类来完成的。除非得到他们的批准，否则我们无法继续推进这个工作流程。还有很多其他的例子可以说明这一点。

例如，我们的代理或工作流程正在询问我们是否可以将JD发布到网站上。那么在这里，如果您愿意，也可以添加人工批准，这样在没有询问我的情况下，您将不会在任何网站上发布任何内容。您可以理解，在现实世界的场景中，每当您设计这样的工作流程时，在很多地方都会出现这样的范围，您会希望完全控制权不在代理手中，而是在人类手中。

因为在很多高风险的事情中，问责应该由人类承担，所以在工作流程中为人类设置的暂停点就被称为“人在回路”。现在，在任何工作流程中实现这一点都是一个挑战。如果你在Lang Chain中构建工作流程，那么这就变成了一个非常大的问题，因为Lang Chain中没有默认机制可以让链条暂停以等待人类批准，并在人类批准后恢复。你可以这样做：拥有一条很长的链条，在中间某个地方向人类请求输入。

但由于这是一个同步顺序链，所以要求短时间的输入是正确的。但如果您需要长时间运行，例如可能需要24小时才能获得经理的批准，那么问题在于您的脚本将在这24小时内一直处于这个状态，停滞不前，消耗您的计算资源，而且中间可能会出现一些问题导致崩溃。所以基本上还是同样的问题：长链并不适用于长时间运行的工作流程。

在短流程中，你可以要求人工输入，但如果人工审批可能需要很长时间才能完成，那么在这种情况下，你将无法在长链中实现这一点。一个方法是将你的大链分成两部分，假设这是一个大链，你需要在这一步获得人工审批，并且你知道人工审批可能需要一两天才能获得。

因为人类会进行全面分析，然后做出决策。那么一个方法就是将你的整个链条分成两部分：一部分成为你的这条链，另一部分成为你的那条链。这样执行到这里时，你会打断这条链，对吧？然后你去征求人类的批准。好的，当人类在一两天后批准时，你就可以启动这条新链，继续后续流程。再次，可能会有很多胶水代码和很多问题，可能会出现可维护性问题。好的，简而言之，人类参与其中。

默认情况下，长链中不存在。对于短期工作流程，您可以请求输入，但长时间运行是不可能的。然而，在长图中，您可以这样做。在长图中，人类参与循环实际上是首要考虑的因素，这意味着在构建这个框架时，他们明确添加了这个功能。事实上，如果您查看长图的文档，他们的文档中明确有一个关于“人类参与循环”的部分。

奥昌银行 是的 ROBIN 我怎么跟你解释呢 所以自己想想 我们学了一个保护的基础吗？我们朋友学了在管道的时代 发现了一些为什么它可以代表 约翰站立的节点就是保护的基础的愿望的实现的 国王 这个图来了或者可以这样呈现 这个节点本身就是一个图 所以本质上你 这里可以画所有的图 既然你可以画所有的图 所以你可以创建任何类型的嵌套工作流 现在你可能在想 嵌套工作流在哪里是一个非常实用的概念 如果你看看我们的例子 我们创建了一个自动招聘的工作流 在这里 如果你去到进行面试的部分 那么这里我们

他只是简单地写道：兄弟，把面试搞定就行了。但这件事本身就是一个非常复杂的任务。想想看，这里有很多事情在同时进行。首先，你在做什么？你正在根据每个候选人生成不同的问题，对吧？这是一项任务。然后，你要进行多轮面试——第一轮面试，然后是评估，接着是第二轮面试，再评估，然后是第三轮面试，再评估。所有这些都发生在一个单一的面试过程中。所以，你不觉得我们可以把“进行面试”当作一个独立的工作流程来对待，并将这个独立的工作流程与我们更大的工作流程连接起来吗？

可以做到，所以基本想法是，在一个工作流中你可以创建任意数量的其他工作流，而且我们将每个工作流都表示为一个节点，在我们实际的大图中。好的，我希望你能稍微理解一些。我再给你看一下文档。再次说明，这是一个单独的特性，你会在land graph的文档中看到它。这个特性非常重要。看这里，上面写着：子图是一个图。

这是一个作为另一个图中的节点使用的子图的简单定义。子图就是这样一个图，它在另一个图中被用作一个节点。比如这是一个大图，里面这个东西是一个单独的节点，但这个节点内部又有自己的一个图，明白吗？这是应用于土地图的封装概念。子图允许你构建由多个组件组成的复杂系统，而这些组件本身也是图，明白吗？

我希望你能理解，这里最大的挑战在于，内部有一个图，外部也有一个图，它们各自有自己的状态，那么这些状态之间如何互动，这正是你需要理解的。当我们继续深入学习时，我们会了解状态之间是如何进行通信的。现在你只需要明白，这在Lang Graph中是可能的，并且它有两个非常重要的应用场景。第一个非常大的应用场景是，你可以利用这个概念来构建多代理系统。

基本上，这是一个多个代理共同工作的系统。我给你举一个现实世界的例子，自动驾驶汽车就是一个很好的例子。在自动驾驶汽车中，基本概念是汽车自行行驶，显然，这需要一个智能系统来驱动它。因此，这个系统可能包含多个代理，比如一个代理负责收集和处理所有传感器的信息，另一个代理可能负责整个驾驶能力。

可能会有一个第三方代理来处理汽车的整个娱乐部分，然后可能还会有第四个代理，像CEO一样工作，它会协调所有这些代理的工作。因此，这种系统被称为多代理系统，而且非常有用。在未来，你会看到在很多地方部署多代理系统来解决复杂问题。所以，多代理系统。

如果你想创建，你可以使用land graph的这个功能，即子图功能。这是一个应用场景。第二个应用场景是，你可以将子图的可重用性带入画面。基本上，你可以使某个图变得可重用，并且可以在更大的图中的不同位置原封不动地使用同一个图。例如，假设你创建了一个用于审批的小图，那么在你的这个工作流程中，多个地方都需要审批，比如JD审批需要审批，JD发布需要审批，面试安排也需要审批。

需要批准才能进行，在很多地方都需要批准，那么我们该怎么办呢？我们会为批准创建一个单独的图表，一个单独的小型工作流程，然后在整个图表中重复使用它。因此，你可以通过子图表的帮助来实现这个可重用性的概念，这非常有益，对吧？就像你在编程中创建函数以便重复使用一样，同样的概念你也可以应用到工作流程中，你可以创建可重复使用的工作流程，这是你大型系统的一部分。

它会在不同的地方使用，所以这是两个非常重要的功能，你可以通过嵌套工作流或子图的帮助来实现。第一个是构建多代理系统，第二个是可重用性。显然，如果我们谈论LangChain，在LangChain中你找不到这个功能。当你尝试在LangChain内部构建这个工作流时，你会遇到困难。在LangChain内部再创建一个工作流是完全不可能的。所以，我一开始就说这不是LangChain的挑战，或者说这就是LangChain的挑战。

这是一个功能，你们在最后一项挑战中会遇到的，那就是可观测性。那么可观测性是什么呢？我写的是：可观测性指的是你在运行时监控、调试和理解工作流行为的难易程度。简单来说，当你运行工作流时，在运行过程中可能会出现各种问题，比如出现错误、工作流崩溃，或者工作流做出了你未曾预料到的决策。在这些情况下...

这非常重要，尤其是在生产环境中，当您已经部署了工作流程或代理并且用户正在使用它时，密切监控您的代理或工作流程在运行时的表现至关重要。这一功能为我们提供了可观测性，而这非常重要。想象一下，如果某个代理做错了什么，比如它在LinkedIn上发布了招聘广告并启动了广告，而且广告还没有限制地运行，导致花费巨大。那么事后审计时，您必须能够回溯查看具体原因。

采取了哪些步骤让代理觉得即使花多少钱也值得，因为它在审计中非常有帮助，在调试中也很有帮助。因此，可观测性整体上是一个非常重要的概念。好消息是，可观测性的概念在Lang Chain中也有体现。有一个叫做LangSmith的库，虽然我还没有教过你们，但我非常确定你们一定听说过它的名字。

Langsmith的正是这个目的，它用于监控基于LLM的应用程序。那么，你可以做什么呢？你可以非常轻松地将Langsmith与Langchain集成，一旦你完成这个集成，Langsmith就会非常密切地监控Langchain。例如，如果你在链中的某个特定步骤调用了LLM，Langsmith会记录这一点，它还会记录你向LLM发送了什么提示，以及LLM返回了什么回复，回复中有多少令牌。

回复花了多少时间，它会记录各种事情，以便你以后可以监控这个链条。只有一个问题，问题是Langchain只能——抱歉，Langsmith只能监控Langchain，不能监控你的胶水代码。所以如果你还记得的话，我在一开始就告诉过你，如果你想用Langchain构建一个非常复杂的工作流程，那么你将无法完全在Langchain中编写所有代码，你需要自己添加一些胶水代码，比如你需要运行一个循环。

那么你要运行自己的while循环，现在Langsmith的问题是它能追踪Langchain的代码，比如调用了LLM，这段代码它能追踪到，但它无法理解循环内部发生了什么，它无法理解我刚刚发送给LLM的消息是循环的哪一次迭代。所以基本上问题是Langsmith能追踪Langchain的部分，但无法理解胶水代码，这意味着当你用Langchain构建复杂应用时，只能获得部分可观测性。

你将无法获得完整的可观测性，而LangGraph很好地解决了这个问题。LangGraph与LangSmith有着非常紧密的集成。正如我所说，整个有状态的执行过程都在LangGraph内部完成。这样做的结果是，每一步都会被跟踪记录，比如你从这个节点跳转到那个节点，这个节点执行了，然后那个节点也执行了。整个事件的时间线都会被完美地记录在LangSmith中。事实上，LangGraph会自动将这些信息告知LangSmith。基本上，你掌握了所有相关信息。

每个节点的执行情况、状态发生了哪些变化、进入状态节点之前是什么样子、离开节点之后又是什么样子、我们与代理之间交换了哪些消息，这些都会被记录下来。此外，还会记录当人类进入循环并给予批准时，是在哪个具体节点上进行的批准。因此，基本上会形成一个完整的时间线，记录您运行时从工作流开始到结束的每一步。这样，您就可以回溯整个过程。

使用LangSmith，这是一个巨大的优势，我敢肯定你现在还没有完全理解，因为它看起来有点高级，但别担心，我只是想告诉你这样的东西是存在的。现在我们会更详细地学习它，当我们在这个播放列表中深入一点时，我会好好教你整个可观察性的概念。我会向你展示如何将LangSmith与LangGraph集成，以及整个集成是如何工作的，我会解释所有这些。现在你只需要明白，当你在生产环境中部署任何工作流时，

因此，从调试和审计的角度来看，密切监控它非常重要。但如果你在Lang Chain中构建了复杂的工作流程，你只能部分实现可观察性，无法完全实现，因为有很多粘合代码。但如果你使用Lang Graph来构建复杂的应用程序，由于没有粘合代码，所有代码都在Lang Graph内部完成，Lang Graph可以很好地告诉Langsmith等工具，我在每个点为什么做出这个决定。这样，调试对你来说就变得非常容易。这就是重点。

这就是我想向你解释的挑战，我真的希望我能解释清楚，如果你觉得太难了，别担心，先放一放，我们后面会详细讲解。那么，伙计们，现在我们来总结一下这个视频，回答一些问题，这也算是一种复习。我相信现在你应该已经理解了所有这些内容。第一个快速问题：什么是语言图？你在视频中已经详细学习过了，我在这里为你总结一下：语言图是一个编排框架，让你能够利用大语言模型构建有状态的、多步骤的、事件驱动的工作流程。

它非常适合设计单智能体和多智能体的AI应用程序。我真的希望在整个定义中你一个陌生的术语都没看到，好吧，把语言图想象成LLM的流程图引擎。你把步骤定义为节点，它们如何通过边连接以及控制转换的逻辑。语言图负责状态管理、条件分支、循环、暂停和恢复以及故障恢复。

构建强大、生产级AI系统所需的核心功能。相信我，这里用了很多专业术语，但我很确定如果你已经完整看完视频，这些术语对你来说都不会陌生，对吧？那么我希望你已经对Language Graph有了初步了解。其次，什么时候该用什么？什么时候该用Lang chain，什么时候该用Lang graph？当你需要构建简单的线性工作流时，比如提示链或摘要器，就该使用Lang chain。

或者你已经有了一个基础的RAG系统，在这种情况下Lang chain表现很好。当你需要构建复杂的非线性工作流时，比如需要条件路径、循环、人工干预环节、多智能体协调或协作，或者需要异步事件驱动执行，这时你就该使用Lang graph。所以，我真的希望当你明天接手某个项目并理解其需求时，也能同时明白自己应该用Lang chain还是Lang graph来工作。

或者使用Lang graph。我在视频开始时向你承诺过，到视频结束时，我会让你清楚Lang chain和Lang graph之间的区别，这样当你明天开始一个新项目时，你会自动明白应该使用Lang chain还是Lang graph。所以我真心希望我做到了这一点，好吗？最后但同样重要的一点，我们在这个视频中看到了很多关于Lang chain的缺点，也听到了很多关于Lang graph的赞美，那么这是否意味着我们应该放弃Lang chain呢？

仅仅专注于学习Lang graph？答案是否定的。你仍然需要使用Lang chain，因为Lang graph是建立在Lang chain之上的。Lang graph的设计初衷并不是为了取代Lang chain，而是为了能够解决更复杂的问题，但它仍然需要借助Lang chain来解决问题，明白吗？所以，即使你在构建非常复杂的工作流程，你仍然需要与LLM交互，仍然需要编写提示词，仍然需要加载文档。

那么所有这些组件，你现在仍然可以从Lang chain获得，chat open AI有了，prompt template有了，retriever有了，document loader有了，text splitter有了，tools有了，所有这些你在Lang chain中用过的东西，所有这些组件你现在仍然会使用，只是为了连接所有这些事物，为了编排它们，你使用Lang graph，所以Lang graph是完全不同的，Lang chain有它自己的目的，Lang graph有它自己的目的，如果你想构建复杂的工作流程，那么你就使用Lang graph。

那么Lang graph是用来，你知道的，串联或编排一个框架，或者编排一个工作流程，它不是用于组件的，所以两者会相辅相成，接下来你也会在这个播放列表中看到，当我们构建任何代理或工作流程时，我们会同时使用这两样东西，我们会使用Lang chain，也会使用Lang graph，所以不要担心你在学习Lang chain上所付出的努力，那些都不会白费，它们也会派上用场，而你正在学习的这个新东西，也会对你有所帮助。

所以我真心希望，经过这么长时间，我向你们解释的Lang chain和Lang graph之间的区别，你们能够理解。同时，你们也对Lang graph有了一个很好的介绍，并且能够看到一个大的图景，明白这个库为什么存在。在我看来，这非常重要，除非你们理解了“为什么”的答案，否则在接下来的视频中你们不会感到有趣。所以我真心希望，现在你们感到受到了启发，并且期待着即将到来的视频。好了，如果你们喜欢某个视频，请点赞。如果你们还没有订阅这个频道，请订阅。我们下个视频见，再见。
