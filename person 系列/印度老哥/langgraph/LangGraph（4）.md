
大家好，我叫 Nitesh，欢迎来到我的 YouTube 频道。在这个视频中，我们将继续我们的“使用语言图的Agentic AI”播放列表。今天的视频是这个播放列表的第四个视频。如果你还记得的话，在上一个视频中，我们做了一个非常详细的比较，比较了 LangChain 和 Lan Graph，在那里我还稍微介绍了一下LangGraph 是什么，它的核心能力是什么，以及什么时候你应该使用 LangChain。今天的视频将完全专注于 LangGraph。

在今天的视频中，我将要做的是向你们介绍LangGraph中的一些核心概念，这些概念你们在任何地方都能看到。我会让你们提前了解这些概念，这样你们就能轻松掌握所有概念，并实际将它们转换为代码。所以请务必看完这个视频到最后，如果可能的话，做好笔记。因为在实践之前，你们需要先通过预览了解一下LangGraph到底是什么。如果你们还记得上一个视频，我在那里详细比较了LangChain和LangGraph之间的区别，并在同一个过程中向你们解释了LangGraph是什么以及它的核心功能是什么。所以在我们开始之前，让我们先总结一下所有这些内容。

好的，如果用简单的语言来解释Lang Graph，它本质上是一个编排框架。这是什么意思呢？意思是如果你给Lang Graph一个LLM工作流程去执行，Lang Graph首先会尝试将该工作流程以图表的形式呈现出来，就像这样。这个图表的最大特点是什么？就是图表中的每个节点都代表你工作流程中的一个任务，明白吗？

现在LLM工作流中可以包含多种任务。一个任务可能是调用LLM，第二个任务可能是调用某个工具，第三个任务可能是做决策。那么Lang Graph在这里做了什么？它理解了你的工作流，然后将这个工作流转化为一个图的形式。这个图的构造方式是，每个节点都是你整个工作流中的一个子任务。最棒的是，所有这些节点都通过边相互连接。这些边告诉我们，在执行完某个特定节点或任务后，接下来应该执行哪个任务。简单来说，Lang Graph 为您提供了一个功能，通过这个功能，您可以将任何LLM工作流首先以流程图的形式呈现出来，然后还可以执行它。一旦您创建了这个图表，接下来您需要做的就是为它的第一个节点提供输入，并触发这个工作流或图表。然后会自动发生什么呢？所有节点将按照正确的顺序依次执行，您的工作流也就完成了。这里写的正是这一点：LangGraph是一个用于构建智能的编排框架。

有状态和多步骤的LLM工作流程。现在，LangGraph不仅仅局限于创建图表。它还为您提供了额外的功能，例如在这里，如果您愿意，可以执行并行任务，就像您在这里看到的那样，一个节点之后，接下来的两个节点将同时执行。如果您愿意，可以实现循环的概念，在这个节点之后，您可以返回到前面的节点，并且您可以在循环中完成这项工作。您还可以进行分支，在这个节点之后，根据某个条件，要么这个节点执行，要么那个节点执行。同时，您还可以获得内存的功能，即在这里执行的所有任务。

无论进行什么对话，您都可以记录下来，而且在这里您还会获得恢复功能，也就是说，如果某天某个任务中您的整个工作流程中断了，您可以从同一点恢复。因此，结合所有这些核心功能，可以说Langrath是构建代理和生产级AI应用的理想选择。好的，这就是我们在上一个视频中讨论的内容。如果您还没有观看上一个视频，我建议您去看一看。

因为在那里我们通过一个真实世界的用例来帮助理解为什么需要Langrath，我在那里向你们介绍了Langrath的7个核心功能，所以不可能再重复覆盖所有内容，但如果你们观看那个视频，一切都会变得清晰。所以现在既然你们已经了解Langrath是什么，接下来我们将逐一研究Langrath的一些核心概念，在学习了这些概念之后，你们将能够编写任何类型的工作流程。那么，首先我们要讨论的第一个概念是，

那就是LLM工作流程。刚才我向你们解释了定义Langrath的过程，提到Langrath是一个编排框架，借助它你可以构建任何类型的LLM工作流程，对吧？所以我认为我们需要稍微关注一下这个特定术语，即LLM工作流程到底是什么。首先，我们来谈谈工作流程是什么。你可以将工作流程定义为实现目标而执行的一系列任务。

例如，我们在上一个视频中看到的自动化招聘示例，我们需要执行一系列步骤来雇佣一个人。首先，我们需要创建职位描述，然后发布它，接着进行筛选，再进行面试，最后进行入职。只有当你按照正确的顺序执行这一系列步骤时，整个招聘流程才算完成。简单来说，你可以将工作流程视为一系列任务，通过按正确顺序执行这些任务来实现一个目标，这就是工作流程。那么，什么是LLM工作流程呢？LLM工作流程是一种工作流程，其中整个系列的任务中...

有很多任务都依赖于LLM（大型语言模型），比如我们之前提到的自动化招聘例子就是一个LLM工作流程。为什么呢？因为其中涉及多个需要LLM的任务环节：在撰写职位描述的流程中会用到LLM，在筛选候选人的流程中可能需要LLM，在面试环节中也可能需要使用LLM。简而言之，任何在执行阶段运用LLM的工作流程，我们都可以称之为LLM工作流程。

好的，看看这里，我已经写了一些东西，你可以浏览一下。LLM工作流程是一个逐步的过程，通过它我们可以构建复杂的LLM应用程序。工作流程中的每一步执行一个独特的任务，比如提示、推理、工具调用、内存访问或决策制定，对吧。而且工作流程可以是线性的、并行的、分支的或循环的，允许复杂的行为，如重试、多代理通信或工具增强推理。好的，所以我真的希望你能对LLM工作流程是什么有一点概念。现在说实话，每个应用程序都会有自己独特的工作流程，对吧。

你的自动招聘会有不同的工作流程，去自动化呼叫中心会有不同的工作流程，所以工作流程总是不同的。但有一些工作流程，你会在不同的地方看到，这些是常见的工作流程。那么，我来告诉你一些常见的工作流程，你会在很多地方看到它们。在这个特定的语言图谱播放列表中，我也会为你展示这些常见的工作流程，好吗？那么，让我们开始吧，从第一个常见的工作流程开始，这是最常见的LLM工作流程。

它的名字叫Prompt Chaining，在LLM的世界里是一个非常常见的工作流程，到处都能看到。基本上，你做的事情就是多次与LLM对话或调用LLM，就像你在这个流程图中看到的那样。在整个工作流程中，你一次、两次、三次地与LLM按顺序对话。这种工作流程的一个例子可能是，假设你正在开发一个应用程序，用户会给你一个主题名称，你需要基于该主题撰写一份详细的报告。现在你不能直接从主题开始写详细报告，相反，你会怎么做呢？你会把整个任务分解开来。首先，你会做什么？你会根据主题准备一个提纲，然后借助提纲来准备报告。所以现在你在做什么呢？你在某种程度上是在进行提示链式操作。你的主题来了，你在进行提示链式操作，将你的主题发送给第一个LLM，并告诉它绘制大纲。当大纲绘制完成后，你再将大纲发送给第二个LLM，并告诉它基于这个大纲打印一份详细报告。这样你就使用了提示链的概念，适用于处理复杂任务时。

你想把任务分成子任务吗？而且好处是，在整个过程中，你可以时不时地加入检查点，看看你的流程是否正常运行。比如在这里你可以看到，我们在这个LLM调用的输出上设置了一个检查点。在我们的用例中，一个检查点可能是我们的报告不应超过5000字。如果超过5000字，我们就会退出。这是一个非常常见的工作流程，你会在很多地方看到。我真的希望你已经理解了提示链。第二个是非常著名的LLM工作流程，我们称之为路由。



so routing में क्या होता है कि आप basically एक task को समझते हो और फिर यह decide करते हो कि उस task को कौन execute करेगा ठीक है थोड़ा abstract तरीके से मैंने बोला पर एक example के थूँ मैं आपको समझाता हूँ माल लो आप customer support के लिए chart board बना रहो तो इसको एक query मिलेगी customer की तरफ से अब query कुछ भी हो सकती है query हो सकती है कुछ technical platform के बारे में या फिर refund से related या फिर sales से related किसी भी तरह की query हो सकती है तो ये query हमारे LLM के पास आई अब हमारा LLM ये decide करेगा कि ये refund related query है या technical doubt related query है या sales related query है अगर refund related query है तो वो इस particular LLM के पास route कर देगा आपके request को अगर technical doubt है तो second वाले के पास भेज देगा अगर sales related doubt है तो third वाले के पास भेज देगा तो basically ये जो LLM है ये एक decision maker की तरह काम कर रहा है जो ये decide कर रहा है कि इन तीनों में से कौन सा LLM इस query को solve करने के लिए सबसे capable है ठीक है तो in a way this particular LLM call is working as a router ठीक है तो ये भी एक pattern है जो आगे चल के बहुत सब देखने को मिलेगा अलग-अलग workflows जब आप build करोगे तो इसमें ये छोटा सा routing pattern आपको use करना पड़ सकता है तो I hope आपको अभी तक के दो LLM workflow समझ में आगे prompt chaining and routing अब बात करते हैं next workflow की next LLM workflow है paralyzation नाम से भी आपको समझ में आ रहा होगा इस particular workflow में आप क्या करते हो कि आप एक given task को break down कर देते हो into multiple sub tasks और फिर आप उन सारे के सारे sub tasks को एक साथ execute करते हो और उन सब के result को फिर आप merge करके final outcome निकाल के देते हो ठीक है? so एक example लेते हैं माल लो आप YouTube जैसे platform के लिए एक content moderation workflow बना रहे हो content moderation workflow का मतलब है कि YouTube पे जैसे ही कोई वीडियो publish होती है तो YouTube पहले उस वीडियो को चेक करता है कि क्या वो वीडियो appropriate है कि उसको लोगों के सामने live किया जाए क्या उसमें कुछ गढबर तो नहीं है तो हम YouTube के लिए वही content moderationation platform बना रहे हैं ठीक है तो content moderation के लिए आपको same वीडियो को multiple angle से चेक करना पड़ता है जैसे कि आप सबसे पहले चेक करते हो कि क्या वो वीडियो YouTube की community guidelines को follow कर रहा है या नहीं second angle यह हो सकता है कि आप यह चेक करो कि क्या उस वीडियो में किसी तरीके का misinformation तो नहीं है और third angle हो सकता है कि आप यह चेक करो कि क्या उसमें कुछ sexual content तो नहीं है अगर यह तीनो checks वीडियो pass कर लेगा तब ही हम उस वीडियो को live करेंगे otherwise हम उसको flag कर देंगे ठीक है तो यहां पे हमने क्या किया कि अपने content moderation task को तीन sub task में डिवाइड कर दिया हमें यह चेक करना है कि वीडियो live करना चाहिए कि नहीं और यह चेक करने के लिए हमें यह तीन चीज़े चेक करनी है अब मज़े की चीज़ क्या है कि यह तीनो चीज़ों को आप परलेली चेक कर सकते हो ऐसा नहीं है कि misinformation चेक करने के लिए आपको पहले से यह पता होना चाहिए कि वीडियो ने community guidelines follow की या नहीं या फिर sexual content है या नहीं यह पता करने के लिए आपको पहले से पता होना चाहिए कि misinformation है या नहीं यह तीनो task परलेली किये तो इस case में आप क्या करोगे माललो अगर आप यह task कुछ से कर रहे हो तो आप वीडियो का content उठाओगे उसका transcription generate करोगे और उसको first LLM के पास भेज दोगे first LLM चेक करेगा कि क्या वो video सारे के सारे community guidelines follow कर रहा है की नहीं second LLM चेक करेगा कि मिस information है की नहीं थर्ड वाला चेक करेगा कि sexual content है की नहीं और फिर यह तीनो अपने-अपने result इस aggregator को भेजेंगे और फिर यह aggregator उन तीनो result के basis पे decide करेगा कि वीडियो publish होना चाहिए या फिर नहीं तो यह एक बहुत अच्छा example है parallelization workflow का और यह भी एक ऐसा pattern है जो आपको कई जगों पे देखने को मिलेगा और हम भी इस playlist में इसके उपर काम करने वाले हैं हमारा जो अगला LLM workflow है उसका नाम है orchestrator worker workflow अब honestly यह particular workflow बहुत similar है parallelization workflow के जो हमने just इसके पहले पढ़ा which means यहाँ पे भी आपको एक task को multiple parallel sub task में divide करना होता है ठीक है the only difference is कि orchestrator worker में आपको पहले से इन sub task का nature नहीं पढ़ा होता है यह dynamically decide होता है जैसे parallelization में क्या हो रहा था आप youtube वाले example में आपको पहले से पढ़ा था कि आपका first वाला LLM वीडियो को community guidelines के basis पे judge करेगा second वाला LLM misinformation के basis पे judge करेगा और third वाला LLM sexual content के basis पे judge करेगा तो यह पहले से pre defined है but orchestrator worker वाले में पहले से पढ़ा नहीं होता कि first LLM क्या काम करेगा second क्या काम करेगा third क्या काम करेगा for example आप एक research assistant बना रहो जिसका काम होगा कि एक given query के उपर एक detailed research report बनाना ठीक है अब इस research report को बनाने के process में सबसे पहले हमारे system को क्या करना पड़ेगा कि multiple जगहों पे multiple platforms पे जा करके उस term को search करना पड़ेगा और फिर जितना information आ रहा है उसको aggregate करके एक report generate करनी पड़ेगी but search कहाँ पे करना है और क्या search करना है ये इस बात पे depend करेगा कि आपकी query क्या है for example अगर आपकी query कोई scientific term है या फिर कोई technical term है तो ऐसा हो सकता है कि आप अपने first LLM को जा के बोलो google scholar पे जा के search करने जहाँ पे आपको research papers मिलते हैं right, where as अगर आपका search term कोई social phenomena है या फिर कोई political incident है तो फिर there is a chance कि आप अपने LLM को बोलो कि जा करके google news पे जा के search करो right, तो यहाँ पे क्या हो रहा है कि based on the input query क्या search करना है कहा search करना है यह बहुत vary कर जा रहा है जो sub task है यह बहुत vary कर जा रहा है तो यह जो decision making है यह करने के लिए यहाँ पर एक orchestrator बोलके LLM होता है तो जैसे ही search query आती है तो orchestrator उसको analyze करता है और वो decide करता है कि हर worker's क्या काम मिलेगा तो depending on the input query orchestrator हर worker LLM को अलग task assign कर सकता है ठीक है तो यही सबसे बड़ा difference है यहाँ पे भी चीज़े parallely हो रही है एंड में जाके उनका result aggregate हो रहा है बट पहले से हमें नहीं पता है कि task का nature क्या होगा वो depending on the input query vary कर सकता है ठीक है तो यह भी एक बहुत important pattern है बहुत important workflow है जो future में आपको देखने को मिलेगा और hopefully इस playlist में हम इसको भी cover करेंगे और जो last common workflow है उसका नाम है evaluator optimizer यह एक बहुत interesting workflow है यहाँ पे क्या होता है कि आपको एक task दिया जाता है और इस task को एक बार में perfectly execute नहीं किया जा सकता for example आप चाहते हो कि आपका system आपके लिए एक email draft करे but there is a good chance कि first time में आपको आपका perfect email ना मिले या फिर आप चाहते हो कि आपका system आपके लिए एक blog बना के दे किसी topic के ओपर तो again कोई guarantee नहीं है कि one go में जब आप अपने LLM को बताओगे कि मुझे इस topic के ओपर blog चाहिए तो वो आपको best blog बना के दे देगा because इस तरह की जो चीज़े हैं जहांपे आप email draft कर रहे हो या blogs लिख रहे हो या poems लिख रहे हो या stories लिख रहे हो ये थोड़ा सा creativity का काम है और इस में iteration लगता है मतलब खुछ सोचो न कोई जो poet होता है या कोई writer होता है जब वो कुछ लिखता है न तो वो iteration में लिखता है वो पहला draft लिखता है फिर उसमें देखता है कि क्या कमी रह गई फिर उस कमी को feedback बना करके दूसरा draft बनाता है फिर ये process वो loop में करता चला जाता है तो 5-6 steps के बाद उसको final अपना अच्छा product मिलता है तो ये same workflow आप execute कर सकते हो with the help of evaluator optimizer workflow यहाँ पह आपके बास दो LLMs होते हैं एक होता है आपका generator LLM और एक होता है आपका evaluator LLM so आप यहाँ से अपना task बताते हो कि मुझे blog लिखना है या email लिखना है तो ये first वाला जो LLM है ये आपको एक blog generate करके देगा जिसको हम solution बुलाते हैं अब इस solution को हम evaluator के पास भेजते हैं और evaluator को हम एक concrete evaluation criteria बताते हैं और उस criteria के basis पे वो क्या करता है आपके solution को या तो accept करता है या तो reject करता है अगर reject करता है तो एक feedback भी देता है तो अगर आप reject हो गए और आपको एक feedback मिला तो आपका generator क्या करेगा उस feedback के basis पे फिर से नया solution generate करेगा और ये अपनी जीज़ loop में होते जाती है until evaluator satisfy हो जाए उसको लगे कि हाँ भाई अब जो solution आया है ये सही है और वो उसको accept कर ले तो फिर ये loop break हो जाता है और आपको आपका output मिल जाता है तो ये एक बहुत interesting workflow है और जब मैं आपको loops के बारे में पढ़ाओंगा लैंग ग्राफ में उसके ठीक बाद मैं आपको ये particular workflow बना के दिखाओंगा it's very interesting ठीक है तो I hope आपको nutshell में समझ में आगया LLM workflows क्या होते हैं और जो common workflows हैं वो मैंने आपको सारे के सारे बता दिये पांच अलग लग workflows and in this playlist I will try to cover all of these ठीक है अगला core concept जो हम discuss करने जा रहे हैं वो है graphs, nodes और edges का concept and trust me guys ये तीनो मिला करके आप कह सकते हो कि LANGRAPH का सबसे important core concept है ठीक है तो अगर आपको याद होगा वीडियो के शुरुवात में जब मैंने define किया था कि LANGRAPH क्या है तो वहाँ पर मैंने आपको बताया था कि LANGRAPH is an orchestrator framework जो किसी भी LLM workflow को graph के form में represent करता है that is why आपको ये समझना बहुत ज़रूरी है कि कैसे LANGRAPH किसी भी workflow को किसी भी LLM workflow को graphs के form में represent करता है ये पुरीचे समझाने के लिए let's take an example, example बहुत होगा तो शायद आपको ये भी बता होगा कि UPSC में Mains exam के टाइम पे जो Candidates होते हैं उनको एक या दो essays लिखने होते हैं और ये essay actually बहुत weightage carry करते हैं उस Mains exam में और इसको crack करना बहुत important माना जाता है in order to crack UPSC तो what we are doing is let's say we are building a website जहाँ पे हम जो भी UPSC aspirants हैं उनको ये essay लिखने का practice कर वा रहे हैं ठीक है so we have a website जहाँ पे जैसे ही कोई user आएगा हमारा website उसको एक essay topic generate करके देगा उसके बाद वो बन्दा क्या करेगा उस topic के ओपर essay लिखेगा हमारी website के ओपर essay लिखेगा टाइप करके वो अपना essay submit करेगा और हमारी website उस essay को multiple perspective से analyze करेगी evaluate करेगी और एक score generate करेगी अगर score cut off से जादा हुआ तो हम उसको congratulate करेंगे अगर score उसका cut off से कम हुआ तो हम उसको feedback provide करेंगे और फिर हम उसको option देंगे कि feedback के basis पे अगर वो चाहे तो दुबारा से essay लिख सकता है और फिर हम उसको दुबारा evaluate करेंगे यह पूरी चीज बैसिकली हम iteration में perform कर रहे हैं तो मालों यह LLM workflow आपको बनाना है अब इसमें LLMs की ज़रूरत पढ़ेगी multiple जगों पे तो मालों हमें यह LLM workflow बनाना है तो हम कैसे बना सकते हैं using land graph सबसे पहले तो आपको इस high level goal को कि आपको इस तरह की एक website बनानी है उसको first of all actionable steps में convert करना पड़ेगा actionable steps क्या है step 1 topic generate करना step 2 जो essay उसने लिखा है student ने वो आप collect कर लो step 3 evaluate करना step 4 multiple perspective से आपने चेक किया है तो उन result को aggregate करना उसके बाद बताना की उसका result उसका essay अच्छा था या खराब था उसके बाद feedback देना उसके बाद अगर वो चाहे तो दुबारा revised ऐसे लिख सकता है यह पूरा flow हमें सबसे पहले copy pen पर लिखना पड़ेगा एक बार जब आप लिख लो तो अब आप इस flow को actually land graph की help से एक graph के form में represent कर सकते हो ठीक है तो मैं आपको दिखाता हूँ मैंने already ये flow बना रखा है so this is the flow the same flow जो हमने अभी discuss किया but this time it is in the form of a graph ठीक है so you can see topic ठीक generate हो रहा है सबसे पहले उसके बाद user essay लिख रहा है हम उस essay को collect कर रहे हैं और ये step में हम उसको evaluate कर रहे हैं तीन चीज़ों के basis पे clarity of thought कितना है essay में depth of analysis कितना है fact check वगरा कर रहे हैं और language कैसा है essay का vocabulary कितना strong है grammatical mistakes तो नहीं है tonality कैसा है ये सब पुछ हम चेक कर रहे हैं और तीनों चीज़ों के basis पे हम उसको normalize score दे रहे हैं पाँच के उपर तो total हम 15 marks पे उसको evaluate कर रहे हैं और मालो threshold हमने रखा है दस number का तो final evaluation ये रहेगा कि अगर आपका score दस से जादा है तो successful हम congratulate करेंगे हमारा flow end हो जाएगा और अगर दस से नीचे है तो हम उसको बताएंगे the essay was not up to the mark और हम उसको feedback देंगे तीनों चीज़ों के basis पे कि क्या गलती हुई और फिर उसको option देंगे कि तुम दुबारा essay लिखना चाते हो अगर वो बोलेगा no तो फिर से flow end हो जाएगा अगर वो बोलेगा yes तो हम वापस यहाँ पे आ जाएँगे और यह पूरा flow फिर से execute होगा अब सबसे पहले आप ये देख सकते हो कि इस तरह के किसी भी flow को आप बहुत आसानी से graph के form में represent कर सकते हो this is the first observation that you should have second आप इस ग्राफ को अगर देखो तो इस ग्राफ में आपको दो चीज़े दिखाई देंगी first दिखाई देगा node as in nodes और second आपको दिखाई देगा edges ठीक है अब मज़ेदार चीज़ क्या है कि यहाँ पे हर जो node है वो actually आपके workflow का एक single task को represent करता है तो लैंग ग्राफ exactly यही कर रहा है जब वो ग्राफ बनाता है तो ग्राफ बनाने के process में हर node एक single task को represent करता है अब आप सोचोगे कि behind the scenes यह node है क्या तो लैंग ग्राफ में हर node behind the scene एक python function है that's it उससे ज़ाधा कुछ भी नहीं है अगर आपको python function लिखना आता है तो आप यह node भी create कर सकते हो तो essentially अगर आप देखो तो लैंग ग्राफ में जो ग्राफ बनता है it is essentially a set of python functions जो आपस में interconnected है with the help of edges, edges हमें यह बताते है कि किसी particular node के execute होने के ठीक बाद next कौन सा node execute होगा ठीक है तो in short nodes हमें बता रहे हैं कि करना क्या है और edges हमें बता रहे हैं कब क्या करना है ठीक है when to execute a node अब edges भी आपके कई तरीके के हो सकते हैं आपके sequential edges हो सकते हैं जहांपे एक के बाद दूसरा आ रहा है आपके parallel edges हो सकते हैं जहांपे एक साथ तीनो चीज़े तोनो चीज़े जितनी भी हैं execute हो रही है आपके पास conditional edges भी हो सकते हैं जहांपे आप branching perform कर रहे हो मतलब या तो इस direction में flow जाएगा या तो इस direction में flow जाएगा या फिर आप loop भी करवा सकते हो so you can see ये graph के structure में इस पूरे workflow को represent करने का फाइदा क्या है कि हर node आपके task को represent कर रहा है उनके बीच में flow of execution कैसा होगा ये edges represent कर रहे हैं और उसमें भी आप अलग अलग type का flow express कर पा रहो sequential flow भी express कर पा रहो


कर पारेओ, ब्रांचिंग भी एक्सप्रेस कर पारेओ, लूपिंग भी एक्सप्रेस कर पारेओ ये सारी चीज आपको लैंग ग्राफ प्रोवाइड कर पारेओ बिकोस ग्राफ का जो स्ट्रॉक्चर है वो आपको ये फ्रीडम प्रोवाइड करता है तो मैं आपको समझा पाया कैसे लैंग ग्राफ किसी भी एलेलम बेस्ट वर्कफलो को बहुत आसानी से ग्राफ में कनवर्ट कर पाता है और कैसे उस ग्राफ में हर नोड एक टास्क को रिपरिजेंट करता है और एजेस फ्लू अफ एग्जिक्यूशन को रिपरिजेंट करते हैं अवविसली ये जो पुरी चीज मैंने आपको पढ़ाई ये बहुत प्राक्टिकल चीज है और इसको आप टूली तब अपरिशेट कर पाओगे जब आप कोड लिखोगे और बट फिलाल मुझे आपको एक कॉंसेप्ट्शल ओवरव्यू देना था आई रिली होब ये पर्टिकुलर पार्ट क्लियर है नेक्स्ट वीडियो में हम लोग अपना फर्स्ट वर्कफलो बनाएंगे वहाँ पर आपको दिखाई देगा ये जो भी आपने पढ़ा अभी उसको आप कितनी आसानी से लाइन ग्राफ में एक्स्प्रेस कर सकते हो जो अगला कॉर कॉंसेप्ट हम डिसकस करने जा रहे हैं उसका नाम है स्टेट और त्रस्ट मी ये बहुत इंपॉर्टने कॉर कॉंसेप्ट है तो सबसे पहले समझते हैं कि स्टेट होता क्या है अगर आप किसी भी LLM वर्कफलो की बात करों तो उस वर्कफलो को अपना execution complete करने के प्रॉसस में कुछ pieces of data का requirement होता है जो उसको throughout execution help करता है For example, हमारा ये UPSC वाला LLM workflow है यहाँ पे इस workflow से related कुछ data points ऐसे हैं जो आपको throughout the execution जरूरी, मतलब required है For example, आपका candidate जो essay लिख रहा है ये एक ऐसा piece of information या data है जो आपको throughout the execution चाहिए होगा, it's required सोच के देखो, आपको जब evaluation perform करना है तो आप evaluation किस चीज़ में perform करोगे इसी essay text के उपर Similarly, जो आप score calculate कर रहे हों यहाँ पे, यहाँ पे, और यहाँ पे ये भी ऐसा piece of information है जिसके basis पे आगे का execution depend करता है Because, इन scores के basis पे आप एक final score calculate कर रहों और फिर उस final score के basis पे आप ये decide कर रहों कि उस बंदे का essay अच्छा है या फिर खराब है So, what I am trying to say is कोई भी NLM workflow जब आप बनाने जाओगे तो उस workflow को चलाने के लिए logically execute करने के लिए आपको कुछ pieces of information चाहिए होता है और उस information की खासियत क्या है कि वो over time evolve होता रहता है उसमें changes आते रहते हैं जैसे कि यहाँ पर देखो आप मानलो user जो भी essay लिख रहा है उसको कहीं पर store कर रहे हो in a variable अब कल को ऐसा होगा कि वो fail कर गया essay उसका essay उतना अच्छा नहीं है और वो दुबारा से essay लिखना जाता है तो हम वापस आके उससे essay लिखवा रहे हैं और जो नया essay है उसको हम वापस उसी variable में store कर रहे हैं तो basically उस variable का जो content है वो over time evolve करते रह रहा है सिमिलरली यहाँ पर जो उसका score है वो भी change होता रहेगा जैसे जैसे execution आगे बढ़ रहा है आपके workflow का तो यह जो data है आपके workflow से related जो first of all execution के लिए required है second जो over time evolve होता है जैसे जैसे आपका execution आगे बढ़ता है इसी को हम state बुलाते हैं ठीक है यहाँ पर लिखा हुआ है in Landgraft state is a shared memory that flows through your workflow it holds all the data being passed between nodes as your graph runs. So Landgraft में एक बहुत critical component है जब आप Landgraft में कोई भी graph बनाने जाते हो तो वो graph बनाने के पहले Landgraft आपको बोलता है कि आप पहले अपना state define करो और उस state में आप key value pair के form में सारे के सारे data points add करो जैसे की हमारे इस particular workflow में क्या-क्या data points हो सकते हैं essay का text एक data point हो सकता है essay का topic एक data point हो सकता है depth के लिए उसको कितना score मिला language के लिए उसको कितना score मिला clarity के लिए उसको कितना score मिला overall score क्या है वो सब कुछ एक-एक data point है जो आपके execution को चलाने में help करेगा और over time evolve करेगा अब state से related सबसे powerful बात यह है कि at any moment आपके हर node के पास इस state का access है तो जब कोई भी particular node execute हो रहा है तो उसको execute होने के time पे first of all input में यह पूरा का पूरा state दिया जाता है फिर यह node अपना execution perform करता है और वो इस state में changes करता है और फिर यही state वो आगे भेजता है अगले node के पास फिर अगले node को same state as input मिला उसमें उसने changes किये और जो भी changes हुए changed state वो आगे भेज रहा है तो हो क्या रहा है कि यह जो state है यह first of all shared है between all nodes second यह mutable है so यह सारे के सारे nodes उसमें changes कर सकते हैं और जैसे जैसे आपका execution आगे बढ़ रहा है वैसे वैसे यह जो state है यह evolve कर रहा है right और यही सबसे बड़ी खासियत है state की अब एक last question आपके दिमाग में शायद आ रहा होगा कि code में यह state बनाया कैसे जाता है so बहुत simple है यह actually एक special dictionary होती है जिसको हम typed dictionary बुलाते हैं यह basically python में class है तो आप इस class का एक object बनाते हो और object में आप यह सारे fields add करते हो आप चाहो तो pydantic object भी बना सकते हो but mostly typed dictionary यूज़ होती है तो कुछ special नहीं है it's just a type of dictionary जो आपके code में हमेशा available है हर node के पास ठीक है and again I'll say this it is a very very important concept जो आगे आप बहुत use करोगे जब आप code लिखोगे ठीक है तो please make sure आपको यह पूरी चीज़ समझ में आगए हो जो अगला core concept हम discuss करने जा रहे हैं उसका नाम है reducers और यह बहुत closely connected है state के concept के साथ so अगर आपको याद होगा थोड़ी दर पहले मैंने आपको state के बारे में दो important चीज़े बताई थी पहला यह कि जो state होता है आपका वो accessible होता है to all the nodes आपके graph में जितने भी nodes हैं वो सब के सब आपके complete state को as in सारे key value pairs जो state के अंदर हैं सब को access कर सकते हैं second state जो होता है वो mutable होता है which means कि कोई भी node जा कर कि आपके state में changes कर सकता है अब एक scenario वो देखते हैं scenario यह है कि हम एक बहुत basic सा workflow design कर रहे हैं जहाँ पर हमें input में दो numbers दिये जा रहे हैं फिर हम उन दो numbers के बीच में sum perform कर रहे हैं और फिर हम जो भी result आ रहा है उसको 2 से multiply कर रहे हैं और result print कर के दे रहे हैं अब माललो यह workflow आपको अपने state में क्या क्या key value pairs add करोगे I guess आप थोड़ा भी सोचोगे तो आपको समझ में आ जाएगा कि यहाँ पे 3 important data points हैं जो आपकी workflow को चाहिए होंगे अपना काम करने के लिए पहला है first number दूसरा है second number और तीसरा है result अब क्या होगा कि जैसे ही क्या क्या क्या क्या क्या क्या क्या क्या क्या क्या क्या क्या क्या क्या क्या क्या क्या क्या क्या क्या क्या क्या कि sum ने result की एक value लिखी which was 11 और अगले node ने उसको अपडेट करके उसके बदले 22 लिख दिया because this value is mutable और यही होता है Multiple nodes, same value के उपर updates कर सकते हैं और update करने का मतलब होता है पिछला value हटा के नएया value रख देना अब most of the cases में यह पूरा का पूरा flow जो है वो चलेगा कोई problem नहीं है इसमें But there are certain scenarios जहांपे यह जो update करने का feature है state को यह आपको फाइदा ना पहुंचा के उल्टा नुकसान पहुंचा दे For example, अगर हम एक और flow की बात करें जहांपे मानलो हम एक simple chatbot बना रहे हैं अब chatbot में पूरा का पूरा workflow कैसा देखेगा कि एक human होगा और एक llm होगा और यह दोनों एक दूसरे से बात करेंगे in loop ठीक है तो यही हमारा workflow है अब अगर आप से पूछा जाए कि इस workflow से related state क्या होगा तो again इसका state बहुत simple है आप simply यहांपे message बोल करके एक key value pair रखोगे ठीक है तो अब जब execution start हुआ आप human node पे आए तो human ने let's say बोला hi my name is नितिश तो यह node क्या करेगा इस state में जाके update कर देगा hi my name is नितिश अब क्या हुआ यह state llm के पास as in llm वाले node के पास पहुँचा और llm वाले node ने इस message को देखके reply किया hi how can i help you hi how can i help you ठीक है अब वापस flow पहुँचा इस node के पास अब इस node के पास यह state है अब human ने फिर से क्या पूछ लिया can you tell me my name तो basically यह हट गया और यह आ गया है अब फिर से हम llm वाले node के पास पहुँचे और अब मेरे पास यह information है अब llm इस message को देखके कभी भी नहीं बता सकता कि user का नाम क्या था क्योंकि वो message जो आया था जहांपे user ने अपना नाम बताया था वो erase हो गया state से तो इस scenario में आपका यह जो update करने का policy है state को update करने का policy है वो actually fail कर जा रहा है chatbot जैसे scenario में ideally आपको क्या करना चीज़िए rather than updating the message आपको अभी तक जितने भी message chat में आए हैं उन सब को add करते जाना चीज़िए ठीक है तो basically यही funda है reducer का reducer आपको यह बताता है कि आपके state में जो updates होंगे वो कैसे होंगे क्या आप replace करोगे या फिर आप add करोगे या फिर आप merge करोगे state में update करने का तरीका क्या होगा यही हमें reducer बताता है ठीक है यहाँ भे देखो लिखा हुआ reducer in language defines how updates from nodes are applied to the shared state each key in the state can have its own reducer मतलब हो सकता है कि एक की बोले update होने दो दूसरा की बोले कि नहीं add होने दो तीसरा की बोले merge होने दो सबका अपना अपना reducer हो सकता है each key in the state can have its own reducer which determines whether new data replaces merges or adds to the existing value ठीक है जैसे हमारा ये use case है UPSC वाला यहाँ भे भी मैं आपको एक example दिखाता हूँ जहांपे आपको रादर देन update करने के प्रिजर्व करके रखना चाहिए past जो भी state की value है for example हमारे पास एक key value pair है ऐसे text बोलके ठीक है यहाँ पर जो भी हमारा student ऐसे लिख है वो हम यहाँ पर store कर रहे हैं अब हुआ क्या कि जो पहला ऐसे उसने लिखा वो अच्छा नहीं निकला और user ने बोला कि भाई मैं दुबारा से नया ऐसे लिखना जाता हूँ तो यहां आके वो नया ऐसे लिखेगा जैसी वो नया ऐसे लिखेगा इस variable की value चेंज हो जाएगी और पुराना जो उसने ऐसे लिखा था वो lost हो जाएगा वो गुम हो जाएगा right फिर वो नीचे आया फिर से evaluation हुआ तो पता चला कि नहीं यार अभी भी feedback अच्छा नहीं है तो उसने फिर से retake किया और उसने तीसरी बार ऐसे लिखा तो अब second वाला ऐसे भी गायब हो जाएगा third वाला यहां पे आप आके store हो जाएगा but what if उस student को देखना था उसका वो अपना पहला वाला ऐसे भी देखना चाहता है दूसरा वाला भी देखना चाहता है तीसरा वाला भी देखना चाहता है और उस देखना चाहता है कि कैसे वो improve कर रहा है in that case अपडेट करने का policy is not good in such situations आप add करोगे आप पहले वाला ऐसे रखोगे उसके आगे second वाला ऐसे add करोगे उसके आगे third वाला ऐसे add करोगे तो आपको simply यहां पर यह add बोल करके एक function होता है वो provide करना पड़ेगा इससे क्या होगा कि आपका previous वाला erase नहीं होगा नएवाला add होता जाएगा ठीक है तो reducer का basic funda यही है reducer बताता है कि state में जो update होगा वो किस तरीके से होगा replace होगा add होगा merge होगा यह तरीका बताता है reducer ठीक है तो आगे चलके मैं आपको किसी न किसी use case में reducers दिखाओंगा generally जब आप parallel workflows बनाते हो तब reducers ज़्यादा काम आते हैं तो hopefully जब हम parallelization वाला workflow बनाएंगे वहाँ पे I'll be able to show you कि reducers को कैसे code किया जाता है कैसे use किया जाता है अब इस वीडियो को conclude करने के पहले आपके साथ एक last चीज डिसकस करना चाहूँगा जो थोड़ी conceptual है और वो चीज है Langrath का execution model so मैं थोड़ा आपके साथ यह discuss करना चाहता हूँ कि behind the scenes Langrath एक workflow को execute कैसे करता है ठीक है यह पूरी चीज समझाने के पहले आपको एक interesting fact बताना चाहूँगा यह जो पूरा का पूरा execution model है जिसके उपर Langrath काम करता है यह actually google preggle से inspired है google preggle क्या है it's basically a system जो बहुत large scale पे graph processing कर सकता है और यह चीज google के बहुत सारे products में integrated है तो Langrath ने अपना execution model बनाया है वो काफी कुछ inspired है google preggle से ठीक है तो मैं आपको बताता हूँ कि जब आप एक workflow बनाते हो और चलाते हो Langrath में तो behind the scenes हो क्या रहा होता है so सबसे पहले आप क्या करते हो जैसे आपको एक workflow दिया जाता है बनाने आप सबसे पहले उस workflow से related एक graph create करते हो ठीक है ग्राफ create करने का मतलब है आप तीं चीज़े कर रहे हो पहला आप उसके nodes और edges define कर रहे हो और साती साथ आप उसका state create कर रहे हो जो कि इस पूरे step को बोला जाता है ग्राफ definition एक बार जब आपका ग्राफ आप define कर लेते हो उसके बाद आप क्या करते हो उसको compile करते हो so compile करने का main funda यह है कि आप पस चेक करना चाहते हो कि आपने जो ग्राफ बनाया है उसका structure logically correct ऐसा तो नहीं है कि कोई एक node ऐसा है जो किसी दूसरे node से connected ही नहीं है इसको हम orphaned node बोलते हैं इस तरह की inconsistencies नहीं होनी चाहिए आपके ग्राफ के structure में तो यह सब कुछ compile वाले step में चेक होता है actually यहाँ पर एक compile बोलके function है जिसको आप call करते हो एक बार जब compilation हो जाता है उसके बाद आपका execution phase start होता है यहाँ पर आप क्या करते हो सबसे पहले invocation करते हो so invocation में आपका काम क्या होता है कि आप जो आपके ग्राफ का first node है उसको आप अपना initial state पास करते हो जैसे ही आप अपना initial state पास करते हो अपने first node को ये particular node activate हो जाता है activate होने का मतलब क्या है कि इस node से attached जो python function है वो call हो जाता है और वो अपना काम करने लगता है और काम करने के बाद वो क्या करता है कि आपके state के उपर एक partial update करता है जैसे ये partial update होता है आपके state के उपर तो automatically आपका updated state इस edge के थूँ अगले node तक पहुँच जाता है और आपका अगला node बिल्कुल same करीके से activate हो जाता है ठीक है फिर वो भी अपना काम करता है state में partial changes करता है और फिर से node edge के थूँ state को आगे भेजता है तो ये जो हम constantly edge को use करके state को अगले node के पास भेज रहे हैं इस process को message passing बोला जाते है ठीक है और ये जो round by round काम हो रहा है जैसे ये हुआ एक round फिर similarly ये हुआ दूसरा round फिर similarly ये हुआ तीसरा round तो ये जो round by round काम हो रहा है इसको lang graph की language में super step बुलाया जाता है step क्यों नहीं बुलाया जाता है super step क्यों बुलाया जाता है ये बहुत interesting है वो भी मैं आपको बताता हूँ जैसे आप इस particular stage पे देखो माल लो यहां पर हो आप यहां पे आपका ये particular right ऐसे वाला node trigger हो गया activate हो गया इसका function call हो गया और इसने कुछ update कर दिया state के अंदर अब message passing के थूँ ये जो updated state है ये आगे जाएगी आगे वाले node के पास बड़ यहां पर आप notice करो कि आगे तीन parallel nodes है तो अब आपके system को क्या करना पड़ेगा इस message को तीनो nodes के पास भेजना पड़ेगा और ये तीनो nodes साथ में अपना काम करना start करेंगे और तीनो साथ में state के उपर updates करेंगे तो यहां पे जो आपका step है this consists of three parallel steps and that is why langrath ने ये सोचा कि rather than calling this a step we should call super step बिकोस ग्राफ का structure ऐसा होता है कि कभी कभी आपके पास parallel invocations हो तो एक से ज़ादा steps parallely execute होंगे तो उनको step बुलाना logical नहीं है तो let's call it super step ठीक है फिर इन तीनो से state update होता है reducer के त्रुब मर्च होता है और फिर इन एजस के त्रूब पास हो करके अगले नोड के पास पहुचता है सिमिलरली अगला नोड अक्टिवेट होता है वो अपना काम करता है स्टेट को अपडेट करता है message passing करता है ऐसे करते करते आप end पे पहुँचते हो ठीक है और आपका पूरा execution तब रुख जाता है जब आपके पास कोई भी अक्टिव नोड नहीं होता और आपके एजस में कोई भी message पास नहीं कर रहा होता अगर ये दोनों conditions true है तो आपका जो work workflow है वो स्टॉप कर जाता है तो यहाँ पे बस समशनी की चीज़ यह है कि आपने जब ये ग्राफ बनाया with multiple nodes तो आपको manually एक नोड को कॉल करके फिर दूसरे नोड को कॉल करने की ज़रूरत नहीं है आप ऐसा नहीं करोगे आप पहले नोड को कॉल करोगे उसको स्टेट दोगे उसका काम ख़तम होने के बाद दूसरे नोड को कॉल करोगे स्टेट भेजोगे नहीं यह सारा काम internally खुद बखुद हो रहा है और इस पूरी चीज़ में जो दो तीन चीज़े आपको सुनने को मिलेंगी आगे वो है आगे वाले नोड के पास एजस के थूँ स्टेट भेजना आगे वाले नोड के पास आगे वाले नोड के पास आगे वाले नोड के पास आगे वाले नोड के पास आगे वाले नोड के पास आगे वाले नोड के पास आगे वाले नोड के पास आगे वाले नोड के पास जो जो important concepts थे core concepts थे जो आपको बार बार सुनने को मिलेंगे आगे वो discuss कर लिए यहाँ पे theoretically, conceptually अब going forward I feel कि जब आप code में यह सारी चीजे करोगे आपको चीजे नई और एलियन नहीं लगेंगी आपको ऐसा लगेगा कि हाँ यह मैंने पढ़ रखा है That is why मैंने अलग से यह वीडियो shoot किया I really hope this was helpful अगर आपको यह वीडियो पसंद आया प्लीज लाइक करना अगर आपने चैनल को सबस्क्राइब नहीं किया है प्लीज दू सबस्क्राइब मिलते हैं next video में बाइ