
## 1、Introduction

欢迎来到这门关于LangChain的大语言模型应用开发短期课程。通过提示一个LLM（大语言模型），现在开发AI应用的速度比以往任何时候都要快得多。但一个应用可能需要多次提示LLM并解析其输出，因此需要编写大量的胶水代码。

LangChain由Harrison Chase创建，使这一开发过程变得更加容易。我很高兴Harrison能来到这里，他与DeepLearning.ai合作构建了这个短期课程，教授如何使用这个神奇的工具。感谢邀请我。能来到这里我真的很兴奋。LangChain最初是一个用于构建LLM应用程序的开源框架。

当时我正在与这个领域的一群开发者交流，他们正在构建更复杂的应用程序，我注意到他们在开发过程中采用了一些共同的抽象模式。到目前为止，LangChain在社区的采用情况让我们感到非常兴奋。我期待在这里与大家分享它，也期待看到人们用它构建出什么样的应用。

事实上，作为LangChain发展势头的体现，它不仅拥有众多用户，还有数百名开源贡献者，这对它的快速发展起到了关键作用。这个团队确实以惊人的速度推出代码和功能。因此，希望在这个简短的课程之后，你能够使用LangChain快速构建一些非常酷的应用程序，谁知道呢，也许你甚至会决定为开源LangChain项目做出贡献。

LangChain是一个用于构建大语言模型（LLM）应用程序的开源开发框架。我们提供两个不同的软件包，一个是Python版本，另一个是JavaScript版本。它们都注重组合性和模块化设计，因此包含许多可以单独使用或相互配合的独立组件，这是其核心价值之一。另一个核心价值是它支持多种不同的应用场景。

因此，通过将这些模块化组件组合成更端到端的应用程序链，可以非常容易地开始这些用例。在本课程中，我们将介绍LangChain的常见组件。我们将讨论模型。我们将讨论提示，这是让模型做有用和有趣的事情的方式。

我们将讨论索引，这是一种数据摄取方式，使您能够将数据与模型结合使用。然后我们会谈到链，这是更端到端的用例，以及代理，这是一种非常令人兴奋的端到端用例，它将模型用作推理引擎。

我们还要感谢Ankush Gola，他是与Harrison Chase共同创立LangChain的联合创始人，他也对这些材料投入了大量思考，并协助创建了这门短期课程。在DeepLearning.AI方面，Geoff Ludwig、Eddy Shyu和Diala Ezzeddine也为这些材料做出了贡献。那么接下来，让我们进入下一个视频，我们将学习LangChain的模型、提示和解析器。

## 2、Models, Prompts and parsers

第一课我们将学习模型、提示和解析器。模型指的是支撑大部分技术的语言模型。提示是指创建输入以传递给模型的方式。而解析器则相反，它涉及获取这些模型的输出并将其解析为更结构化的格式，以便后续处理。

是的，当你使用 LLM 构建应用程序时，常常会有可复用的模型。我们会反复提示一个模型，解析输出，因此 LangChain 提供了一套简单的抽象方法来执行这类操作。那么，接下来我们就深入了解一下模型、提示和解析器。首先，这里有一些入门代码。我将导入 OS，导入 OpenAI，并加载我的 OpenAI 密钥。

OpenAI 库已经安装在我的 Jupyter Notebook 环境中。如果你在本地运行这个程序，并且还没有安装 OpenAI，你可能需要运行这个命令。砰，pip install OpenAI，但我不会在这里执行。然后这里有一个辅助函数。这实际上与我与 OpenAI 的 Iza Fulford 共同提供的 ChaiGPT 开发者提示工程课程中你可能见过的辅助函数非常相似。

因此，有了这个辅助函数，你可以询问“1加1等于多少”，它会调用ChatGPT，或者更准确地说，是GPT-3.5 Turbo模型，来给你一个像这样的答案。现在，为了引出模型提示和解析器的链式抽象概念，假设你收到了一封非英语语言的客户邮件。

为了确保大家都能理解，我要用的另一种语言是英语海盗语，内容是：我气得要命，因为搅拌机的盖子飞了出去，把厨房的墙都溅满了奶昔。更糟的是，保修还不包括清理厨房的费用。伙计，我现在就需要你的帮助。所以，我们要做的就是让这个语言模型把这段话翻译成美式英语，语气要平静且礼貌。

因此，我将以平静且尊重的语气将风格设定为美式英语。为了实现这一点，如果你之前看过一些提示，我将使用f-string来指定提示，其中包含指令：将三重反引号分隔的文本翻译成指定风格，然后应用这两种风格。

因此，这会生成一个提示，要求翻译文本等等。我建议你暂停视频并运行代码，同时尝试修改提示，看看是否能得到不同的输出。然后你可以提示大型语言模型来获取回应。让我们看看回应是什么。它说将英文海盗的信息翻译成了非常礼貌的表达：“我真的很沮丧，我的搅拌机盖子飞了出去，把我的厨房墙壁弄得满是奶昔等等。朋友，我现在真的很需要你的帮助。”

听起来很不错。所以，如果你的客户用不同的语言撰写评论，而不仅仅是英语，还有法语、德语、日语等等，你可以想象需要生成一系列提示来生成这些翻译。让我们看看如何用LangChain以更方便的方式实现这一点。我要导入Chat OpenAI。

这是LangChain对ChatGPT API端点的抽象封装。因此，当我设置chat等于ChatOpenAI并查看chat对象时，它会创建如下使用ChatGPT模型（也称为GPT-3.5 Turbo）的对象。在开发应用程序时，我经常会将温度参数设置为零。默认温度值是0.7，但让我重新以temperature=0.0来设置，现在温度值设为0可以让输出结果减少随机性。

现在，让我按如下方式定义模板字符串。将三重向量分隔的文本翻译为风格即风格的样式，然后这里是文本。为了重复使用这个模板，让我们导入LangChain的聊天提示模板，然后，让我使用我们刚才在上面写的模板字符串创建一个提示模板。

从提示模板中，你实际上可以提取出原始提示语，它会发现这个提示语有两个输入变量——风格和文本，这里用花括号表示了出来。这里也展示了我们之前指定的原始模板。事实上，如果我打印出来，它会发现有两个输入变量：风格和文本。现在，让我们来指定风格。

这是我想要客户信息翻译成的风格，我称之为客户风格，这是我之前相同的客户邮件。现在，如果我创建客户信息，它将生成提示，并在一分钟内将这个大型语言模型传递以获取响应。如果你想看看类型，客户信息实际上是一个列表，如果你查看列表的第一个元素，这大致就是你期望创建的提示。

最后，让我们将这个提示传递给大语言模型（LLM），因此我将调用之前设置的“chat”——它是对OpenAI ChatGPT端点的引用。如果我们打印出客户回复的内容，那么它会返回这段从英文海盗语翻译为礼貌美式英语的文本。

当然，你可以想象其他应用场景，比如客户邮件使用的是其他语言，这也可以用来翻译邮件内容，让说英语的人能够理解并回复。我建议你暂停视频，运行代码，并尝试修改提示语，看看是否能得到不同的输出。现在，希望我们的客服人员能用客户的原语言回复他们。

假设一位讲英语的客服人员这样写道：“嘿，顾客，保修不包括您厨房的清洁费用，因为这是您的错。您忘记盖上搅拌机的盖子，导致误用。运气不好。再见。”现在这是一条礼貌的信息，但假设这是客服人员想要表达的。我们将指定这条服务信息将被翻译成这种海盗风格。

所以我们希望它能以一种礼貌的语气，用英语海盗的方式表达。而且因为我们之前已经创建了那个提示模板，最棒的是，我们现在可以重复使用那个提示模板，并指定我们想要的输出风格是这种服务风格的海盗，文本就是这个服务回复。如果我们这样做，那就是提示了。

如果我们输入提示词，ChaiGPT会这样回复我们："喂，伙计！我得告诉你，保修可不包括清理你厨房的费用。"诸如此类。唉，运气不好。再见，老兄。你可能会想，为什么我们要用提示模板，而不是直接用f字符串？答案是，当你构建复杂的应用程序时，提示可能会非常长且详细。

因此，提示模板是一种有用的抽象概念，可以帮助你在可能的情况下重用好的提示。这是一个相对较长的提示示例，用于为在线学习应用程序评分学生的提交。像这样的提示可能会相当长，你可以在其中要求LLM首先解决问题，然后以某种格式输出，并以某种格式输出。

将这段内容封装到LangChain提示中，可以更方便地复用此类提示。此外，你稍后会看到LangChain为一些常见操作提供了预设提示，例如摘要生成、问答、连接SQL数据库或对接不同API。因此，通过使用LangChain内置的一些提示模板，你可以快速启动应用程序，而无需自行设计提示语。

LangChain提示库的另一个特点是它还支持输出解析，我们稍后会讲到这一点。但在使用LLM构建复杂应用时，你通常会指示LLM以特定格式生成输出，例如使用特定的关键词。左边的这个例子展示了如何使用LLM通过React框架执行所谓的思维链推理。

但不必担心技术细节，关键在于“思考”代表大语言模型（LLM）的思维过程——通过赋予LLM思考空间，它往往能得出更准确的结论。而“行动”作为关键词承载具体操作，“观察”则展示从行动中获得的反馈，如此循环推进。

如果你有一个提示词，指示大语言模型使用这些特定的关键词——思考、行动和观察，那么这个提示词可以与解析器结合使用，以提取出被标记了这些特定关键词的文本。这样一来，就形成了一个非常优雅的抽象层，既能明确指定大语言模型的输入，又能让解析器正确解读大语言模型的输出。

因此，让我们回到使用LangChain的输出解析器示例。在这个例子中，我们将看看如何让大型语言模型输出JSON，并使用LangChain来解析这个输出。我将使用的运行示例是从产品评论中提取信息，并将输出格式化为JSON格式。

以下是一个示例，展示了您希望输出的格式。从技术上讲，这是一个Python字典，其中产品是否为礼物映射为false，交付所需天数为五天，价格相当实惠。这是一个期望输出的示例，这里还有一个客户评论的示例，以及一个尝试达到该JSON输出的模板。

这是一条客户评价。评价说，这款吹铅机非常棒。它有四种模式：烛光微风、轻柔微风、风城劲风和龙卷风。两天就到货了，正好赶上我妻子的周年纪念礼物。我想我妻子非常喜欢它，喜欢到说不出话来。到目前为止，只有我一个人在用，等等。

以下是评论模板。针对以下文本，提取以下信息。请注明，这是礼物吗？在本例中，答案是肯定的，因为这是一份礼物。另外，还有交付天数。交付用了多长时间？看起来在本例中，两天就到了。价格价值如何？比领先的吹风机稍贵一些，等等。

因此，审阅模板要求LLM接收客户评论作为输入，提取这三个字段，然后将输出格式化为带有以下键的JSON。好的。这就是如何在LangChain中封装它的方法。让我们导入聊天提示模板。实际上我们之前已经导入过这个了。

从技术上讲，这一行是多余的，但我还是重新导入它，然后基于顶部的评论模板创建提示模板。好了，这就是提示模板。现在，与我们之前使用提示模板的方式类似，让我们创建要传递给OpenAI端点的消息。

创建OpenAI端点，调用该端点，然后我们打印出响应。我建议你暂停视频并运行代码。看，结果出来了。它显示，返回值为true，交货日期是2天，价格数值看起来也相当准确。但请注意，如果我们检查响应的类型，这实际上是一个字符串。

看起来它像JSON，也像有键值对，但实际上并不是字典。这只是一个长字符串。所以我真正想做的是访问响应内容，从gift键获取值，这个值应该是true，但我运行这段代码时，应该会报错，因为，嗯，这实际上是一个字符串。这不是Python字典。那么，让我们看看如何使用LangChain的解析器来完成这个任务。

我将从LangChain导入响应模式和结构化输出解析器。然后通过指定这些响应模式来告诉它我想要解析的内容。gif模式名为gif，描述如下：该商品是否为他人购买的礼物？

回答“是”或“真”，如果不是或未知则回答“否”，以此类推。例如，有一个礼物模式、交付日期模式、价格值模式，然后将这三个模式放入一个列表中。现在我已经为这些模式指定了架构，LangChain实际上可以通过输出解析器告诉你它希望你发送给LLM的指令，从而为你提供提示本身。

所以如果我要打印格式说明。她有一套非常精确的指令集给LLM，能让它生成输出解析器能处理的输出。这就是新的评论模板，该模板包含了LangChain生成的格式说明。

因此，我们也可以从评论模板中创建一个提示，然后生成将传递给OpenAI端点的消息。如果你愿意，可以看看实际的提示内容，它会指导如何提取礼物、交付天数、价格价值等字段，这里是文本内容，然后这里是格式说明。

最后，如果我们调用OpenAI的端点，让我们看看得到了什么响应。现在的结果是这样的，如果我们使用之前创建的输出解析器，就可以将其解析成一个输出字典，打印出来是这样的。注意，这是一个字典类型，而不是字符串，因此我现在可以提取与键"gift"关联的值得到true，或者提取与"delivery days"关联的值得到2，还可以提取与"price value"关联的值。

所以这是一个巧妙的方法，可以将你的LLM输出解析成一个Python字典，使输出在下游处理中更容易使用。我建议你暂停视频并运行代码。那么，关于模型、提示和解析器的内容就到这里了。

有了这些工具，希望你能轻松复用自己设计的提示模板，与协作伙伴共享模板，甚至直接使用LangChain内置的提示模板——正如刚才所见，这些模板常能与输出解析器配合使用，使输入提示能按特定格式输出内容，再由解析器将输出内容转换为Python字典或其他数据结构，便于后续处理。

希望这些内容能在你的多种应用中派上用场。接下来，让我们进入下一个视频，看看LangChain如何帮助你构建更出色的聊天机器人，或者通过更好地管理它对当前对话的记忆，让大语言模型进行更高效的交流。

## 3、Memory

当你与这些模型互动时，它们自然不会记住你之前说过的话或任何之前的对话内容。这在构建某些应用程序（如聊天机器人）时是一个问题，因为你希望与它们进行对话。因此，在本节中，我们将讨论记忆功能，这基本上是关于如何记住对话的先前部分，并将其输入到语言模型中，以便在你与它们互动时能够保持这种对话的流畅性。

因此，LangChain提供了多种复杂选项来管理这些记忆。让我们深入了解一下。首先，让我导入我的OpenAI API密钥，然后导入一些我需要的工具。让我们以聊天或聊天机器人对话为例，使用LangChain来管理记忆。

因此，为了实现这一点，我将把LLM设置为OpenAI的聊天界面，并将温度参数设为0。同时，我会使用ConversationBufferMemory作为记忆模块，稍后你会明白这意味着什么。然后我将构建一个对话链。在这门短期课程的后半部分，Harrison会更深入地讲解LangChain中的链究竟是什么。

所以，现在不必过于担心语法的细节，这已经构建了一个大语言模型。如果我开始对话，使用conversation.predict，输入“嗨，我叫Andrew”，看看它会怎么回答。它会说“你好，Andrew，很高兴认识你”，对吧？然后，假设我问它“1加1等于多少？”，它会回答“1加1等于2”，接着再问它“你知道我叫什么名字吗？”

你的名字是Andrew，就像你之前提到的。嗯，这里有点讽刺的痕迹，不太确定。所以如果你愿意，你可以将这个verbose变量改为true，看看LangChain实际上在做什么。当你运行predict时，输入“Hi my name is Andrew”，这就是LangChain生成的提示。它说，以下是一个人类和AI之间的友好对话。

人工智能很健谈，诸如此类。因此，这是LangChain生成的一个提示，目的是让系统进行一场充满希望且友好的对话，并且必须保存对话内容，这是系统的回应。当你在对话的第二和第三部分执行这个提示时，它会保持如下提示。请注意，当我说出“我的名字是什么？”时。

这是第三个回合，这是我的第三次输入。它已经存储了当前的对话内容如下：嗨，我叫安德鲁，1加1等于多少，等等。因此，这段记忆或对话的历史会变得越来越长。实际上，在上面我已经使用了记忆变量来存储记忆。

所以如果我打印 memory.buffer，它会存储到目前为止的对话内容。你也可以打印 memory.loadMemoryVariables。这里的花括号实际上是一个空字典。还有一些更高级的功能，你可以通过更复杂的输入来使用，但我们在这个简短的课程中不会讨论这些。所以不用担心为什么这里有一个空的花括号。

但这就是LangChain目前在对话记忆中所记录的内容。它只是AI或人类所说的一切。我鼓励你暂停视频并运行代码。所以，LangChain存储对话的方式是通过这个ConversationBufferMemory。

如果我要使用ConversationBufferMemory来指定几个输入和输出，这就是你如何显式地向内存中添加新内容的方法。Memory.saveContext会说，嗨，最近怎么样？我知道这不是最令人兴奋的对话，但我想要一个简短的例子。

就这样，这就是内存的当前状态。让我再次展示一下内存变量。现在，如果你想向内存中添加更多数据，可以继续保存额外的上下文。对话继续，内容不多，只是闲聊，很酷。如果你打印出内存，你会发现里面现在有更多内容了。

因此，当你使用大型语言模型进行聊天对话时，大型语言模型本身实际上是无状态的。语言模型本身不会记住你到目前为止的对话内容。每一次交互、每一次对API端点的调用都是独立的。聊天机器人看起来有记忆，只是因为通常有一些快速代码将迄今为止的完整对话作为上下文提供给大型语言模型。

因此，记忆可以明确存储到目前为止的术语或话语。嗨，我叫安德鲁。你好，很高兴认识你等等。这个记忆存储被用作LLM的输入或额外上下文，这样它们就可以生成输出，就好像它只是在知道之前说过的话的情况下进行下一轮对话。

随着对话的延长，所需的内存容量会变得非常庞大，同时向大语言模型发送大量标记的成本也会变得更高——因为大语言模型通常根据处理的标记数量收费。为此，LangChain提供了几种便捷的记忆存储机制来积累对话内容。

到目前为止，我们一直在讨论ConversationBufferMemory。现在让我们看看另一种类型的内存。我将导入conversation buffer window memory，它只保留一个记忆窗口。如果我将内存设置为k等于1的conversational buffer window memory，变量k等于1表示我只想记住一次对话交流。

这是我的一句话和聊天机器人说的一句话。所以，现在如果我要让它保存上下文，嗨，最近怎么样，没什么，就是随便待着。如果我要查看memory.load变量，它只记得最近的发言。注意到它已经丢失了。嗨，最近怎么样？它只显示人类说没什么，就是随便待着，而AI说酷。这是因为k等于1。

这个功能很不错，因为它能让你只追踪最近几次对话的内容。实际应用中，你可能不会将k值设为1，而是会设置更大的数值。不过即便如此，它也能防止随着对话延长，内存无限增长。所以如果我要重新运行刚才的对话，我们会说：嗨，我叫安德鲁。

1加1等于几？现在我问它，我的名字是什么？因为k等于1，它只记得最近的对话，而不是“1加1等于几？”这个问题的答案是1加1等于2，但它已经忘记了之前的对话，现在它会说，抱歉，无法获取该信息。

我希望你做的一件事是暂停视频，在左侧代码中将此值改为 true，然后重新运行这段对话并将 verbose 设为 true，这样你就能看到实际用于生成内容的提示词。希望你会发现，当你向大语言模型询问「我的名字是什么」时，它的记忆已经丢失了之前获知你名字的对话片段，这就是为什么它现在回答不知道你的名字。

通过对话令牌缓冲存储器，系统会限制保存的令牌数量。由于许多大型语言模型的定价基于令牌数量，这直接关系到调用模型所产生的成本。例如，如果将最大令牌限制设为50——这里请允许我插入几句说明——

假设对话是这样的：AI是什么？令人惊叹。反向传播是什么？美妙。聊天机器人是什么？迷人。我用ABC作为所有这些对话术语的首字母。我们可以记录下每个时刻说了什么。如果我用较高的令牌限制运行这个程序，它几乎能记住整个对话。如果把令牌限制增加到100，它现在就能记住整个对话了，AI的标志是什么？

如果我减少它，那么，你知道的，它会截掉对话的前面部分，保留最近交流对应的token数量，但前提是不超过token限制。如果你想知道为什么我们需要指定一个LLM，那是因为不同的LLM使用不同的方法来计算token，所以这告诉它使用chatOpenAI LLM的token计数方式。

我建议你暂停视频，运行代码，并尝试修改提示词，看看是否能得到不同的输出。最后，我想在这里说明最后一种记忆类型，即对话摘要缓冲记忆。其核心思想是，不要将记忆限制在基于最近发言的固定数量标记或固定数量的对话交流上，而是让我们使用一个大型语言模型来编写迄今为止对话的摘要，并将其作为记忆。

这是一个例子，我将创建一个包含某人日程安排的长字符串。比如，早上8点要和产品团队开会，你需要准备PowerPoint演示文稿，诸如此类。所以会有一个长字符串描述你的日程安排，可能最后是在意大利餐厅与客户共进午餐，带上你的笔记本电脑，展示最新的LLM演示。

因此，让我在这种情况下使用一个最大标记限制为400的对话摘要缓冲存储器，这个标记限制相当高，我将在其中插入一些对话术语，我们从“你好，最近怎么样”、“没什么，就是闲着呢”、“酷”开始。然后问“今天有什么安排”，回答是“你知道的，就是那一长串的安排”。所以现在这个存储器里已经有了相当多的文本。

事实上，让我们来看看记忆变量。它包含了整段文本，因为400个标记足以存储所有这些内容。但现在，如果我将最大标记限制减少到100个，请注意，这里存储的是整个对话历史。当我把标记数缩减到100时，对话摘要缓冲记忆实际上调用了大语言模型（这里用的是OpenAI的接口，因为我们之前将LLM设置为该平台），来生成迄今为止对话的摘要。

总结一下，人类和AI在日程开始前会闲聊，并在晨会上向人类通报情况，等等等等，午餐会是与对AI及最新AI发展感兴趣的客户进行的。那么，如果我们用这个LLM进行对话，让我像之前一样创建一个对话链。假设我们要问，比如输入什么会是一个好的演示。我说verbose等于true，所以这是提示。

LLM认为当前对话已经进行了这些讨论，因为这是对话的总结。另外请注意，如果你熟悉OpenAI聊天API端点，有一个特定的系统消息。在这个例子中，并没有使用官方的OpenAI系统消息，而是将其作为提示的一部分包含在这里，但它仍然运作得相当好。

好事正在启动。有趣的是，如果你现在看看记忆发生了什么变化，你会发现，这里已经融入了最新的人工智能系统输出，而我询问“展示什么演示比较好”的话语，已经被整合到了系统消息中，也就是目前为止对话的整体摘要。通过对话摘要缓冲记忆，它试图做的事情是将消息的显式存储保持在我们指定的令牌数量限制范围内。

所以，这部分显式存储，我们尽量控制在100个标记以内，因为这是客户要求的。超过这个数量的部分，就会用CLM来生成摘要，也就是上面看到的内容。

尽管我以聊天为例说明了这些不同的记忆方式，但这些记忆对其他应用场景同样有用。比如，当你不断接收到新的文本片段或信息时（例如系统反复联网搜索事实数据），这些方法能帮助你控制存储这些不断增长的事实列表所需的总内存，使其保持在限定范围内，避免无限膨胀。

我建议你暂停视频并运行代码。在这段视频中，你看到了几种记忆类型，包括基于对话轮次或令牌数量限制的缓冲记忆，以及能够对超出特定限制的令牌进行总结的记忆。LangChain实际上还支持其他记忆类型。其中最强大的是向量数据记忆，如果你熟悉词嵌入和文本嵌入，向量数据库实际上存储的就是这些嵌入。

如果你不明白这是什么意思，别担心，哈里森稍后会解释。然后，它可以通过这种向量数据库检索最相关的文本块作为记忆。LangChain还支持实体记忆功能，适用于需要记住特定人物或其他实体细节的场景。比如，当你谈论某个朋友时，可以让LangChain以显式方式记住关于该朋友（作为实体）的事实信息。

在使用LangChain实现应用程序时，您还可以使用多种类型的内存，例如使用本视频中介绍的某一种对话内存，再加上实体内存来回忆个体信息。这样，你就能记住对话的概要，同时还能以明确的方式存储对话中重要人物的关键信息。当然，除了使用这些记忆类型外，开发者通常也会将整个对话存储在传统数据库中。

某种键值存储或SQL数据库。这样你就可以回顾整个对话，用于审计或进一步改进系统。以上就是记忆类型。希望这些内容对你构建自己的应用程序有所帮助。现在，让我们继续观看下一个视频，学习LangChain的关键构建模块，即链。

## 4、Chains

在本节课中，Harrison将教授LangChain最重要的核心构建模块——链（chain）。链通常将大语言模型（LLM）与提示词相结合，通过这个基础模块，您还可以将多个此类模块串联起来，对文本或其他数据执行一系列操作。我已经迫不及待要深入探讨了。好的，首先我们会像之前一样加载环境变量，然后还会加载一些待使用的数据。

这些链的强大之处在于，你可以一次性对多个输入运行它们。这里我们将加载一个pandas DataFrame。pandas DataFrame是一种数据结构，包含许多不同的数据元素。如果你不熟悉pandas，不用担心。这里的关键点是我们正在加载一些数据，以便稍后使用。如果我们查看这个pandas DataFrame内部，可以看到有一个产品列和一个评论列。

每一行都是一个不同的数据点，我们可以开始将其输入到我们的链中。我们要介绍的第一个链是LLM链。这是一个简单但非常强大的链，支撑着我们未来将要讨论的许多链。因此，我们将导入三个不同的东西。我们将导入OpenAI模型，也就是LLM。我们将导入聊天提示模板。这就是提示。然后我们将导入LLM链。

首先，我们要做的是初始化我们想要使用的语言模型。我们将以较高的温度参数初始化Chat OpenAI，这样就能得到一些有趣的描述。接着，我们会初始化一个提示词模板。这个模板会接收一个名为"product"的变量，要求大语言模型为生产该产品的公司生成最佳名称建议。最后，我们将把这两个组件整合成一个处理链条。

因此，这就是我们所说的LLM链。它非常简单，只是将LLM和提示词结合起来。但现在这个链将让我们以顺序的方式运行提示词并进入LLM。所以如果我们有一个名为queen-size-sheet-set的产品，我们可以通过使用chain.run将其运行通过这个链。这样做的效果是，它会在后台格式化提示词，然后将整个提示词传递给LLM。

因此我们可以看到，我们得到了这个假设公司"皇家博彩"的名称。这里是一个很好的暂停时机。你可以输入任何你想要的商品描述，然后看看链条会输出什么结果。LLM链条是最基本的一种链条类型，未来将会被大量使用。接下来我们可以看到它如何被应用于下一种链条类型——顺序链条中。

因此，顺序链会一个接一个地运行一系列链。首先，你需要导入简单的顺序链。当我们有子链只期望一个输入并只返回一个输出时，这种方法很有效。在这里，我们将首先创建一个链，它使用一个LLM和一个提示。这个提示将接收产品信息，并返回描述该公司的最佳名称。

那么这就是第一条链。接下来我们将创建第二条链。在这第二条链中，我们会接收公司名称，然后输出一段20字的公司描述。你可以想象这些链可能需要依次运行，第一条链的输出——公司名称——会被传递到第二条链中。我们可以通过创建一个简单的顺序链来轻松实现这一点，其中包含刚才描述的两条链。我们将这个整体结构称为简单链。

现在，你可以对任何产品描述运行这个链条。如果我们用上面的产品——大号床单套装来运行它，我们可以看到它首先输出“royal betting”。然后它将其传递到第二个链条，并得出关于这家公司可能是做什么的描述。当只有一个输入和一个输出时，简单的顺序链条效果很好。

但如果输入或输出有多个呢？这时我们可以通过使用常规的顺序链来实现。让我们导入这个功能。然后你将创建一系列链，我们将一个接一个地使用它们。我们将使用上面的数据，其中包含一条评论。第一个链，我们将把这条评论翻译成英文。第二个链，我们将用一句话总结这条评论。

这将使用之前生成的英文评论。第三条链将首先检测评论使用的是哪种语言。如果你注意到，这里使用的是来自原始评论的review变量。最后，第四条链将接收多个输入。它将接收我们通过第二条链计算的summary变量，以及通过第三条链计算的language变量。然后，它会要求以指定语言对摘要进行后续回复。

关于所有这些子链，有一点很重要，那就是输入键和输出键需要非常精确。在这里，我们接收的是review。这是一个在开始时传入的变量。可以看到，我们明确将输出键设置为English review。然后，在下面的提示中，我们使用相同的变量名English review来接收它。我们将该链的输出键设置为summary，可以看到它在最终的链中被使用。

第三个提示接收评论、原始变量并输出语言，该语言再次用于最终提示。确保这些变量名称完全正确对齐非常重要，因为涉及许多不同的输入和输出。如果出现任何关键错误，您一定要检查它们是否对齐。简单的顺序链接收多个链，每个链都有一个输入和一个输出。

为了更直观地理解这一点，我们可以看一下幻灯片，其中一条链依次输入到另一条链中。在这里，我们可以看到对顺序链的直观描述。与上面的链相比，您会注意到链中的任何步骤都可以接收多个输入变量。当您需要将多个前序链组合成更复杂的下游链时，这一点非常有用。

现在我们有了所有这些链，就可以轻松地在顺序链中组合它们。你会注意到，这里我们将把创建的四个链传入 chains 变量中。我们将用一个人类输入（即评论）创建 inputs 变量。然后我们希望返回所有中间输出，包括英文评论、摘要和后续消息。现在，我们可以对一些数据运行这个流程。

那么我们选择一个评论，并将其传递到整个链条中。可以看到这里的原始评论似乎是法语写的。我们能查看英文翻译的评论内容，能看到该评论的摘要，然后还能看到一条以原始法语撰写的后续回复。建议你在此处暂停视频，尝试输入不同的内容。到目前为止，我们已经介绍了LLM链和顺序链，但如果你想进行更复杂的操作呢？

一种相当常见但基本的操作是根据输入的具体内容将其路由到不同的处理链。可以这样想象：如果你有多个子链，每个子链专门处理特定类型的输入，那么你可以设置一个路由链，它首先决定将输入传递给哪个子链，然后再将其传递给该子链。

举一个具体的例子，我们来看看如何根据输入的主题在不同类型的链之间进行路由。这里我们有不同的提示。第一个提示适合回答物理问题，第二个适合回答数学问题，第三个适合历史问题，第四个则适合计算机科学问题。

让我们来定义所有这些提示模板。有了这些提示模板后，我们就可以提供更多关于它们的信息。我们可以为每个模板命名并添加描述。比如这个物理模板的描述就很适合回答物理相关问题。这些信息将被传递给路由链，以便路由链决定何时使用这个子链。现在让我们导入所需的其他类型链。

这里我们需要一个多提示链。这是一种特殊类型的链，用于在多个不同的提示模板之间进行路由选择。如你所见，我们所有的选项本身都是提示模板。但这只是你可以进行路由选择的一种类型。你可以在任何类型的链之间进行路由选择。我们将在这里实现的其他类是一个LLM路由链。它使用语言模型本身来在不同的子链之间进行路由选择。

此处将使用上述提供的描述和名称。我们还将导入一个路由器输出解析器，该解析器将大语言模型（LLM）的输出解析为字典格式，以便后续确定使用哪条链及该链的输入内容。现在我们可以开始使用它了。首先，导入并定义我们将要使用的语言模型。接着创建目标链。

这些是由路由器链调用的子链。可以看到，每个目标链本身就是一个语言模型链（LLM链）。除了目标链外，我们还需要一个默认链。当路由器无法决定使用哪个子链时，就会调用这个默认链。在上面的例子中，当输入问题与物理、数学、历史或计算机科学无关时，就可能调用这个默认链。

现在我们定义由大语言模型（LLM）用于在不同链之间进行路由的模板。该模板包含待执行任务的指令，以及输出应遵循的特定格式。让我们将这些部分组合起来构建路由链。首先，我们通过用上面定义的目标格式化来创建完整的路由模板。该模板适用于多种不同类型的目标。

你可以在这里做的一件事是暂停并添加不同类型的目标。所以在这里，不仅仅是物理、数学、历史和计算机科学，你还可以添加不同的科目，比如英语或拉丁语。接下来，我们从这个模板创建提示模板，然后通过传入LLM和整体路由器提示来创建路由器链。请注意，这里我们有路由器输出解析器。这很重要，因为它将帮助这个链决定在哪些子链之间进行路由。

最后，将所有内容整合起来，我们就可以创建完整的链条。这里定义了一个路由链，我们在此处传入目标链，同时也传入了默认链。现在我们可以使用这个链条了。让我们来问它一些问题。如果我们询问一个关于物理的问题，比如“什么是黑体辐射？”，希望能看到它被路由到物理链进行处理。

然后，这会被传递到下面的链中，我们可以看到响应非常详细，包含了很多物理细节。你应该在这里暂停视频，尝试输入不同的内容。你可以尝试使用我们上面定义的所有其他类型的特殊链。例如，如果我们问它一个数学问题，我们应该看到它被路由到数学链，然后传递到那里。

我们还可以看看当传入一个与任何子链无关的问题时会发生什么。这里，我们问了一个关于生物学的问题，可以看到它选择的链是“无”。这意味着问题将被传递给默认链，而默认链本身只是对语言模型的一个通用调用。幸运的是，语言模型对生物学了解很多，所以在这里它可以帮助我们。

既然我们已经介绍了这些基本的链条类型，现在我们可以开始将它们组合起来，创建真正有趣的应用程序。例如，在下一节中，我们将介绍如何创建一个能够对你的文档进行问答的链条。

## 5、Question and Answer Over Document

人们使用大语言模型（LLM）构建的最常见、最复杂的应用之一，就是能够基于文档或针对文档内容进行问答的系统。比如，给定一段文本（可能是从PDF文件、网页或某公司的内网内部文档库中提取的），能否利用LLM来回答与这些文档内容相关的问题，从而帮助用户更深入地理解并获取所需信息？

这真的很强大，因为它开始将这些语言模型与它们最初未经训练的数据结合起来。这使得它们更加灵活，更能适应你的使用场景。同样令人兴奋的是，我们将开始超越语言模型、提示和输出解析器，并引入更多LangChain的关键组件，比如嵌入模型和向量存储。

正如Andrew提到的，这是我们目前最受欢迎的链条之一，希望大家感到兴奋。事实上，嵌入技术和向量存储是最强大的现代技术手段，如果你还没接触过，它们绝对值得深入学习。话不多说，让我们开始吧！动手！首先照例导入环境变量。接下来我们将导入构建这个链条所需的工具，包括检索问答链。

这将检索一些文档。我们将导入我们最喜欢的聊天OpenAI语言模型。我们将导入一个文档加载器。这将用于加载一些专有数据，我们将这些数据与语言模型结合使用。在本例中，数据将以CSV格式存在。因此我们将导入CSV加载器。最后，我们将导入一个向量存储。

向量存储有多种不同类型，我们稍后会详细介绍这些内容，但现在我们将从"DocArrayInMemorySearch"向量存储开始。这种存储方式非常方便，因为它是一个内存中的向量存储，不需要连接任何外部数据库，所以很容易上手。我们还将导入display和markdown这两个常用工具，用于在Jupyter笔记本中显示信息。

我们提供了一个户外服装的CSV文件，将用于与语言模型结合。这里我们将初始化一个加载器——CSV加载器，并指定该文件的路径。接下来我们将导入一个索引工具"VectorStoreIndexCreator"，它能帮助我们轻松创建向量存储。如下所示，只需几行代码即可完成创建。在创建过程中，我们需要指定两个要素。

首先，我们将指定向量存储类。如前所述，我们将使用这个向量存储，因为它特别容易上手。创建完成后，我们将调用"from_loaders"方法，该方法接收一个文档加载器列表。我们实际上只关心一个加载器，所以这里传入的就是它。现在它已经创建完成，我们可以开始向它提问了。

接下来我们将深入探讨其背后的具体运作机制，不过现在不必为此担忧。这里，我们将从一个查询开始。然后使用"index.query"创建响应并传入该查询。再次强调，我们稍后会详细解释底层原理。目前，我们只需等待其响应。完成后，现在可以查看返回的具体内容。我们得到了一个Markdown格式的表格，其中列出了所有具有防晒功能的衬衫名称及其描述。

我们还得到了语言模型提供的一个很好的小总结。我们已经了解了如何对文档进行问答，但背后到底发生了什么？首先，让我们思考一下总体思路。我们希望使用语言模型并将其与大量文档结合起来。但有一个关键问题。语言模型一次只能检查几千个单词。

那么，如果我们有非常大的文档，如何让语言模型回答其中所有内容的问题呢？这时就需要用到嵌入和向量存储了。首先，我们来谈谈嵌入。嵌入技术能为文本片段生成数值化的表示形式。这种数值化表示能捕捉到所处理文本片段的语义信息。

内容相似的文本片段将具有相似的向量。这使得我们可以在向量空间中对文本片段进行比较。在下面的例子中，我们可以看到有三句话。前两句是关于宠物的，而第三句是关于汽车的。如果我们观察它们在数值空间中的表示，就会发现当比较关于宠物的两句话对应的文本向量时，它们非常相似。

但如果我们将其与关于汽车的文本进行比较，就会发现它们毫无相似之处。这样我们就能轻松辨别哪些文本片段彼此相似，这对于我们思考在向语言模型传递信息以回答问题时需要包含哪些文本片段非常有用。接下来我们要介绍的是向量数据库。

向量数据库是一种存储我们在上一步创建的向量表示的方法。我们创建这个向量数据库的方式是用来自传入文档的文本块填充它。当我们收到一个大的传入文档时，我们首先会将其分解成更小的块。这有助于创建比原始文档更小的文本片段，这很有用，因为我们可能无法将整个文档传递给语言模型。

因此，我们希望将这些内容分割成小块，以便只将最相关的部分传递给语言模型。然后，我们为每个小块创建嵌入向量，并将它们存储在向量数据库中。这就是我们创建索引时发生的事情。现在，我们有了这个索引，就可以在运行时使用它来查找与传入查询最相关的文本片段。当查询到来时，我们首先为该查询创建一个嵌入向量。

然后我们将其与向量数据库中的所有向量进行比较，并选出最相似的n个。这些结果会被返回，我们可以将它们放入提示中传递给语言模型，以获取最终答案。如上所述，我们创建了这个链条，仅用了几行代码。这对于快速入门来说非常棒。但现在让我们更详细地一步步进行，并了解其背后的具体运作原理。

第一步与上述步骤类似。我们将创建一个文档加载器，从包含所有待问答产品描述的CSV文件中加载数据。然后，我们可以从这个文档加载器中加载文档。如果我们查看单个文档，会发现每个文档对应CSV文件中的一个产品。之前我们讨论过创建文本块的方法。

由于这些文档已经非常精简，我们实际上不需要进行任何分块处理。因此可以直接创建嵌入向量。我们将使用OpenAI的嵌入类来生成嵌入向量，只需导入并初始化即可。如果想了解这些嵌入向量的作用，我们可以观察对特定文本进行嵌入时会发生什么。让我们在嵌入对象上调用"embed_query"方法，为特定文本生成嵌入向量。

在这种情况下，句子“嗨，我叫哈里森。”如果我们看一下这个嵌入，可以看到有超过一千个不同的元素。每个元素都是一个不同的数值。这些数值组合起来，就构成了这段文本的整体数值表示。我们想要为刚刚加载的所有文本片段创建嵌入，然后我们还想将它们存储在一个向量存储中。

我们可以通过使用向量存储上的"from_documents"方法来实现这一点。该方法接收一个文档列表和一个嵌入对象，然后我们将创建一个整体的向量存储。现在我们可以使用这个向量存储来查找与传入查询相似的文本片段。让我们看看这个查询："请推荐一件防晒衬衫"。如果我们在向量存储上使用相似性搜索方法并传入查询，我们将得到一个文档列表作为返回结果。

我们可以看到它返回了四个文档，如果查看第一个文档，可以发现它确实是一件关于防晒的衬衫。那么，如何利用这一点在我们自己的文档上进行问答呢？首先，我们需要从这个向量存储中创建一个检索器。检索器是一个通用接口，可以由任何接收查询并返回文档的方法支持。向量存储和嵌入就是这样一种方法，尽管还有许多不同的方法，有些较为简单，有些则更为先进。

接下来，由于我们需要进行文本生成并返回自然语言响应，我们将导入一个语言模型并使用ChatOpenAI。如果手动操作的话，我们会将文档合并为一段文本。具体做法类似这样：我们将所有文档中的页面内容合并到一个变量中，然后将这个变量或问题的变体（例如："请以markdown表格形式列出所有具有防晒功能的衬衫，并对每款进行总结"）输入到语言模型中。

如果我们在这里打印出响应，就能看到返回的表格完全符合我们的要求。所有这些步骤都可以通过LangChain链进行封装。因此，这里我们可以创建一个检索问答链。它会先执行检索，然后在检索到的文档上进行问答。要创建这样的链，我们需要传入几个不同的组件。首先，我们会传入语言模型。这将用于最后的文本生成。

接下来，我们将传入链类型。我们将使用"stuff"方法。这是最简单的方式，因为它只是将所有文档内容塞入上下文，并对语言模型进行一次调用。还有其他几种问答方法我可能会在最后简单提及，但不会详细展开。第三，我们将传入一个检索器。之前创建的检索器只是一个用于获取文档的接口。

这将用于获取文档并将其传递给语言模型。最后，我们将设置"verbose=True"。现在，我们可以创建一个查询，并在这个查询上运行链式处理。当我们得到响应时，可以再次使用显示和标记工具来展示它。你可以在这里暂停视频，尝试用各种不同的查询来测试。以上就是详细的操作方法，但请记住，我们仍然可以非常简单地用上面提到的那一行代码来完成。

所以，这两种方式得到的结果是一样的。这正是LangChain有趣的地方之一。你可以用一行代码搞定，也可以拆分成五个更详细的步骤。更详细的五个步骤能让你更精确地控制具体操作，但单行代码更容易上手。具体采用哪种方式，取决于你的偏好。我们也可以在创建索引时进行自定义设置。

因此，如果你还记得，当我们手动创建它时，我们指定了一个嵌入。我们也可以在这里指定一个嵌入。这样我们就能灵活控制嵌入本身的创建方式。我们还可以在这里更换为其他类型的向量存储。所以，无论是手动创建还是在这里创建索引，你都能获得相同程度的自定义选项。在这个笔记本中，我们使用了“填充方法”。

填充方法确实很好，因为它非常简单。你只需将所有内容放入一个提示中，发送给语言模型，然后得到一个回复。因此，理解整个过程相当简单。它成本低廉且效果不错。但这并不总是奏效。还记得吗，当我们在笔记本中获取文档时，只返回了四个文档，而且它们相对较小。

但如果你想对许多不同类型的文本块进行同样的问答处理呢？这时我们可以采用几种不同的方法。第一种是"Map_reduce（映射归约）"。这种方法本质上会获取所有文本块，将它们连同问题一起传递给语言模型，获取响应后，再通过另一个语言模型调用将所有独立响应汇总成最终答案。

这确实非常强大，因为它可以处理任意数量的文档。而且它也很强大，因为你可以并行处理各个问题。但这确实需要更多的调用。而且它将所有文档视为独立的，这可能并不总是最理想的情况。"Refine"是另一种方法，同样用于循环处理多个文档。但它实际上是迭代进行的。

它基于前一份文档的答案进行构建。因此，这种方式非常适合整合信息并逐步构建答案，通常会形成更长的回答。同时，它的速度也会稍慢，因为现在的调用不再是独立的，而是依赖于之前调用的结果。这意味着它通常需要更长的时间，且调用次数与"Map_reduce"基本相当。"Map_rerank"则是一种相当有趣且更具实验性的方法，它对每个文档仅进行一次语言模型调用。

你还要求它返回一个分数，然后选择最高的分数。这依赖于语言模型知道分数应该是什么。因此，你经常需要告诉它：“嘿，如果它与文档相关，就应该是一个高分，并且在那里真正细化指令。”与“Map_reduce”类似，所有的调用都是独立的。

这样你就可以批量处理，速度相对较快。但同样，你需要进行多次语言模型调用，因此成本会稍高一些。这些方法中最常见的是“填充法”，我们在笔记本中用它把所有内容合并成一个文档。第二常见的是“映射归约法”，它将文本块分割后发送给语言模型处理。

除了问答之外，这里提到的方法——包括stuff、map_reduce、refine和rerank——还可以用于许多其他任务链。例如，"Map_reduce"链的一个非常常见的用途是摘要生成，当你有一个非常长的文档，并且想要递归地汇总其中的信息片段时。以上就是关于文档问答的全部内容。你可能已经注意到，我们在这里使用的不同链条中有很多复杂的操作。因此，在下一节中，我们将介绍如何更好地理解所有这些链条内部的具体运作情况。

## 6、 Evaluation

在使用大语言模型（LLM）构建复杂应用时，一个关键但有时颇具挑战性的环节是如何评估应用的实际表现。它是否达到了预期的准确度标准？此外，若您决定调整实施方案——比如更换不同的大语言模型、改变向量数据库的检索策略、或是修改系统其他参数时，又该如何判断这些改动是优化还是劣化呢？

在本视频中，Harrison将深入探讨如何评估基于大型语言模型（LLM）应用程序的一些框架，以及一些有助于完成这项评估的工具。这些应用程序实际上是许多不同步骤的链条和序列。因此，老实说，你首先应该做的一部分工作就是准确理解每个步骤的输入和输出是什么。因此，从这个角度来看，一些工具实际上可以被视为可视化工具或调试器。但通常，获取模型在不同数据点上的表现的整体情况是非常有用的。

实现这一目标的一种方法是通过肉眼观察事物。但还有一种非常酷的想法，那就是利用语言模型本身和链式结构来评估其他语言模型、其他链式结构以及其他应用程序。我们也将深入探讨这一点。因此，本视频涵盖了许多有趣的主题。我发现，随着大量开发工作转向基于提示的开发，即使用大型语言模型（LLMs）开发应用程序，整个工作流程的评估过程正在被重新思考。所以，这个视频中有很多令人兴奋的概念。

让我们开始吧。好的，首先我们需要设置评估环境。第一步，我们需要准备好要评估的链或应用程序。我们将使用上一节课中的文档问答链。所以，我们需要导入所有必要的组件，并加载之前使用的相同数据。

我们将用一行代码创建该索引。然后，通过指定语言模型、链类型、检索器以及要输出的详细程度，来创建检索问答链。我们有了这个应用程序，首先需要真正确定一些我们想要评估的数据点。

因此，我们将介绍几种不同的方法来实现这一目标。第一种是最简单的，基本上就是由我们自己想出一些我们认为很好的数据点作为示例。为此，我们可以查看一些数据，提出示例问题，然后给出示例真实答案，以便后续用于评估。

如果我们看看这里的几份文件，就能大致了解其中的内容。第一份文件里提到了这款套头衫套装，第二份里有这件夹克，每份文件都包含大量产品细节。根据这些细节，我们可以创建一些示例问答对。比如第一个问题可以很简单："Cozy Comfort套头衫套装是否有侧兜？"

从上面我们可以看到，它确实有一些侧袋。然后对于第二个例子，我们可以看到这件夹克来自某个系列，即DownTek系列。因此我们可以问一个问题：“这件夹克来自哪个系列？”答案就是“DownTek系列”。这样我们就创建了两个例子。

但这并不能很好地扩展。查看每个示例并弄清楚发生了什么需要花费一些时间。那么有没有办法可以自动化这个过程呢？我们认为，其中一个非常酷的自动化方法就是利用语言模型本身。在LangChain中，我们有一个链可以做到这一点。我们可以导入问答生成链，它会接收文档并为每个文档生成一个问答对。

它将通过语言模型本身来实现这一点。因此，我们需要通过传入Chat OpenAI语言模型来创建这个链条。然后，我们可以基于此创建一系列示例。我们将使用apply和parse方法，因为这里需要对结果应用输出解析器，以便获取包含查询和答案对的字典，而不仅仅是单个字符串。

因此，现在如果我们仔细看看这里返回的内容，可以看到一个查询和一个答案。让我们检查一下这个问答对应的文档，可以看到它在询问这个东西的重量是多少，可以看到它从这里获取了重量信息。看吧！我们刚刚生成了一堆问答对。

我们不必自己全部编写。这节省了我们大量时间，让我们可以做更多令人兴奋的事情。那么现在，让我们继续将这些示例添加到我们已经创建的示例中。现在，我们有了这些示例，但究竟该如何评估发生了什么？我们首先要做的就是将一个示例通过链运行，看看它产生的输出。在这里，我们传入一个查询，然后得到一个答案。

但是，这在我们能够实际观察链内部发生的情况方面有些局限。实际输入语言模型的提示是什么？它检索了哪些文档？如果这是一个包含多个步骤的更复杂链条，中间结果又是什么？通常仅看最终答案不足以理解链条中正在或可能出现的问题。

为了帮助解决这个问题，LangChain提供了一个有趣的小工具叫做"langchain.debug"。如果我们设置"langchain.debug = True"，然后重新运行上面的例子，就能看到它开始打印出更多信息。仔细观察打印内容，会发现它首先深入检索QA链，然后进入文档汇总链。

如前所述，我们正在使用填充方法。现在它进入了LLM链，我们有几个不同的输入。可以看到原始问题就在那里。现在我们正在传入这个上下文。可以看到这个上下文是由我们检索到的一堆不同文档创建的。

因此，在进行问答时，很多时候返回错误结果并不一定是语言模型本身出了问题。实际上，问题往往出在检索步骤上。所以，仔细审视问题的具体内容以及上下文的具体内容，有助于找出问题所在并进行调试。

然后我们可以再深入一层，看看具体是什么内容进入了语言模型——也就是Chat OpenAI本身。在这里，我们可以看到传入的完整提示。它包括一条系统消息，以及所用提示的描述。这就是问答链在底层使用的提示，而我们直到现在才真正看到它。

因此，我们可以看到提示信息打印出来：“使用以下上下文内容来回答用户的问题。如果你不知道答案，就直接说不知道，不要试图编造答案。”然后我们看到之前插入的一大段上下文内容，接着看到一个人工提问，也就是我们向它提出的问题。

我们还可以看到关于实际返回类型的更多信息。因此，不仅仅是返回一个字符串，我们还能获取到一系列信息，比如"token_usage"（令牌使用情况），包括"prompt_tokens"（提示令牌数）、"completion_tokens"（完成令牌数）、"total_tokens"（总令牌数）以及"model_name"（模型名称）。这对于跟踪你在链式调用或语言模型调用过程中使用的令牌数量非常有用，可以帮助你掌握总令牌数，而这与总成本密切相关。

由于这是一个相对简单的链条，我们现在可以看到最终的响应——“The Cozy Comfort Pullover Set, Stripe 确实有侧袋。”——正在通过链条向上传递并返回给用户。我们刚刚逐步了解了如何查看和调试这个链条对单个输入的处理过程。但我们创建的所有示例呢？我们将如何评估这些示例？


与创建它们时类似，一种方法是手动操作。我们可以对所有示例运行链式处理，然后查看输出结果，尝试分析发生了什么，判断其是否正确、错误或部分正确。和创建示例一样，随着时间的推移，这种方法会变得有点繁琐。因此，让我们回到我们最喜欢的解决方案。我们可以让语言模型来完成这项工作吗？首先，我们需要为所有示例创建预测。

在开始之前，我实际上要关闭调试模式，这样就不会把所有内容都打印到屏幕上。然后，我将为所有不同的例子创建预测。我记得我们总共有七个例子，所以我们将循环遍历这个链七次，为每个例子获取一个预测。

既然我们已经有了这些示例，现在可以考虑对它们进行评估了。我们将导入问答评估链（QA evaluation chain），并使用语言模型来创建这个评估链——因为正如之前所说，我们会借助语言模型来协助完成评估工作。接着我们将调用这个评估链的evaluate方法，传入示例和预测结果，最终会获得一系列经过评分的输出结果。

因此，为了了解每个示例的具体情况，我们将逐一查看它们。我们会打印出问题，再次说明，这是由语言模型生成的。我们还会打印出真实答案，同样，这也是语言模型在拥有完整文档的情况下生成的，因此它能提供一个准确的基准答案。

我们将打印出预测答案，这是语言模型在执行问答链时生成的，即通过嵌入和向量数据库进行检索，将结果输入语言模型后尝试推测出的预测答案。

然后我们还要打印出评分，同样，这也是由语言模型生成的，当它要求评估链对正在发生的事情进行评分，判断其正确与否时。因此，当我们遍历所有这些示例并打印出来时，我们可以详细查看每个示例的情况。看起来这里它都答对了。

这是一个相对简单的检索问题，所以这让人放心。让我们来看第一个例子。这里的问题是："Cozy Comfort Pullover Set有侧口袋吗？"。真实的答案是我们创建的，是"有"。语言模型预测的答案是："Cozy Comfort Pullover Set，条纹款确实有侧口袋"。

因此我们可以理解这是一个正确答案。实际上，语言模型也这么认为，并将其判定为正确。但让我们思考一下为什么我们一开始需要使用语言模型。这两个字符串实际上毫无相似之处。它们非常不同。一个非常短，一个非常长。我甚至不认为，"yes"这个词在这个字符串的任何地方出现过。

因此，如果我们尝试进行一些字符串匹配、精确匹配，甚至使用正则表达式，它都不知道该如何处理。它们不是一回事。这显示了在此处使用语言模型进行评估的重要性。你得到的这些答案都是任意的字符串，没有一个绝对正确的字符串是最佳答案。

有许多不同的变体。只要它们具有相同的语义，就应该被评定为相似。这正是语言模型的作用所在，而不仅仅是进行精确匹配。字符串比较的困难正是评估语言模型如此困难的首要原因。我们使用它们来完成这些非常开放的任务，在这些任务中，它们被要求生成文本。

以前从未真正实现过这一点，因为直到最近，模型才足够好到可以做到这一点。因此，到目前为止存在的许多评估指标都不够好。我们不得不发明新的指标，并为此发明新的启发式方法。目前最有趣和最受欢迎的启发式方法实际上是使用语言模型来进行评估。

评估课程到此结束，但最后我想向大家展示的是LangChain评估平台。这个平台可以将我们在笔记本中完成的所有操作持久化，并通过用户界面展示出来。让我们来看看吧。在这里，我们可以看到有一个会话，我们将其命名为deeplearningai。可以看到，我们在笔记本中运行的所有记录都已实际保存下来。

因此，这是从高层次追踪输入和输出的好方法。同时，它也能让你清晰地了解底层究竟发生了什么。这些信息与我们开启调试模式时在笔记本中打印的内容相同，只不过现在以更直观的方式呈现在用户界面上。这样，我们就能逐步查看链式过程中的输入与输出了。

然后我们可以逐步深入点击查看链条中的更多信息，了解实际传递的内容。如果我们一直往下看到最底层，现在就能确切地看到传递给聊天模型的内容。这里有系统消息，有人类提问，还有聊天模型的响应。

我们还有一些输出元数据。另外，我们在这里添加了一个功能，可以将这些示例添加到数据集中。如果你还记得的话，在开始时创建那些示例数据集时，我们部分是手工创建的，部分是使用语言模型创建的。在这里，我们可以通过点击这个小按钮将其添加到数据集中。

现在我们有了输入查询和输出结果。这样我们就可以创建一个数据集。我们可以称之为深度学习。然后我们可以开始向这个数据集中添加示例。再次回到我们在课程开始时处理的那个原始问题，我们需要创建这些数据集以便进行评估。

这种方式非常巧妙，能让它在后台持续运行。然后随着时间的推移不断向示例数据集添加内容，逐步积累这些可用于评估的案例，从而启动这个评估飞轮的运转。

## 7、Agents

有时人们会将大型语言模型视为知识库，仿佛它已学会记忆大量信息（可能来自互联网），因此当你提问时，它就能给出答案。但我认为更有用的理解方式是：大型语言模型有时更像推理引擎——你可以向它输入文本片段或其他信息来源。

然后，大型语言模型（LLM）可能会利用从互联网上学到的背景知识，但也会利用你提供的新信息来帮助你回答问题、推理内容，甚至决定下一步该做什么。而这正是LangChain的Agents框架所擅长的。Agents可能是我最喜欢LangChain的部分。

我认为它们也是最强大的部分之一，但同时也是较新的部分。因此，我们在这里看到了许多对该领域所有人来说都非常新颖的东西。所以当我们深入探讨智能代理是什么、如何创建和使用它们、如何为它们配备不同类型的工具（比如LangChain内置的搜索引擎），以及如何创建你自己的工具，以便让代理能够与你希望它们交互的任何数据存储、API或功能进行互动时，这应该是一堂非常令人兴奋的课程。

这真是令人兴奋的前沿技术，而且已经出现了重要的应用场景。那么，话不多说，让我们开始吧！要开始使用代理（Agents），我们首先要像往常一样导入正确的环境变量。这里还需要安装几个包。我们将使用"duckduckgo-search"搜索引擎和"wikipedia"。

所以我们需要用pip安装这些。我已经在我的环境中安装好了，所以我不会运行这行命令。但如果你们还没安装，应该取消这行的注释，运行它，然后就可以继续了。接着我们要从LangChain导入一些需要的方法和类。我们会导入一些加载工具的方法。这些工具将用于连接语言模型。我们还要加载一个初始化代理的方法。

我们将加载Chat OpenAI的封装器，并加载"AgentType"。"AgentType"将用于指定我们要使用的代理类型。LangChain中有多种不同类型的代理，我们现在不会逐一介绍，而是选择一个并直接使用。接着，我们将初始化要使用的语言模型。再次强调，我们将其作为驱动代理的推理引擎。然后，我们将加载要使用的工具。

所以我们要加载DuckDuckGo搜索和维基百科。这些都是LangChain内置的工具。最后，我们要初始化代理。我们给它传递工具、语言模型和代理类型。这里我们使用的是"CHAT_ZERO_SHOT_REACT_DESCRIPTION"。不会详细解释这是什么意思。需要注意的是聊天。

这是针对聊天模型优化的。然后是React。React是一种提示策略，能够从语言模型中引出更好的思考。我们还将设置"handle_parsing_errors=True"。如果你还记得第一课的内容，我们讨论了很多关于输出解析器的话题，以及如何利用它们将大语言模型的输出（即字符串）解析成我们可以在下游使用的特定格式。

这一点在这里至关重要。当我们获取大语言模型（LLM）输出的文本后，需要将其解析为模型应执行的具体操作和对应的操作输入。现在让我们使用这个智能体。我们向它询问一个模型训练时尚未知晓的近期事件——比如2022年世界杯。这些模型的训练数据截止到2021年左右，因此它本不该知道这个问题的答案。正因如此，它应该意识到需要使用工具来查询这条最新信息。

从这里我们可以看到，智能体意识到需要使用DuckDuckGo搜索引擎，然后查询了2022年世界杯冠军。它获取了大量信息后，却误以为2022年世界杯尚未举办。这个案例很好地说明了为什么智能体技术仍处于探索阶段——虽然它获取了关于2022年世界杯的诸多信息，却未能完全理解已发生的事件全貌，因此需要进一步检索和获取更多信息。

因此，基于这些信息，它可以给出正确的答案：“阿根廷赢得了2022年世界杯”。接下来让我们问它一个问题，它应该能意识到需要使用维基百科。维基百科包含大量关于很久以前特定人物和实体的信息，这些信息不需要是最新的。

那么让我们来问问它关于汤姆·M·米切尔（Tom M. Mitchell）——一位美国计算机科学家的情况。他写了哪本书？我们可以看到，它意识到应该使用维基百科来查找答案。于是它搜索了“汤姆·M·米切尔 维基百科”，然后又进行了一次后续搜索以确保答案的准确性。接着它搜索了“汤姆·M·米切尔 机器学习”，并获得了更多信息。

然后基于此，它最终能够回答“Tom M. Mitchell撰写了《机器学习》这本教科书”。你应该在这里暂停视频，尝试输入不同的内容。到目前为止，我们使用的都是LangChain中已经定义好的工具，但代理的强大之处在于你可以将其连接到自己的信息来源、自己的API和自己的数据。因此，接下来我们将介绍如何创建一个自定义工具，以便你可以将其连接到任何你想要的内容。

让我们开发一个工具来获取当前数据。首先导入这个工具装饰器，它能将任何函数转换为LangChain可用的工具。接着编写名为"time"的函数，该函数接收任意文本字符串（实际不会使用此参数），并通过调用datetime返回当天日期。除了函数名称外，我们还会编写非常详细的文档字符串。

这是因为代理将使用这些信息来确定何时调用该工具以及如何调用该工具。例如，这里我们说：“输入应该始终是一个空字符串。”这是因为我们并没有使用它。如果我们对输入内容有更严格的要求，例如，如果我们有一个函数应该始终接收一个搜索查询或SQL语句，你就要确保在这里提到这一点。

现在我们将创建另一个智能体。这次我们要在现有工具列表中添加时间工具。最后，让我们调用这个智能体并询问今天的日期。它识别出需要使用时间工具，并在此处进行了指定。其动作输入为空字符串。这很棒，完全符合我们的指令。随后它返回了一个观察结果。

最后，语言模型会接收这一观察结果，并回应用户："今天的日期是2023-05-21"。建议你在此处暂停视频，尝试输入不同的内容。关于智能体的课程就到这里。这是LangChain中较新、更令人兴奋且更具实验性的部分之一。希望你喜欢使用它。但愿它能向你展示如何将语言模型用作推理引擎，执行不同的操作并连接到其他功能与数据源。


## 总结

在这门短期课程中，您见识了一系列应用案例，包括处理客户评论、构建文档问答应用程序，甚至使用大型语言模型来决定何时调用外部工具（如网络搜索）来解答复杂问题。

如果一两周前有人问你，开发所有这些应用程序需要多少工作量？我想很多人会觉得，"天啊，这听起来要好几周，甚至更长时间"。但在这个短期课程中你看到了，只需相当合理的代码量，就能用LangChain高效地构建所有这些应用。

希望你能采纳这些想法，甚至可以把在Jupyter Notebook中看到的代码片段用到你自己的应用程序中。这些想法仅仅是个开始。语言模型还有很多其他应用场景。这些模型之所以如此强大，是因为它们适用于如此广泛的任务，无论是回答关于CSV文件的问题、查询SQL数据库，还是与API交互。

LangChain中有许多使用链、提示组合和输出解析器以及更多链来完成所有这些任务的不同示例。这主要归功于LangChain社区。因此，我也想向社区中所有做出贡献的人表示衷心的感谢，无论是改进文档、帮助他人更容易上手，还是开发新型链式工具，开辟全新的可能性世界。所以，如果你还没有这样做的话，我希望你能打开你的笔记本电脑或台式机，运行pip install LangChain，然后使用这个工具去构建一些令人惊叹的应用程序。

----------------------

下来我们将定义两个辅助函数。第一个是我们所有视频中一直在使用的"get_completion"函数。仔细看这个函数会发现，我们虽然传入的是提示词，但在函数内部实际上是将这个提示词包装成了类似用户消息的形式。这是因为ChatGPT模型本质上是一个对话模型，其训练方式决定了它需要接收一系列消息作为输入，然后返回模型生成的消息作为输出。

所以用户消息是输入，而助手消息是输出。在这个视频中，我们将实际使用一个不同的辅助函数，不再是将单个提示作为输入并获取单个完成结果，而是传入一个消息列表，这些消息可以来自各种不同的角色。

我来描述一下这些内容。这里有一个消息列表的例子，第一条消息是系统消息，它给出了一个总体指令。在这条消息之后，用户和助手之间会进行轮换对话，这种对话会持续进行。如果你使用过ChatGPT的网页界面，那么你的消息就是用户消息，而ChatGPT的回复则是助手消息。

因此，系统消息有助于设定助手的行为和角色，它就像是对话的高级指令。你可以把它想象成在助手耳边低语，引导它的回应，而用户却察觉不到系统消息的存在。作为用户，如果你曾经使用过ChatGPT，你可能并不知道ChatGPT的系统消息里有什么内容。

系统消息的好处在于，它为开发者提供了一种在不将请求本身纳入对话的情况下引导对话的方式。这样，你可以在用户不知情的情况下悄悄引导助手，影响其回应方式。现在，让我们尝试在对话中使用这些消息。

因此，我们将使用新的辅助函数从消息中获取回复。同时，我们还采用了更高的温度参数。系统消息写道："你是一个说话像莎士比亚的助手"。这相当于我们在向助手描述它应有的行为方式。接着，第一条用户消息是："给我讲个笑话"。下一条是："鸡为什么过马路？"最后一条用户消息则是："我不知道。"

那么如果我们运行这个程序，响应会是“去另一边”。让我们再试一次。“去另一边，尊敬的先生或女士”。这是一个古老而经典的笑话，永远不会过时。这就是我们的莎士比亚式回应。实际上，让我们再尝试一件事。因为我想更清楚地表明这是助手的消息。所以在这里，我们直接打印出整个消息响应。只是为了让它更加清晰。

此回复为助手消息。因此角色为助手，内容即为消息本身。这就是这个辅助函数的作用——我们只是传递消息的内容。现在让我们再举一个例子。这里我们的消息包括：系统消息是"你是一个友好的聊天机器人"，第一条用户消息是"你好，我叫伊萨"。我们想要获取的就是第一条用户消息。

那么让我们来执行第一条助手消息。第一条消息是：“你好，Isa！很高兴认识你。今天有什么可以帮你的吗？”现在让我们再试一个例子。这里的消息包括系统消息“你是一个友好的聊天机器人”和第一条用户消息“是的，你能提醒我我的‘名字’是什么吗？”，然后我们来看回复。如你所见，模型实际上并不知道我的名字。

因此，与语言模型的每次对话都是一次独立的互动，这意味着你必须提供当前对话中所有相关的信息供模型参考。如果你希望模型能够参考或“记住”对话的早期部分，你必须在输入中提供之前的交流内容。

因此，我们将其称为上下文。让我们试试这个。现在，我们已经在前面的消息中提供了模型所需的上下文，即我的名字，然后我们会问同样的问题，问我的名字是什么。模型能够回答，因为它在我们输入的消息列表中有它需要的所有上下文。

现在你要开始构建自己的聊天机器人了。这个机器人将命名为"订单助手"，我们将通过自动化收集用户提示和助手回复来打造这个"订单助手"。它将负责披萨餐厅的订单处理，首先我们会定义这个辅助函数，它的作用是收集用户消息，这样我们就不需要像之前那样手动重复输入了。这个函数会从我们稍后构建的用户界面收集提示，并将其添加到一个名为"context"的列表中，之后每次都会带着这个上下文来调用模型。

然后，模型的响应也会被添加到上下文中，因此这类模型消息会被添加到上下文里，用户消息同样如此，以此类推，所以上下文会变得越来越长。这样模型就能获得所需的信息来决定下一步该做什么。接下来，我们将设置并运行这种用户界面来展示Autobot。这就是上下文，其中包含了带有菜单的系统消息。

请注意，每次我们调用语言模型时，都会使用相同的上下文，而这个上下文会随着时间的推移不断累积。然后让我们执行这个操作。好的，我要说：“嗨，我想点一个披萨。”助手回答说：“太好了，您想点哪种披萨？我们有意大利辣香肠披萨、奶酪披萨和茄子披萨。”嗯。“它们多少钱？”很好，我们有价格了。我觉得我想要一个中号的茄子披萨。所以你可以想象，我们可以继续这个对话。

让我们来看看我们在系统消息中放了什么内容。比如：“你是Autobot，一个为披萨餐厅收集订单的自动化服务。你首先问候顾客，然后收集订单，接着询问是自取还是外送。你会等待收集完整个订单，然后进行总结，并最后一次确认顾客是否还需要添加其他东西。如果是外送，你可以询问地址。”

最后，你收取款项。务必确认所有选项、额外配料和尺寸，以便从菜单中准确识别商品。你的回应要简短、口语化且友好。菜单包括……”，然后，这里是菜单。那么，让我们回到对话中，看看助手是否遵循了指示。好的，很好，助手询问我们是否需要额外配料，这一点我们在系统消息中已经提到过。所以，我想我们不需要任何额外配料。

当然可以。"您还想点些别的吗？" 来点水吧。其实，薯条也不错。要小份还是大份？这很棒，因为我们之前在系统消息里让助手明确了附加项和配菜。这样你就明白了，请随意自己试试看。你可以暂停视频，直接在左边的笔记本里运行这段代码。现在，我们可以让模型根据对话生成一个JSON摘要，以便发送给订单系统。

因此，我们现在要附加另一条系统消息，这是一条指令，内容是：“创建一份之前食物订单的JSON摘要。列出每个项目的价格。字段应包括：1) 披萨，包含配菜，2) 配料列表，3) 饮料列表，4) 配菜列表”，最后是总价。你也可以在这里使用用户消息，不一定非要是系统消息。那么，让我们执行这个操作。

请注意，在这种情况下，我们使用的是较低的温度参数，因为对于这类任务，我们希望输出结果相对可预测。如果是对话型AI，你可能会想用更高的温度值。但就这个案例而言，我可能也会选择较低温度，因为对于客户服务聊天机器人来说，你可能同样希望输出结果更具可预测性。现在，我们来看下订单摘要。

因此，如果我们愿意的话，就可以把这个提交到订单系统中。好了，你已经构建了自己的订单聊天机器人。你可以自由地自定义它，调整系统消息来改变聊天机器人的行为，让它扮演不同角色、拥有不同知识。


## 9、总结

恭喜你完成了这门简短课程的学习。总结一下，在这门短课程中，你学到了提示的两个关键原则：写出清晰具体的指令，并在适当的时候给模型留出思考的时间。你还学习了迭代式提示开发，以及如何通过一个流程找到适合你应用的提示是关键所在。

我们探讨了大语言模型在多种应用场景中的实用功能，特别是总结、推理、转换和扩展。你还学习了如何构建自定义聊天机器人。在这短短的一门课程中，你学到了很多知识，希望你享受这些学习内容。我们期待你现在能萌生出一些自己可以开发的应用创意。

请去尝试一下，然后告诉我们你的成果。项目再小都没关系，可以从一个非常小的项目开始，可能只有一点点实用性，甚至可能根本没什么用，只是好玩而已。是的，我发现摆弄这些模型真的很有趣，所以去试试吧！我同意，根据经验来说，这是个很好的周末活动。嗯，还有，请用你第一个项目的经验来打造一个更好的第二个项目，甚至可能还有更好的第三个项目，以此类推。


我认为在这个时代，构建人工智能系统的人可以对他人产生巨大影响。因此，比以往任何时候都更重要的是，我们所有人都要负责任地使用这些工具。嗯，我认为目前构建基于大型语言模型的应用程序是一个非常令人兴奋且不断发展的领域。

现在你已经完成了这门课程，我认为你已经掌握了丰富的知识，能够构建出当今很少有人懂得如何实现的东西。因此，我也希望你能帮助我们传播这门课程，鼓励其他人也来学习。最后，我希望你在学习这门课程的过程中感到愉快，并感谢你完成了这门课程。我和Ezra都期待着听到你构建出的惊人成果。

