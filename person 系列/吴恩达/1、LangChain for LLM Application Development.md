
欢迎来到这门关于LangChain的大语言模型应用开发短期课程。通过提示一个LLM（大语言模型），现在开发AI应用的速度比以往任何时候都要快得多。但一个应用可能需要多次提示LLM并解析其输出，因此需要编写大量的胶水代码。

LangChain由Harrison Chase创建，使这一开发过程变得更加容易。我很高兴Harrison能来到这里，他与DeepLearning.ai合作构建了这个短期课程，教授如何使用这个神奇的工具。感谢邀请我。能来到这里我真的很兴奋。LangChain最初是一个用于构建LLM应用程序的开源框架。

当时我正在与这个领域的一群开发者交流，他们正在构建更复杂的应用程序，我注意到他们在开发过程中采用了一些共同的抽象模式。到目前为止，LangChain在社区的采用情况让我们感到非常兴奋。我期待在这里与大家分享它，也期待看到人们用它构建出什么样的应用。

事实上，作为LangChain发展势头的体现，它不仅拥有众多用户，还有数百名开源贡献者，这对它的快速发展起到了关键作用。这个团队确实以惊人的速度推出代码和功能。因此，希望在这个简短的课程之后，你能够使用LangChain快速构建一些非常酷的应用程序，谁知道呢，也许你甚至会决定为开源LangChain项目做出贡献。

LangChain是一个用于构建大语言模型（LLM）应用程序的开源开发框架。我们提供两个不同的软件包，一个是Python版本，另一个是JavaScript版本。它们都注重组合性和模块化设计，因此包含许多可以单独使用或相互配合的独立组件，这是其核心价值之一。另一个核心价值是它支持多种不同的应用场景。

因此，通过将这些模块化组件组合成更端到端的应用程序链，可以非常容易地开始这些用例。在本课程中，我们将介绍LangChain的常见组件。我们将讨论模型。我们将讨论提示，这是让模型做有用和有趣的事情的方式。

我们将讨论索引，这是一种数据摄取方式，使您能够将数据与模型结合使用。然后我们会谈到链，这是更端到端的用例，以及代理，这是一种非常令人兴奋的端到端用例，它将模型用作推理引擎。

我们还要感谢Ankush Gola，他是与Harrison Chase共同创立LangChain的联合创始人，他也对这些材料投入了大量思考，并协助创建了这门短期课程。在DeepLearning.AI方面，Geoff Ludwig、Eddy Shyu和Diala Ezzeddine也为这些材料做出了贡献。那么接下来，让我们进入下一个视频，我们将学习LangChain的模型、提示和解析器。

----------------------

 JSON 格式提供，包含以下键：book ID、title、author 和 genre。正如你所看到的，我们得到了三个虚构的书名，并以这种漂亮的 JSON 结构化输出呈现。这样做的好处是，你可以直接用 Python 将其读入字典或列表中。

*下一个策略是要求模型检查条件是否满足*。因此，如果任务假设不一定成立，我们可以告诉模型先检查这些假设。如果不满足，就指出这一点，并停止完整的任务完成尝试。你可能还需要考虑潜在的边缘情况，以及模型应如何处理它们，以避免意外的错误或结果。

那么现在，我将复制一段文字。这段文字只是描述泡一杯茶的步骤。然后我会复制我们的提示语。提示语是：你将获得用三重引号分隔的文本。如果其中包含一系列指令，请按照以下格式重写这些指令，并仅列出步骤。如果文本不包含指令序列，则只需写下“未提供步骤”。因此，如果我们运行这个单元格，你会看到模型能够从文本中提取出指令。

现在，我要用同样的提示词尝试另一个段落。这个段落只是在描述一个晴朗的日子，里面没有任何指令。所以，如果我们使用之前相同的提示词，但在这个文本上运行，模型会尝试提取指令。如果没有找到任何指令，我们就让它直接回答“未提供步骤”。那么让我们来运行这个。模型判定第二段中没有指令。

因此，我们*针对这一原则的最终策略就是我们所说的少样本提示*。这只是在要求模型执行你希望它做的实际任务之前，提供一些成功执行该任务的示例。让我给你看一个例子。在这个提示中，我们告诉模型它的任务是以一致的风格回答问题。因此，我们有了这样一个孩子与祖父母之间对话的例子。孩子说：“教我耐心。”祖父母则用这些隐喻来回应。既然我们已经告诉模型要以一致的语调回答，现在我们说：“教我韧性。”由于模型已经有了这几个示例，它会以类似的语调回应下一条指令。因此，韧性就像一棵随风弯曲却永不折断的树，如此等等。那么，这就是我们*第一原则的四个策略*，即给模型提供清晰而具体的指令。


*我们的第二原则是给模型思考的时间*。如果模型因急于得出错误结论而出现推理错误，你应该尝试重新构建查询，要求模型在提供最终答案之前进行一系列相关的推理。

另一种思考方式是，如果你给模型一个过于复杂的任务，以至于它无法在短时间内或用少量文字完成，它可能会做出一个猜测，而这个猜测很可能是错误的。你知道，这种情况在人身上也会发生。如果你要求某人在没有时间先算出答案的情况下完成一道复杂的数学题，他们也可能会犯错。因此，在这些情况下，你可以指示模型花更多时间思考问题，这意味着它在任务上投入更多的计算资源。

那么现在，我们将讨论第二个原则的一些策略。我们也会做一些示例。我们的*第一个策略是明确完成一项任务所需的步骤*。首先，让我复制一段文字。在这段文字中，我们只是描述了杰克和吉尔的故事。好的，现在我将复制一个提示。在这个提示中，指令是执行以下操作。

首先，用一句话总结由三重反引号分隔的以下文本。其次，将摘要翻译成法语。第三，列出法语摘要中的每个名字。第四，输出一个包含以下键的 JSON 对象：法语摘要和名字数量。然后我们希望用换行符分隔答案。因此，我们添加文本，也就是这一段。那么如果我们运行这个程序。如你所见，我们有摘要文本。然后是法语翻译。接着是人名部分。有意思的是，它给这些人名加了个法语标题。之后就是我们请求的 JSON 数据了。

现在我要展示另一个提示词来完成同样的任务。在这个提示词中，我采用了一种个人偏好的格式来明确指定模型的输出结构——因为正如本例所示，这个人名标题是法语的，而这可能并非我们想要的效果。如果我们直接传递这个输出，可能会有点困难且难以预测，有时它可能会显示名称，有时又可能显示，比如这个法语标题。因此，在这个提示中，我们提出了类似的要求。提示的开头部分是一样的，所以我们只是要求相同的步骤，然后我们要求模型使用以下格式，因此，我们只是明确指定了确切的格式：文本、摘要、翻译、名称和输出 JSON。

然后我们一开始只需说要总结的文本，甚至可以直接说“文本”。然后这和之前的文本是一样的。所以让我们运行这个。如你所见，这就是完成的结果，模型已经按照我们要求的格式输出了。所以，我们已经给了它文本，然后它给我们提供了摘要、翻译、名称和输出的 JSON。因此，这有时很好，因为通过代码传递会更容易，因为它有一种更标准化的格式，你可以预测。另外，请注意，在这种情况下，我们使用了尖括号作为分隔符，而不是三重反引号。你可以选择任何对你和模型有意义的分隔符。

我们的*下一个策略是指导模型在匆忙得出结论之前先自行思考解决方案*。同样，有时当我们明确指示模型在得出结论之前先进行推理时，会得到更好的结果。这与我们之前讨论的理念类似，即给模型足够的时间去真正解决问题，而不是像人一样直接判断答案是否正确。

因此，在这个提示中，我们要求模型判断学生的解答是否正确。首先给出数学题目，然后是学生的解答。实际上，学生的解答是错误的，因为他们将维护成本计算为 100,000+100x，但实际上应该是 10x，因为每平方英尺的成本仅为 10 美元，其中 x 是他们定义的隔热层面积（平方英尺）。所以，这里实际上应该是360x加上100,000，而不是450x。如果我们运行这个单元格，模型会说学生的解答是正确的。如果你仔细阅读学生的解答，我自己其实也计算错了，因为乍一看这个回答似乎是对的。如果你只看这一行，这一行是正确的。因此，模型只是简单地同意了学生的答案，因为它和我一样只是粗略地看了一下。

因此，我们可以通过指示模型先自行找出解决方案，然后将自己的方案与学生的方案进行比较来解决这个问题。让我展示一个实现这一点的提示。这个提示要长得多。在这个提示中，我们告诉模型：你的任务是判断学生的解决方案是否正确。要解决这个问题，请执行以下步骤。首先，自己动手解决问题。然后，将你的解法与学生的解法进行比较，评估学生的解法是否正确。在你亲自解决问题之前，不要判断学生的解法是否正确。或者更明确地说，确保你自己亲自解决问题。因此，我们基本上采用了相同的技巧，使用了以下格式。所以，格式会是问题、学生的解答、实际解答，然后判断解答是否一致，是或否，接着是学生成绩，正确或错误。那么，我们这里的问题和解答与上面相同。现在，如果我们运行这个单元格……如你所见，模型实际上已经过了一遍，并且先进行了自己的计算。然后，它得到了正确答案，即360x加上100,000，而不是450x加上100,000。接着，当被要求将其与学生的解答进行比较时，它意识到两者并不一致。因此，学生实际上是错的。这个例子展示了如何通过让模型自行计算并将任务分解为多个步骤，给模型更多思考时间，从而获得更准确的回答。

那么接下来，我们将 *讨论模型的一些局限性*，因为在开发基于大语言模型的应用时，牢记这些限制非常重要。尽管语言模型在训练过程中接触了大量知识，但它并未完美记住所看到的信息，因此它并不十分清楚自身知识的边界。这意味着它可能会尝试回答一些冷门话题的问题，并编造出听起来合理但实际上并不正确的内容。我们称这些虚构的想法为"幻觉"。

因此，我将向你展示一个模型产生幻觉的例子。这是一个模型虚构出某真实牙刷公司一款不存在的产品名称并进行描述的例子。提示词是："告诉我关于 Boy 公司的 AeroGlide Ultra Slim 智能牙刷的信息"。如果我们运行这个提示，模型会给出一个听起来相当逼真的虚构产品描述。这种情况之所以可能具有危险性，是因为它听起来确实非常真实。

因此，在构建自己的应用程序时，请务必运用我们在本笔记本中介绍的一些技巧，尽量避免这种情况。要知道，这是这些模型的一个已知弱点，也是我们正在积极努力解决的问题。还有一个减少幻觉的额外策略，就是如果你想让模型基于某段文本生成答案，可以先让模型从文本中找到相关的引用，然后再让它利用这些引用来回答问题。能够将答案追溯到源文件的方法通常对于减少这些幻觉非常有帮助。就是这样！你已经完成了提示指南的学习，接下来你将进入下一个视频，该视频将介绍迭代式提示开发过程。

## 3、Iterative

在我使用大型语言模型构建应用程序的过程中，从未有过第一次尝试就能得到最终应用所需提示词的情况。但这并不重要。只要你能通过迭代不断优化提示词，最终就能找到适合实现目标任务的优质方案。

你可能听我说过，当我训练一个机器学习模型时，它几乎从未在第一次就成功。事实上，我第一次训练的模型能成功运行，这让我非常惊讶。我认为在使用提示时，第一次就成功的概率可能会稍微高一些，但正如他所说，第一次提示是否成功并不重要，最重要的是找到适合你应用的提示的过程。

那么，接下来让我们直接进入代码部分，我来介绍一些框架，帮助大家思考如何迭代式地开发提示词。好的。如果你之前上过我的机器学习课程，可能见过我用一张图来说明机器学习开发的过程：通常你有了一个想法，然后去实现它。也就是说，编写代码、获取数据、训练模型，最终得到实验结果。

然后你可以查看输出结果，进行错误分析，找出哪些部分有效或无效，甚至可能改变你对要解决的问题或解决方法的想法。接着修改实现方式，进行另一次实验，如此反复迭代，最终得到一个高效的机器学习模型。

如果你不熟悉机器学习，之前没见过这张图，也不用担心。这对接下来的演示并不重要。但在使用大语言模型开发应用程序时，编写提示的过程可能非常相似：你有一个想要完成的任务或想法，然后可以初步尝试编写一个提示，希望它清晰明确，如果合适的话，还可以给系统一些思考的时间。

然后你可以运行它，看看得到什么结果。如果第一次效果不够好，那么通过迭代过程找出原因——比如指令不够清晰，或者没有给算法足够的思考时间——就能让你改进想法、优化提示词，如此反复多次，直到最终得到一个适用于你应用的提示词。

这也是为什么我个人不太关注那些号称 “30 个完美提示词” 的网络文章，因为我认为，世界上可能并不存在适用于所有情况的完美提示词。更重要的是，你要有一套针对具体应用场景开发优质提示词的方法。那么，让我们通过代码示例来一起看看。

我这里有你之前视频中看到的初始代码，已经导入了 OpenAI 和 OS 模块。这里我们获取了 OpenAI 的 API 密钥，这个辅助函数和你上次看到的是一样的。在本视频中，我将以总结椅子产品说明书作为示例任务。现在我把内容粘贴到这里。如果你想更仔细地阅读，可以随时暂停视频查看左侧笔记本中的内容。

但这里有一把椅子的产品说明书，描述称其属于一个受中世纪风格启发的美丽系列，诸如此类。说明书介绍了椅子的构造、尺寸、可选配置、材质等信息。这把椅子产自意大利。假设你想利用这份说明书，帮助营销团队为在线零售网站撰写产品描述。

让我快速运行这三个，然后我们会提出一个提示如下，我就……我就把这个粘贴进去。所以我的提示是这样的：你的任务是帮助营销团队根据技术说明书为零售网站创建一个产品描述，编写产品描述等等。对吧？这是我第一次尝试向大型语言模型解释这个任务。让我按下 Shift+Enter，这需要几秒钟来运行，然后我们得到了这个结果。

看起来它在撰写描述方面做得不错，介绍了一把惊艳的中世纪风格办公椅，完美之选等等。但当我看到这个时，我不禁感叹，这确实太长了。它确实按照我的要求完成了任务，即从技术参数表开始撰写产品描述。但当我看到这个时，我觉得这有点冗长。或许我们想要它再简洁一些。

所以，我有了一个想法，写了一个提示语，得到了一个结果。我对这个结果不太满意，因为它太长了。于是，我会进一步明确我的提示语，要求用不超过 50 个词来更好地指导期望的长度。让我们再试一次。好的。这次看起来是一个更简洁的产品描述，介绍了一款受中世纪风格启发的办公椅，等等。

你们五个刚刚的表现，既时尚又实用，还不错。让我再确认一下这段内容的长度。我会把回复按空格分开，然后打印出字数。总共52个单词，其实还不错。大语言模型还行，但在遵循非常精确的字数指令方面并不那么出色。不过这次其实挺不错的。

有时候它会打印出 60 或 65 个单词之类的内容，但还算合理。你可以尝试一些方法，比如规定最多使用三个句子。让我再试一次。这些都是告诉大型语言模型你期望输出长度的不同方式。现在是一、二、三，我数到三个句子，看来我做得不错。

此外，我还注意到人们有时会采取这样的做法——比如限制在最多 280 个字符。由于大语言模型通过分词器处理文本（这里就不展开讨论分词器原理了），它们在字符计数方面往往表现平平。不过你看，281 个字符，这次居然出人意料地接近。通常大语言模型很难把控得如此精准。但这些都是可以用来调控输出长度的有趣方法。

但让我把它切换回最多使用 50 个单词。这就是我们刚才得到的结果。在我们继续为网站优化这段文字时，我们可能会觉得，哎呀，这个网站并不是直接面向消费者销售的，实际上是面向家具零售商销售家具的，他们可能对椅子的技术细节和材质更感兴趣。

既然如此，你可以拿着这个提示语说：我想修改这个提示语，让它更精确地描述技术细节。那我就继续修改这个提示语。我会说，这个描述是针对家具零售商的，所以应该技术性强，重点关注材料、产品和构造方式。好，让我们运行一下看看效果。

还不错，比如，你知道的，涂层铝制底座和气动椅身，都是高品质材料。通过调整提示词，你可以让它更专注于特定的特征或你想要的特定属性。当我看到这个时，可能会决定在描述的最后加上产品 ID。这把椅子有两个型号，SWC 110 和 SWC 100。所以，也许我可以进一步优化这个提示词。

为了让它给我产品 ID，我可以在描述末尾添加这条指令：在技术规格中包含所有 7 字符的产品 ID。让我们运行一下，看看会发生什么。于是它显示：为您介绍我们的 Miss Agents 5 办公椅，外壳颜色，谈到塑料涂层、铝制底座、实用性，一些选项，还提到了两个产品 ID。看起来效果不错。你刚才看到的就是许多开发者都会经历的迭代式提示开发的简短示例。

我认为，一个指导原则是，在上一个视频中，你看到伊莎分享了一些最佳实践。所以，我通常的做法是牢记这些最佳实践，保持清晰和具体，并在必要时给模型时间思考。记住这些要点后，值得经常先尝试写一个提示，看看效果如何，然后在此基础上不断迭代优化提示，逐步接近你所需的结果。

因此，许多你在各种程序中看到的成功提示词，都是通过类似这样的迭代过程得出的。为了好玩，让我给你展示一个更复杂的提示词例子，或许能让你感受到 ChatGPT 的能力。这次我多加了几条指令：在描述之后，包含一个表格列出产品尺寸，然后将所有内容格式化为 HTML。

那么，我们来运行一下。实际上，你最终得到的提示词大概是这样的，这真的需要经过多次迭代才能完成。我不认为有谁能在第一次尝试让系统处理一份资料表时就写出这么精确的提示词。然后，这实际上输出了一大堆 HTML 代码。让我们展示一下这段 HTML，看看它是否是有效的 HTML，是否能够正常运行。其实我也不确定它是否能运行，但让我们拭目以待。哦，太棒了。好的。

看起来已经渲染完成了。这里有一段关于椅子的非常精美的描述，包括构造、材质和产品尺寸等信息。哦，我好像漏掉了"最多50字"的提示要求，所以这段描述有点长。不过如果你想调整的话，完全可以暂停视频，要求它更简洁些，然后重新生成看看效果如何。希望通过这个视频你能明白，提示词的优化是一个需要不断迭代的过程。

尝试一些方法，看看它是否还不能完全满足你的需求，然后思考如何更清晰地表达你的指令，或者在某些情况下，考虑如何给予它更多思考的空间，使其更接近你期望的结果。我认为，成为一个高效的提示工程师的关键并不在于知道完美的提示，而在于拥有一个良好的流程来开发适合你应用的有效提示。

在这个视频中，我演示了如何仅用一个例子来开发提示。对于更复杂的应用场景，有时你会用到多个例子，比如 10 个、甚至 50 或 100 个情况说明的列表，然后通过迭代开发提示并针对大量案例进行评估。

但对于大多数应用的早期开发阶段，我发现很多人和我一样，只用一个示例来开发。不过，对于更成熟的应用，有时评估针对更大示例集的提示可能会很有用，例如在几十份资料表上测试不同的提示，看看在多个资料表上的平均或最差表现如何。

但通常情况下，只有当应用程序较为成熟时，你才会这样做，并且需要这些指标来推动提示改进的最后几步。因此，请务必尝试使用 Jupyter 代码笔记本示例，尝试不同的变化，看看能得到什么结果。完成后，让我们继续观看下一个视频，在那里我们将讨论大型语言模型在软件应用中的一个非常常见的用途，即文本摘要。当你准备好后，让我们一起进入下一个视频。

## 4、Summarizing

当今世界充斥着大量文本，我们几乎没有人有足够的时间去阅读所有我们希望有时间阅读的内容。因此，我认为大型语言模型最令人兴奋的应用之一就是用它来总结文本。我看到多个团队正在将这一功能构建到各种软件应用中。你也可以在 ChatGPT 的网页界面中实现这一点。

我经常这样做来总结文章，这样我就能比以前阅读更多文章的内容。如果你想更程序化地实现这一点，这节课你会学到方法。那么，接下来我们就深入代码，看看如何自己动手实现文本摘要功能。首先，我们从之前见过的初始代码开始：导入OpenAI，加载API密钥，以及那个get completion辅助函数。

我将以总结这篇产品评论的任务作为运行示例。给我女儿的生日买了这个熊猫毛绒玩具，她非常喜欢，走到哪儿都带着它，诸如此类。如果你正在建立一个电子商务网站，并且有大量评论，拥有一个工具来总结冗长的评论可以让你更快地浏览更多评论，更好地了解所有客户的想法。

所以，这是一个生成摘要的提示。你的任务是从电商网站的产品评论中生成一个简短的摘要，总结下面的评论，等等，最多30个字。嗯，这个熊猫毛绒玩具柔软可爱，女儿很喜欢，就是价格有点贵，尺寸偏小，但到货很快。还不错，算是个挺好的总结。

正如你在上一个视频中所看到的，你还可以通过控制字符数或句子数量来调整摘要的长度。有时，在创建摘要时，如果你对摘要有一个非常具体的目的，例如你想向运输部门提供反馈，你也可以修改提示词以反映这一点，这样他们就能生成一个更适用于你企业中某个特定群体的摘要。

例如，如果我要给运输部门提供反馈，假设我将此改为开始关注任何提及产品运输和交付的方面。如果我运行这个，那么，你会再次得到一个摘要，但它不再以“柔软可爱的熊猫毛绒玩具”开头，而是现在专注于它比预期提前一天到达的事实。

然后它还有，你知道的，其他细节。或者再举个例子，如果我们不是要给他们的运输部门提供反馈，而是假设我们想给定价部门提供反馈。定价部门负责确定产品的价格，我会告诉它专注于与价格和感知价值相关的任何方面。

然后，系统会生成一个不同的摘要，指出可能某个尺码的价格偏高。在我为物流部门或定价部门生成的摘要中，会更多地聚焦于与这些特定部门相关的信息。事实上，你现在可以暂停视频，尝试让系统为负责产品用户体验的产品部门生成信息，或者为其他你认为对电商网站可能有用的内容生成摘要。

但在这些摘要中，尽管它生成了与运输相关的信息，但也包含了一些其他信息，这些信息你可能认为有用，也可能没用。因此，根据你想要的摘要方式，你也可以要求它提取信息，而不是进行摘要。这里有一个提示，说你的任务是提取相关信息，以便向运输部门提供反馈。

现在它只显示“产品比预期提前一天到达”，而没有了其他信息。这些信息在总体摘要中很有帮助，但如果运输部门只想了解运输情况，这些信息就不够具体。最后，让我用一个具体例子来说明如何在流程中使用这个功能，以帮助汇总多条评论，使其更易于阅读。以下是几条评论。

这篇评论有点长，但你知道的，这是对一款落地灯的第二次评价，卧室里需要一盏灯。这是对电动牙刷的第三次评价，我的牙科保健师推荐了一篇关于电动牙刷的长篇评论。这是对搅拌机的评价，他们说17p系统在季节性促销，诸如此类等等。

这实际上有很多文字。如果你愿意，可以暂停视频，仔细阅读所有这些文字。但如果你不想停下来详细阅读，而是想知道这些评论者写了什么，该怎么办呢？所以，我要把第一条评论设置为我们在上面看到的产品评论。然后，我会把所有这些评论放入一个列表中。现在，如果我实现或遍历这些评论，那么，这是我的提示。

我让它用最多20个词来总结。然后我们获取响应并打印出来。运行后，它会依次输出：熊猫玩具的评论摘要、台灯的评论摘要、牙刷的评论摘要，最后是搅拌机的评论摘要。

因此，如果你有一个拥有数百条评论的网站，你可以想象如何利用这一点来构建一个仪表板，处理大量评论，生成简短的摘要，这样你或其他人就可以更快地浏览评论。然后，如果他们愿意，还可以点击查看原始的长篇评论。

这能帮助你更高效地了解所有客户的想法，对吧？总结部分就到这里。希望你能想象到，如果你的应用中有大量文本，如何利用这类提示来总结它们，帮助人们快速了解文本内容（尤其是大量文本内容），并且如果他们愿意，还可以选择深入挖掘更多信息。

在下一个视频中，我们将探讨大型语言模型的另一项能力——通过文本进行推理。比如，如果你再次面对产品评论，并希望快速了解哪些评论表达了正面或负面情绪，该如何操作？让我们在下一个视频中看看具体实现方法。

## 5、Inferring

下一个视频将介绍推理任务。我喜欢把这些任务看作是模型接收文本输入并进行某种分析的过程。这可能包括提取标签、提取名称、理解文本的情感倾向等等。

因此，如果你想从一段文本中提取情感（无论是积极的还是消极的），在传统的机器学习工作流程中，你必须收集标注数据集、训练模型、想办法将模型部署到云端某个地方并进行推理。虽然这种方法可能效果不错，但你知道，整个过程需要耗费大量精力。

对于每项任务，比如情感分析、提取名称或其他任务，你都需要训练和部署一个单独的模型。大型语言模型的一个真正优点是，对于许多类似的任务，你只需编写一个提示，它几乎可以立即开始生成结果。这在应用程序开发方面提供了巨大的速度优势。

而且，你还可以只使用一个模型、一个 API 来完成许多不同的任务，而不需要弄清楚如何训练和部署许多不同的模型。那么，接下来让我们直接进入代码，看看如何利用这一点。这是我们通常的起始代码。我直接运行它。我要使用的最合适的例子是一个关于台灯的评论。

所以，“卧室需要一盏漂亮的灯，这款还带有额外的储物空间”等等。那么，我来写一个提示来对这句话的情感进行分类。如果我想让系统告诉我，你知道的，情感是什么。我可以直接写，“以下产品评论的情感是什么”，加上常用的分隔符和评论文本等等，然后我们来运行这个。

这上面写着：“产品评论的情绪是积极的。”，实际上，这看起来相当正确。这盏灯并不完美，但这位顾客似乎相当满意。看起来这是一家关心顾客和产品的好公司。我认为积极的情绪似乎是正确的答案。

现在这段文字会输出完整的句子：“该产品评论的情感倾向是积极的。”如果你想得到一个更简洁的回复以便于后续处理，我可以修改这个提示，添加另一条指令，让你只用一个词来回答，要么是“积极的”，要么是“消极的”。

所以它只是像这样输出积极的内容，这样更容易让一段文本获取这个输出并处理它，然后进行一些操作。让我们看看另一个提示，还是使用灯的评价。在这里，我说：“识别以下评价作者表达的情感列表。列表中不超过五个项目。”

因此，大型语言模型非常擅长从一段文本中提取特定的内容。在这个例子中，我们正在表达情感，这对于理解客户对某一特定产品的看法很有帮助。对于许多客户支持组织来说，了解某个用户是否非常不满是很重要的。

所以，你可能会遇到这样的不同分类问题：“以下评论的作者是否表达了愤怒？”因为如果有人真的很愤怒，可能需要额外关注这条客户评论，让客户支持或客户成功团队介入，了解情况并为客户解决问题。

在这种情况下，客户并没有生气。请注意，对于监督学习来说，如果我想要构建所有这些分类器，根本不可能在短短几分钟内完成，就像你在视频中看到的那样。我建议你暂停视频，尝试修改其中的一些提示。

或许可以询问顾客是否表示满意，或者询问是否有任何缺失的部件，看看能否通过提示对这条灯具评论做出不同的推断。让我展示更多你可以用这个系统做的事情，特别是从顾客评论中提取更丰富的信息。所以，信息提取是自然语言处理（NLP）的一部分，它涉及从一段文本中提取你想知道的某些内容。

因此，在这个提示中，我要求它识别以下项目：物品购买情况以及制造该物品的公司名称。再次强调，如果你试图总结来自在线购物电子商务网站的许多评论，对于你收集的大量评论来说，找出物品是什么、谁制造了物品、分析正面和负面情绪，以及追踪特定物品或特定制造商的正面或负面情绪趋势可能会很有用。

在这个例子中，我会要求它以JSON对象的格式返回响应，其中"Item"和"Brand"作为键。如果我这样做，它会说物品是一盏灯，品牌是Lumina，你可以轻松地将其加载到Python字典中，然后对这个输出进行额外的处理。在我们看过的例子中，你看到了如何编写提示来识别情绪，判断某人是否生气，以及提取物品和品牌。

提取所有这些信息的一种方法是使用三到四个提示，并调用“get_completion”三次或四次，逐一提取这些不同的观点。但事实证明，你实际上可以编写一个提示，同时提取所有这些信息。比如说，“识别以下项目，提取情感，评论者是否表达愤怒，购买的商品，制造该商品的公司”。

然后在这里，我还要告诉它把愤怒值格式化为布尔值，让我运行一下。这样输出的JSON中，情感是积极的，愤怒值false周围没有引号，因为它要求直接输出为布尔值。提取的条目是“带额外存储的灯”而不是简单的灯，看起来没问题。但通过这种方式，你可以仅用一个提示就从一段文本中提取多个字段。

一如既往，欢迎随时暂停视频，自己尝试不同的变化。甚至可以试着输入一篇完全不同的评论，看看是否仍能准确提取这些内容。目前，我见过的大型语言模型一个很酷的应用是推断主题。给定一段长文本，你知道这段文本是关于什么的吗？

主题是什么？这是一篇虚构的报纸文章，讲述政府工作人员对他们所在机构的感受。比如，最近政府进行的一项调查显示，"结果揭示NASA是一个受欢迎的部门，满意度很高。"我是NASA的粉丝，很喜欢他们的工作，但这只是一篇虚构的文章。

因此，对于这样一篇文章，我们可以通过这个提示要求它确定文中讨论的五个主题。为了让我的回答简洁明了，每个主题请用一到两个词表示，并用逗号分隔。如果我们执行这个操作，就会得到这篇文章的主题。它涉及政府调查、工作满意度、NASA等等。

所以，总的来说，我认为这个主题列表的提取相当不错。当然，你也可以将其拆分，这样就能得到一个包含这篇文章涉及的五个主题的Python列表。如果你有一系列文章并提取了主题，那么你还可以利用大型语言模型来帮助你索引不同的主题。那么，让我用一个稍微不同的主题列表来演示一下。

假设我们是一个新闻网站之类的平台，这些是我们追踪的主题："NASA、地方政府、工程、员工满意度、联邦政府"。假设你想判断一篇新闻文章涉及了上述哪些主题。那么，我可以使用这个提示词：请判断下方文本中是否包含最终主题列表里的每一项主题。

将你的答案以0或1的列表形式给出，对应每个主题。好的，那么，这就是之前相同的故事文本。所以，这个东西是一个故事。它是关于NASA的。它不是关于地方政府。它不是关于工程学。它是关于员工满意度的，并且它是关于联邦政府的。因此，在机器学习中，这有时被称为“零样本学习算法”，因为我们没有提供任何带有标签的训练数据，所以这就是零样本。

只需一个提示，它就能判断出这篇新闻文章涉及哪些主题。因此，如果你想生成一个新闻提醒，比如处理新闻时，我非常喜欢NASA的许多工作。所以，如果你想构建一个系统，可以接收这些信息，将其存入字典，每当NASA新闻出现时，打印“警报：新的NASA故事！”，他们可以利用这个系统快速处理任何文章，判断其涉及的主题，如果主题包括NASA，就打印出“警报：新的NASA故事！”。

哦，还有一件事。我在这里用的是这个主题词典。我在这里使用的这个提示词其实不够健壮。如果要构建一个生产系统，我可能会让它输出JSON格式的答案，而不是列表形式，因为大语言模型的输出有时会不太稳定。所以这段代码实际上相当脆弱。

但如果你愿意，看完这个视频后，不妨试试看能否修改这个提示词，让它输出JSON格式而非这样的列表，然后采用更可靠的方法来判断某篇文章是否与NASA相关。关于推理部分的内容就到这里。

短短几分钟内，你就能构建多个文本推理系统，而这在过去，即便是熟练的机器学习开发者也需要数天甚至数周才能完成。因此，我感到非常兴奋的是，无论是经验丰富的机器学习开发者，还是刚入门的新手，现在都可以通过提示词快速构建系统，并开始对这类相当复杂的自然语言处理任务进行推理。

在下一个视频中，我们将继续探讨如何利用大型语言模型实现令人兴奋的功能，并进入"文本转换"环节。您将学习如何将一段文字转换成不同的文本形式，比如翻译成其他语言。让我们继续观看下一个视频。

## 6、Transforming

大型语言模型非常擅长将其输入转换为不同的格式，例如输入一种语言的文本并将其转换或翻译成另一种语言，或者帮助进行拼写和语法纠正。因此，它可以接受可能不完全符合语法的文本作为输入，并帮助你进行一些修正，甚至转换格式，例如输入 HTML 并输出 JSON。

以前我写一些应用时，常常要费劲地使用一堆正则表达式，而现在用大语言模型加上几个提示词就能轻松实现。没错，现在我几乎所有的文字都会用ChatGPT来校对，所以很期待接下来在笔记本里给大家展示更多例子。首先我们要导入OpenAI，并继续使用视频里一直用的那个get_completion辅助函数。

我们要做的第一件事是一个翻译任务。大型语言模型通过大量文本进行训练，这些文本来源广泛，其中很多来自互联网，而这些内容当然涵盖了多种不同语言。因此，这赋予了模型进行翻译的能力。这些模型能够掌握数百种语言，熟练程度各不相同。接下来，我们将通过一些示例来展示如何使用这一功能。让我们从一个简单的例子开始。

在第一个例子中，提示词是“将以下英文翻译成西班牙语：‘Hi, I would like to order a blender’”，而模型的回答是“Hola, me gustaría ordenar una licuadora”。向所有说西班牙语的朋友们致歉——显然能看出我从未学过西班牙语。好，我们再试一个例子。这次的提示词是“告诉我这是什么语言”，然后输入法语句子“Combien coûte le lampadaire”。运行后，模型识别出“这是法语”。该模型还能同时处理多个翻译任务。

所以在这个例子中，假设我们要将以下文本翻译成法语和西班牙语。你知道吗？我们再加一个英语海盗版。文本内容是"我想订购一个篮球"。这样我们就有了法语、西班牙语和英语海盗版的翻译。在某些语言中，翻译可能会根据说话者与听者的关系而改变。你也可以向语言模型解释这一点，这样它就能相应地做出合适的翻译。

因此在这个例子中，我们说：“将以下文本翻译成西班牙语的正式和非正式形式”。“您想订购一个枕头吗？”同时请注意，这里我们使用的分隔符与反引号不同。只要有一个清晰的分隔，具体用什么符号并不重要。这里我们展示了正式和非正式的表达。正式用语用于对上级或在专业场合说话时使用，而非正式用语则用于与朋友交谈时。

我其实不会说西班牙语，但我爸爸会，他说这个是对的。所以下一个例子，我们要假装自己是一家跨国电子商务公司的负责人，用户的消息会以各种不同的语言发送，用户会用各种各样的语言告诉我们他们的IT问题。所以我们需要一个万能翻译器。

首先，我们将粘贴一系列不同语言的用户消息列表。接着，我们会遍历每一条用户消息。即“for issue in user_messages”。然后，我会复制这段稍长的代码块。我们要做的第一件事是让模型告诉我们这条消息使用的是哪种语言。这是提示内容。之后，我们会打印出原始消息的语言和内容。最后，我们会要求模型将其翻译成英文和韩文。

那么让我们来运行这个。原始信息是法语的。我们有多种语言，然后模型将它们翻译成英语，再翻译成韩语。你可以在这里看到，模型说：“这是法语”。这是因为这个提示的响应将是“这是法语”。你可以尝试编辑这个提示，比如说告诉我这是什么语言，只用一个词回答，或者不要用句子，诸如此类。如果你希望它只是一个词的话。

或者你可以要求它以 JSON 格式或其他类似格式输出，这样可能会促使它不使用完整的句子。太棒了，你已经构建了一个通用翻译器。此外，你可以随时暂停视频，添加任何你想尝试的其他语言。也许是你自己说的语言，看看模型的表现如何。

接下来我们要探讨的是语气转换。写作风格会根据目标受众而有所不同，比如，我给同事或教授写邮件的方式显然会与给我弟弟发短信的方式大不相同。而ChatGPT实际上也能帮助生成不同的语气。那么，我们来看一些例子。

那么，在这个第一个例子中，提示语是“将以下俚语翻译成商务信函”。“嘿，我是乔，看看这个落地灯的规格。”让我们执行这个操作。如你所见，我们得到了一封更为正式的商务信函，其中包含了对落地灯规格的建议。接下来我们要做的是在不同格式之间进行转换。

ChatGPT非常擅长在不同格式之间进行转换，比如将JSON转为HTML，你知道的，XML、各种格式都可以。Markdown也是。因此，在提示中，我们会同时描述输入和输出的格式。这里有一个例子。我们有一段JSON数据，里面包含餐厅员工的名单，有他们的姓名和邮箱。然后在提示中，我们会要求模型将这段JSON数据转换成HTML格式。

所以，提示是“将以下Python字典从JSON格式转换为带有列标题和标题的HTML表格”。然后我们会从模型获取响应并打印出来。这里我们有一些HTML代码，显示所有员工的姓名和电子邮件。现在让我们看看是否真的能查看这个HTML。我们将使用这个Python库中的显示函数，“display(HTML(response))”。

在这里你可以看到这是一个格式正确的HTML表格。接下来我们要进行的转换任务是拼写检查和语法检查。这确实是ChatGPT非常受欢迎的一种用途。我强烈推荐这样做，我自己就经常这样做。当你在使用非母语工作时，这一点尤其有用。以下是一些常见的语法和拼写问题的例子，以及语言模型如何帮助解决这些问题。

所以我将粘贴一份包含语法或拼写错误的句子列表。然后我们将逐一检查这些句子，并要求模型进行校对和修正。校对并纠正。接着我们会使用一些分隔符。之后我们将获取响应并像往常一样打印出来。这样模型就能纠正所有这些语法错误。

我们可以运用之前讨论过的一些技巧。比如，为了改进提示语，我们可以说"校对并更正以下文本"。然后重写。整体重写。重新改写。更正版。如果未发现错误，只需回复"未发现错误"。让我们试试这个方法。这样一来我们就能...哦，他们这里还在使用引号。

但你可以想象，通过一点迭代式的提示开发，你就能找到方法。某种程度上，每次都能找到一个更可靠的提示。现在，我们再来看一个例子。在公共论坛发布之前检查你的文本总是有用的。因此，我们将通过一个检查评论的例子来说明。这里有一个关于毛绒熊猫的评论。

因此，我们将要求模型对评论进行校对和修正。很好，现在我们有了修正后的版本。我们可以做的一件很酷的事情是找出原始评论与模型输出之间的差异。为此，我们将使用这个名为 redlines 的 Python 包。我们将获取原始评论文本与模型输出之间的差异，并将其显示出来。在这里，你可以看到原始评论与模型输出之间的差异以及被修正的内容。

我们使用的提示词是“校对并修改这篇评论”。但你也可以进行一些更具戏剧性的改动，比如调整语气等等。那么，让我们再试一次。这次，我们将要求模型校对并修改同一篇评论，同时使其更具吸引力，确保其遵循APA格式，并针对高水平的读者。

我们还会要求以markdown格式输出结果。这里我们使用了原始评论中的相同文本。那么，让我们执行这个操作。现在我们得到了关于softpanda的扩展版APA格式评论。以上就是"转换"视频的全部内容。接下来是"扩展"部分，我们将从一个较短的提示出发，让语言模型生成更长的、更自由形式的回答。


## 7、expanding

扩展是指将较短的文本（如一组指令或主题列表）输入大型语言模型，由其生成较长的文本（如电子邮件或关于某个主题的文章）。这一功能有许多绝妙的用途，例如将大型语言模型作为头脑风暴的合作伙伴。

但我也想指出，这种技术存在一些有问题的使用场景，比如如果有人用它来生成大量垃圾邮件。因此，在使用大型语言模型的这些功能时，请务必以负责任的方式使用，并且要以帮助人们的方式进行。在本视频中，我们将通过一个示例，展示如何利用语言模型根据一些信息生成个性化的电子邮件。

这封邮件自称来自一个AI机器人，正如Andrew提到的，这一点非常重要。我们还将使用模型的另一个输入参数，称为"温度"，这个参数可以让你调整模型响应中的探索程度和多样性。那么让我们开始吧！在正式开始之前，我们会先做一些常规的设置。

首先安装OpenAI Python包，然后定义我们的辅助函数"get_completion"。接下来我们将根据客户评论和情感分析撰写定制化的邮件回复。现在我们将使用语言模型，基于客户评论及其情感倾向，为客户生成个性化的邮件回复。

因此，我们已经通过推断视频中展示的提示方式提取了情感倾向，这是关于搅拌机的客户评价。现在，我们将根据情感倾向定制回复内容。这里的指令是："你是一名客户服务AI助手。你的任务是向一位重要客户发送邮件回复。给定由三个反引号分隔的客户邮件，生成一封感谢客户评价的回复。"

如果评论情绪为正面或中立，则感谢他们的评价；若为负面，则致歉并建议其联系客服。务必引用评论中的具体细节，采用简洁专业的口吻，并在邮件末尾署名"AI客服专员"。此外，当使用语言模型生成面向用户的文本时，必须保持这种透明度——明确告知用户所阅内容由AI生成。

然后我们只需输入客户评价和评价情感。需要注意的是，这部分并非绝对必要，因为我们实际上可以使用这个提示来提取评价情感，然后在后续步骤中撰写邮件。但为了举例说明，我们已经从评价中提取了情感。因此，这里我们有一个给客户的回复。它回应了客户在评价中提到的细节。并且按照我们的指示，建议他们联系客服，因为这只是一个AI客服代理。

接下来，我们将使用语言模型的一个参数——“温度”（temperature），它能让我们调整模型回答的多样性。你可以把温度理解为模型探索或随机性的程度。以短语“我最喜欢的食物是”为例，模型预测最可能接的下一个词是“披萨”，其次可能是“寿司”和“塔可”。

因此，在温度为0时，模型总是会选择最有可能的下一个词，在这个例子中就是“披萨”；而在较高的温度下，它也会选择一些可能性较低的词；甚至在更高的温度下，它可能会选择“墨西哥卷饼”，这个词被选中的概率只有5%左右。你可以想象，随着模型继续生成最终的回复，比如“我最喜欢的食物是披萨”，然后继续生成更多的词，这个回复会逐渐偏离第一个回复，也就是“我最喜欢的食物是墨西哥卷饼”。

因此，随着模型的持续发展，这两种响应会变得越来越不同。一般来说，在构建需要可预测响应的应用程序时，我建议使用温度为零的设置。在所有这些视频中，我们一直使用的是温度为零的设置，我认为如果你正在尝试构建一个可靠且可预测的系统，你应该选择这种方式。如果你希望以更具创造性的方式使用模型，可能需要更广泛的不同输出，那么你可能需要使用更高的温度设置。

那么现在，让我们使用刚才相同的提示词，尝试生成一封邮件，但这次调高温度值。在我们视频中一直使用的"get_completion"函数里，虽然我们指定了模型和温度参数，但之前都采用默认设置。现在让我们尝试调整温度参数。

所以我们使用提示词，然后让我们试试温度参数设为0.7。当温度为零时，每次执行相同的提示词，你应该会得到相同的补全结果。而当温度为0.7时，每次都会得到不同的输出。现在我们生成了这封邮件，你可以看到它与我们之前收到的那封邮件有所不同。

让我们再执行一次，看看会得到另一个不同的电子邮件。看，我们又得到了一个不同的电子邮件。所以我建议你自己尝试调整一下“温度”参数。也许你现在可以暂停视频，用不同的“温度”值试试这个提示，看看输出结果会有什么变化。

总结一下，在较高温度下，模型的输出会显得更加随机。你可以这样理解：温度越高，助手越容易分心，但也可能更具创造力。在下一个视频中，我们将进一步讨论聊天补全端点的格式，以及如何利用这种格式创建自定义聊天机器人。

## 8、Chatbot

大型语言模型令人兴奋的一点在于，只需投入少量精力，你就能用它打造专属聊天机器人。网页版ChatGPT为你提供了通过大模型实现对话交互的途径。但更酷的是，你还能利用大语言模型构建定制聊天机器人——比如扮演AI客服专员或餐厅AI点餐员。本视频将教你如何亲手实现这一目标。

我将详细描述OpenAI聊天完成格式的组成部分，然后你将亲自构建一个聊天机器人。让我们开始吧。首先，我们会像往常一样设置OpenAI的Python包。像ChatGPT这样的聊天模型实际上被训练成接收一系列消息作为输入，并返回模型生成的消息作为输出。虽然聊天格式旨在使像这样的多轮对话变得容易，但通过之前的视频我们也看到，它对于没有任何对话的单轮任务同样有用。

接下来我们将定义两个辅助函数。第一个是我们所有视频中一直在使用的"get_completion"函数。仔细看这个函数会发现，我们虽然传入的是提示词，但在函数内部实际上是将这个提示词包装成了类似用户消息的形式。这是因为ChatGPT模型本质上是一个对话模型，其训练方式决定了它需要接收一系列消息作为输入，然后返回模型生成的消息作为输出。

所以用户消息是输入，而助手消息是输出。在这个视频中，我们将实际使用一个不同的辅助函数，不再是将单个提示作为输入并获取单个完成结果，而是传入一个消息列表，这些消息可以来自各种不同的角色。

我来描述一下这些内容。这里有一个消息列表的例子，第一条消息是系统消息，它给出了一个总体指令。在这条消息之后，用户和助手之间会进行轮换对话，这种对话会持续进行。如果你使用过ChatGPT的网页界面，那么你的消息就是用户消息，而ChatGPT的回复则是助手消息。

因此，系统消息有助于设定助手的行为和角色，它就像是对话的高级指令。你可以把它想象成在助手耳边低语，引导它的回应，而用户却察觉不到系统消息的存在。作为用户，如果你曾经使用过ChatGPT，你可能并不知道ChatGPT的系统消息里有什么内容。

系统消息的好处在于，它为开发者提供了一种在不将请求本身纳入对话的情况下引导对话的方式。这样，你可以在用户不知情的情况下悄悄引导助手，影响其回应方式。现在，让我们尝试在对话中使用这些消息。

因此，我们将使用新的辅助函数从消息中获取回复。同时，我们还采用了更高的温度参数。系统消息写道："你是一个说话像莎士比亚的助手"。这相当于我们在向助手描述它应有的行为方式。接着，第一条用户消息是："给我讲个笑话"。下一条是："鸡为什么过马路？"最后一条用户消息则是："我不知道。"

那么如果我们运行这个程序，响应会是“去另一边”。让我们再试一次。“去另一边，尊敬的先生或女士”。这是一个古老而经典的笑话，永远不会过时。这就是我们的莎士比亚式回应。实际上，让我们再尝试一件事。因为我想更清楚地表明这是助手的消息。所以在这里，我们直接打印出整个消息响应。只是为了让它更加清晰。

此回复为助手消息。因此角色为助手，内容即为消息本身。这就是这个辅助函数的作用——我们只是传递消息的内容。现在让我们再举一个例子。这里我们的消息包括：系统消息是"你是一个友好的聊天机器人"，第一条用户消息是"你好，我叫伊萨"。我们想要获取的就是第一条用户消息。

那么让我们来执行第一条助手消息。第一条消息是：“你好，Isa！很高兴认识你。今天有什么可以帮你的吗？”现在让我们再试一个例子。这里的消息包括系统消息“你是一个友好的聊天机器人”和第一条用户消息“是的，你能提醒我我的‘名字’是什么吗？”，然后我们来看回复。如你所见，模型实际上并不知道我的名字。

因此，与语言模型的每次对话都是一次独立的互动，这意味着你必须提供当前对话中所有相关的信息供模型参考。如果你希望模型能够参考或“记住”对话的早期部分，你必须在输入中提供之前的交流内容。

因此，我们将其称为上下文。让我们试试这个。现在，我们已经在前面的消息中提供了模型所需的上下文，即我的名字，然后我们会问同样的问题，问我的名字是什么。模型能够回答，因为它在我们输入的消息列表中有它需要的所有上下文。

现在你要开始构建自己的聊天机器人了。这个机器人将命名为"订单助手"，我们将通过自动化收集用户提示和助手回复来打造这个"订单助手"。它将负责披萨餐厅的订单处理，首先我们会定义这个辅助函数，它的作用是收集用户消息，这样我们就不需要像之前那样手动重复输入了。这个函数会从我们稍后构建的用户界面收集提示，并将其添加到一个名为"context"的列表中，之后每次都会带着这个上下文来调用模型。

然后，模型的响应也会被添加到上下文中，因此这类模型消息会被添加到上下文里，用户消息同样如此，以此类推，所以上下文会变得越来越长。这样模型就能获得所需的信息来决定下一步该做什么。接下来，我们将设置并运行这种用户界面来展示Autobot。这就是上下文，其中包含了带有菜单的系统消息。

请注意，每次我们调用语言模型时，都会使用相同的上下文，而这个上下文会随着时间的推移不断累积。然后让我们执行这个操作。好的，我要说：“嗨，我想点一个披萨。”助手回答说：“太好了，您想点哪种披萨？我们有意大利辣香肠披萨、奶酪披萨和茄子披萨。”嗯。“它们多少钱？”很好，我们有价格了。我觉得我想要一个中号的茄子披萨。所以你可以想象，我们可以继续这个对话。

让我们来看看我们在系统消息中放了什么内容。比如：“你是Autobot，一个为披萨餐厅收集订单的自动化服务。你首先问候顾客，然后收集订单，接着询问是自取还是外送。你会等待收集完整个订单，然后进行总结，并最后一次确认顾客是否还需要添加其他东西。如果是外送，你可以询问地址。”

最后，你收取款项。务必确认所有选项、额外配料和尺寸，以便从菜单中准确识别商品。你的回应要简短、口语化且友好。菜单包括……”，然后，这里是菜单。那么，让我们回到对话中，看看助手是否遵循了指示。好的，很好，助手询问我们是否需要额外配料，这一点我们在系统消息中已经提到过。所以，我想我们不需要任何额外配料。

当然可以。"您还想点些别的吗？" 来点水吧。其实，薯条也不错。要小份还是大份？这很棒，因为我们之前在系统消息里让助手明确了附加项和配菜。这样你就明白了，请随意自己试试看。你可以暂停视频，直接在左边的笔记本里运行这段代码。现在，我们可以让模型根据对话生成一个JSON摘要，以便发送给订单系统。

因此，我们现在要附加另一条系统消息，这是一条指令，内容是：“创建一份之前食物订单的JSON摘要。列出每个项目的价格。字段应包括：1) 披萨，包含配菜，2) 配料列表，3) 饮料列表，4) 配菜列表”，最后是总价。你也可以在这里使用用户消息，不一定非要是系统消息。那么，让我们执行这个操作。

请注意，在这种情况下，我们使用的是较低的温度参数，因为对于这类任务，我们希望输出结果相对可预测。如果是对话型AI，你可能会想用更高的温度值。但就这个案例而言，我可能也会选择较低温度，因为对于客户服务聊天机器人来说，你可能同样希望输出结果更具可预测性。现在，我们来看下订单摘要。

因此，如果我们愿意的话，就可以把这个提交到订单系统中。好了，你已经构建了自己的订单聊天机器人。你可以自由地自定义它，调整系统消息来改变聊天机器人的行为，让它扮演不同角色、拥有不同知识。


## 9、总结

恭喜你完成了这门简短课程的学习。总结一下，在这门短课程中，你学到了提示的两个关键原则：写出清晰具体的指令，并在适当的时候给模型留出思考的时间。你还学习了迭代式提示开发，以及如何通过一个流程找到适合你应用的提示是关键所在。

我们探讨了大语言模型在多种应用场景中的实用功能，特别是总结、推理、转换和扩展。你还学习了如何构建自定义聊天机器人。在这短短的一门课程中，你学到了很多知识，希望你享受这些学习内容。我们期待你现在能萌生出一些自己可以开发的应用创意。

请去尝试一下，然后告诉我们你的成果。项目再小都没关系，可以从一个非常小的项目开始，可能只有一点点实用性，甚至可能根本没什么用，只是好玩而已。是的，我发现摆弄这些模型真的很有趣，所以去试试吧！我同意，根据经验来说，这是个很好的周末活动。嗯，还有，请用你第一个项目的经验来打造一个更好的第二个项目，甚至可能还有更好的第三个项目，以此类推。


我认为在这个时代，构建人工智能系统的人可以对他人产生巨大影响。因此，比以往任何时候都更重要的是，我们所有人都要负责任地使用这些工具。嗯，我认为目前构建基于大型语言模型的应用程序是一个非常令人兴奋且不断发展的领域。

现在你已经完成了这门课程，我认为你已经掌握了丰富的知识，能够构建出当今很少有人懂得如何实现的东西。因此，我也希望你能帮助我们传播这门课程，鼓励其他人也来学习。最后，我希望你在学习这门课程的过程中感到愉快，并感谢你完成了这门课程。我和Ezra都期待着听到你构建出的惊人成果。

