
## 1、Reflection to improve outputs of a task

反思设计模式是我在许多应用程序中使用过的一种方法，而且实现起来出奇地简单。让我们来看看。就像人类有时会反思自己的输出并找到改进的方法一样，大型语言模型也可以做到。例如，我可能会写一封这样的邮件，如果我打字很快，最终得到的初稿可能并不理想。

如果我再看一遍，可能会发现下个月汤米哪天有空吃饭这部分写得不够清楚，还有打错的字，甚至忘了署名。这样我就能修改草稿，更具体地问：“汤米，5号到7号有空一起吃晚饭吗？”类似的过程也能让大语言模型优化它们的输出。

你可以让 LLM 撰写邮件的初稿，得到邮件版本 1 后，可以将其传递给同一个模型（或同一个大语言模型），但使用不同的提示词，要求它进行反思并写出改进后的第二稿，从而获得最终输出——邮件版本2。在这里，我只是简单地硬编码了这个工作流程：先让大语言模型生成初稿，然后再提示它进行反思和改进，最终得到邮件版本 2。

事实证明，类似的方法也可以用于优化其他类型的输出。例如，当你让大语言模型编写代码时，可以先让它生成完成某项任务的初版代码，随后将这段代码交给同一个或另一个大语言模型进行错误检查，并生成经过改进的第二版代码。

不同的 LLM 各有所长，因此有时我会选择不同的模型来撰写初稿和进行反思改进。例如，事实证明，推理模型（有时也被称为思维模型）在发现错误方面表现相当出色，所以我有时会通过直接生成代码来撰写初稿，但随后会使用推理模型来检查错误。

现在，与其仅让大语言模型（LLM）对代码进行自我反思，事实证明，如果能获得外部反馈（即来自 LLM 之外的新信息），反思的效果会显著增强。就代码而言，一个可行的方法是直接执行代码以观察其行为，并通过检查输出（包括代码的任何错误信息）来获取极其有用的信息，这些信息能帮助 LLM 进行反思并找到改进代码的方法。

在这个例子中，大语言模型生成了代码的第一版草稿，但当我运行它时，却产生了语法错误。当你将这些代码输出和错误日志反馈给大语言模型，并要求它根据反馈进行反思并写出新的草稿时，这为它提供了大量非常有用的信息，从而能够生成一个更好的第二版代码。

所以反思设计模式并不是魔法。它并不能让大语言模型每次都 100% 正确无误，但往往能带来些许性能提升。不过需要牢记的一个设计考量是：当有新的外部信息可以融入反射过程时，反射机制会发挥出更强大的作用。

因此在这个例子中，如果你能运行代码并将代码输出或错误信息作为反思步骤的额外输入，就能让大语言模型进行更深入的反思，找出可能存在的问题（如果有的话）。相比缺乏这类可吸收的外部信息，这种做法能产生质量更高的代码第二版。关键要记住：每当反思环节有机会获取额外信息时，其效果就会显著增强。接下来让我们进入下一个视频，我将系统性地比较"反思生成"与"直接生成"（有时称为零样本提示）的差异。我们继续观看下一个视频吧。

## 2、Why not just direct generation?

让我们来看看为什么我们可能更倾向于使用反思工作流程，而不是仅仅提示一次大型语言模型（LLM），让它直接生成答案就完事。在直接生成的方式中，你只需给 LLM 一个指令，让它生成答案。

因此，你可以要求一个大型语言模型写一篇关于黑洞的文章，让它直接生成文本；或者让它编写计算复利的 Python 函数，让它直接输出代码。你在这里看到的提示示例也被称为零样本提示。让我解释一下零样本的含义。与零样本提示相反，一种相关的方法是在你的提示中包含一个或多个你希望输出看起来像的示例。

这被称为单次提示（one-shot prompting），如果在提示中包含一个期望的输入-输出对示例；或者根据提示中包含的示例数量，称为双次提示（two-shot prompting）或少次提示（few-shot prompting）。因此，零次提示（zero-shot prompting）指的是不包含任何期望输出示例的情况。不过，如果你还不熟悉这些术语，也不用担心。

重要的是，你在这些例子中看到的只是直接提示大语言模型一次性生成答案，我也称之为零样本提示，因为我们没有包含任何示例。事实证明，多项研究表明，反思能提高直接生成在各种任务上的表现。

该图表改编自 Madaan 等人的研究论文，展示了不同模型在执行各类任务时，在有反思机制和无反思机制下的表现对比。阅读此图的关键在于观察相邻的浅色与深色条形组：浅色条代表零样本提示（zero-shot prompting）的模型表现，深色条则展示同一模型在引入反思机制后的效果。

蓝色、绿色和红色分别代表使用不同模型（如 GPT-3.5 和 GPT-4）进行的实验。可以看到，在许多不同应用中，带有反思机制的深色柱状图明显高于浅色柱状图。当然，具体效果可能因应用场景而异。以下是反思机制可能发挥作用的更多案例。

如果你正在生成结构化数据，比如 HTML 表格，有时输出格式可能会出现错误。因此，使用反思提示来验证 HTML 代码可能会有所帮助。如果是基本的 HTML，这可能帮助不大，因为大型语言模型在基本 HTML 方面表现相当出色。但特别是当你处理更复杂的结构化输出时，比如可能包含大量嵌套的 JSON 数据结构，反思更有可能发现错误。

或者，如果你让大语言模型生成一系列步骤来构成一套操作指南，比如如何冲泡一杯完美的茶，有时大语言模型可能会遗漏某些步骤，而通过反思提示来检查指南的连贯性和完整性可能有助于发现错误。再比如，我实际做过的一个项目是利用大语言模型生成域名，但有时它生成的域名会有意想不到的含义，或者非常难发音。

因此，我利用反思提示来反复检查域名是否存在任何有问题的内涵或含义，或者名称是否难以发音。实际上，我们团队的人工智能基金就采用了这种方法，帮助我们为正在合作的初创企业集思广益，想出合适的域名。

我想给你举几个反思提示的例子。在头脑风暴域名时，你可以让它回顾你建议的域名，然后检查每个名字是否容易发音。确认每个名字在英语或其他语言中是否有负面含义，最后输出一个仅包含符合这些标准的简短名单。或者为了改进一封邮件，你可以写一个反思提示，让它先审阅邮件的初稿，检查语气，核实所有陈述的事实和承诺是否准确。

在 LLM 被输入了大量事实、日期等信息以撰写邮件草稿的背景下，这确实讲得通。所有这些信息都将作为 LLM 上下文的一部分提供。然后，基于它可能发现的任何问题，撰写下一版邮件草稿。以下是一些撰写反思提示的建议。

这有助于明确表示你希望它审查或反思输出的初稿。如果你能指定一套明确的标准，比如域名是否易于发音、是否可能有负面含义，或者对于邮件，检查语气并核实事实，那么这将更好地引导大语言模型根据你最关心的标准进行反思和批评。

我发现，学习写出更好提示词的方法之一，就是大量阅读别人写的提示词。有时候我甚至会下载开源软件，专门去找那些我认为写得特别好的软件中的提示词，仔细阅读作者们写的提示词内容。

所以我希望你现在对如何撰写一个基本的反思提示有了概念，甚至可能会在自己的工作中尝试一下，看看是否能帮助你提高表现。在下一个视频中，我想和大家分享一个有趣的例子，我们将开始探讨多模态的输入和输出。我们会让一个算法对正在生成的图像或图表进行反思。让我们一起来看看吧。

## 3、Chart generation workflow

在本模块中看到的编码实验室里，您将体验一个图表生成工作流程，通过使用智能代理来创建精美的图表。事实证明，反思能显著提升输出质量。让我们具体看看：这个案例中，我有一台咖啡机的销售数据，显示拿铁咖啡、热巧克力、卡布奇诺等不同饮品的售出时间及对应价格。

我们希望让一个智能体生成一张图表，对比 2024 年和 2025 年第一季度（Q1）的咖啡销售数据。一种实现方式是编写提示词，要求大语言模型利用存储在电子表格（CSV 文件或以逗号分隔值的表格文件）中的数据，创建 2024 年与 2025 年第一季度咖啡销售额的对比图表。

而一个大型语言模型可能会像这样编写 Python 代码来生成图表。使用这个 v1 版本的代码，如果你执行它，可能会生成这样的图表。当我运行这段由 LLM 输出的代码时，它第一次实际上生成了这个结果。这是一个堆叠条形图，并不是一种非常直观的可视化方式，看起来也不是一个很好的图表。

但你可以做的是，将代码的第一版以及这段代码生成的图表一起输入到一个多模态模型中——这个模型是一个也能接受图像输入的大语言模型（LLM）——然后让它检查这段代码生成的图像，对图像进行评价，找到改进可视化的方法，并更新代码以生成更清晰、更好的图表。

多模态大语言模型能够运用视觉推理能力，因此它实际上可以通过视觉观察这张图表来寻找改进方法。当我这样做时，它生成了一张非堆叠式的柱状图，而是将 2024 年和 2025 年的咖啡销售额分开显示的常规柱状图，我认为这种呈现方式更加美观清晰。

当你到达编程实验室时，请随意尝试这些问题，看看是否能得到更好看的图表。因为不同的 LLM 各有优缺点，有时我会用不同的 LLM 进行初始生成和反思。例如，你可以用一个 LLM 生成初始代码，比如 GPT-4o 或 GPT-5 之类的模型，然后像这样提示它编写 Python 代码来生成可视化图表等等。

然后，反思提示可能是这样的：你让大语言模型扮演一位专家数据分析师的角色，提供建设性的反馈，然后给它代码的第一版，即生成的部分，可能还包括代码生成的计算历史，并要求它根据特定标准进行批评。

记住，当你给出诸如可读性、清晰度和完整性等具体标准时，这有助于大型语言模型更好地理解该做什么。然后，你可以要求它编写新的代码来实现你的改进。你可能会发现，有时使用推理模型进行反思可能比非推理模型效果更好。

因此，当你尝试不同的模型进行初始生成和反思时，这些是你可能会切换或尝试不同组合的不同配置。所以当你进入编码实验室时，我希望你能享受可视化咖啡销售的过程。现在，当你构建一个应用程序时，你可能会想知道的一件事是，反思是否真的能提高你在特定应用程序上的性能？

多项研究表明，反思机制在某些应用上能小幅提升性能，在另一些应用上则能大幅提升，而在其他应用中可能几乎没有任何效果。因此，了解反思对您具体应用的影响将很有帮助，同时也能指导您如何调整初始生成或反思提示以获得更好的性能。在下一个视频中，我们将探讨反思工作流程的评估方法。让我们继续观看下一个视频。


## 4、Evaluating the impact of reflection

反思通常能提升系统性能，但在决定保留这一机制前，我通常会再次确认它实际带来的性能提升幅度，毕竟多出的步骤确实会让系统运行速度略微变慢。让我们来看看反思工作流程的评估。

我们来看一个例子，通过反思来改进 LLM 编写的数据库查询，以获取数据来回答问题。假设你经营一家零售店，可能会遇到这样的问题：哪种颜色的产品总销售额最高？要回答这样的问题，你可以让大语言模型生成一个数据库查询。如果你听说过像 SQL 这样的数据库语言，它可能会生成那种语言的查询语句。但如果你不熟悉 SQL，也不用担心。

在编写完数据库查询后，与其直接用它从数据库中获取信息，不如让同一个或另一个大语言模型对初版查询进行反思并优化，然后再执行这个优化后的查询来获取信息，最终由大语言模型回答问题。

那么问题来了，使用第二个 LLM 来反思和改进数据库或 SQL 查询，是否真的能提升最终输出效果？为了评估这一点，我可能会收集一组问题或提示，并附上标准答案。比如：2025 年 5 月 售出了多少件商品？库存中最贵的商品是什么？我的店里有多少种款式？我会为大约 10 到 15 个 提示写下标准答案。然后你就可以在没有反思的情况下运行这个工作流程。

因此，“无反思” 意味着直接使用第一个 LLM 生成的 SQL 查询语句，仅观察其返回的结果；而“有反思”则指让第二个 LLM 对生成的数据库查询进行反思优化后，再执行查询并获取结果。通过对比两种方式得出正确答案的百分比：本例中无反思的正确率为 87%，有反思的正确率达 95%。这表明反思机制能显著提升数据库查询质量，从而更精准地获取正确答案。

开发者经常还会做的一件事是重写反思提示。例如，你是否想在反思提示中添加指令，使数据库查询运行得更快或更清晰？或者你可能对如何重写初始生成提示或反思提示有不同的想法。一旦你建立了这样的评估机制，你就可以快速尝试这些提示的不同想法，并在更改提示时测量系统的正确率，从而了解哪些提示最适合你的应用。因此，如果你正在尝试大量提示词，构建评估体系就非常重要。它能帮助你系统性地在不同候选提示词之间做出选择。不过这个例子属于可以使用客观评估的情况，因为存在明确答案——售出商品数量为 1,301 件，答案非对即错。

那么对于需要主观评估而非客观判断的应用场景呢？就像我们在上个视频中看到的绘图案例：未经反思时得到的是堆叠条形图，经过反思后获得了这个优化后的图表。但我们如何知道哪个图表实际上更好呢？我知道我更喜欢后者，但当不同的图表在不同维度上有所变化时，我们如何判断哪个更好呢？衡量这些图表哪个更好更多是一种主观标准，而非纯粹非黑即白的客观标准。因此，对于这些更主观的标准，你可以做的一件事是使用 LLM 作为评判者。

也许一个基本的方法是，将两个图表输入到一个能够接受两张图像作为输入的多模态大语言模型中，然后直接问它哪张图像更好。原来这个方法效果并不理想。我马上会分享一个更好的方案。不过你可以尝试给它一些评估标准，比如清晰度、美观度等，让它来比较这两个图表。但事实证明，用 LLM 来比较两个输入并判断哪个更好，存在一些已知问题。

首先，它的答案往往不太靠谱。作为评判者，LLM 对提示词的措辞非常敏感，而且它的排序结果有时与人类专家的判断并不一致。其中一个表现是许多 LLM 会有位置偏好。事实证明，许多大语言模型往往会更频繁地选择第一个选项而非第二个。实际上，我测试过很多大语言模型，当给定两个选择时，无论我先展示哪个选项，它都会说第一个选择更好。也许有些大语言模型更喜欢第二个选项，但我认为大多数大语言模型都偏爱第一个选项。

与其让大语言模型比较一对输入，使用评分标准进行评分可以得到更一致的结果。

例如，你可以提示一个 LLM，给定一张图片，根据质量评分标准对附件中的图片进行评估。评分标准或评分准则可能包括明确的指标，比如图表是否有清晰的标题、坐标轴标签是否齐全、是否选择了合适的图表类型等，包含若干这样的标准。事实证明，与其让 LLM 以 1 到 5 的等级来评分（它在这方面往往不够准确），不如给它 5 个二元标准（即 0 或 1 的标准），让它给出 5 个二元分数，然后将这些分数相加，得到 1 到 5 或 1 到 10 的评分（如果你有 10 个二元标准的话）。这种方法往往能产生更一致的结果。

因此，如果我们收集一些（比如 10 到 15 个）用户可能想看到的咖啡机销售的不同可视化查询，那么你可以让它生成带有反思的图像或不带反思的图像，并使用类似这样的评分标准来对每张图像进行评分，以检查带有反思的图像是否真的比不带反思的图像更好。

一旦你建立了一套这样的评估标准，如果你想改变初始生成提示或反思提示，你也可以重新运行这个评估，看看更新其中一个提示是否能让系统生成根据这个评分标准得分更高的图像。这样，你就能不断调整提示，以获得越来越好的表现。

在构建用于反思或其他自主工作流程的评估时，你可能会发现，当存在客观标准时，基于代码的评估通常更容易管理。在我们看到的数据库查询示例中，我们建立了一个包含真实案例和真实输出的数据库，并编写代码来查看系统在非常客观的评估指标中生成正确答案的频率。

相比之下，对于小型主观任务，你可能会使用一个元素作为评判标准，但这通常需要更多的调整，比如需要思考你可能希望使用什么样的评分标准，以使作为评判者的 LLM 能够良好校准或输出可靠的评估结果。因此，我希望这能让你了解如何构建评估标准来评估反思，或者更广泛地说，甚至评估不同的代理工作流程。

掌握如何做好评估对于构建高效自主的工作流程至关重要，在后续视频中我也会详细讲解这一点。现在你已经了解了反思的运用方法，接下来我将深入探讨其中一个关键环节——如何从外部获取额外信息，这种方法能显著提升反思的效果。在本模块的最后一期视频中，我们将重点解析这个能让反思流程事半功倍的技巧。下期视频见。

## 5、using external feedback

如果能获得外部反馈，那么结合外部反馈的反思比仅依赖大语言模型作为反馈来源的反思要强大得多。让我们具体看看：当我开发应用程序时，如果只是通过即时工程直接生成零样本提示，性能的变化可能会呈现这样的趋势——最初随着提示词的调整，性能会提升一段时间，但之后就会趋于平稳。即使继续优化提示词，性能也很难再有显著提高。

因此，与其把所有时间都浪费在调整提示词上，有时如果在流程早期就开始加入反思环节，效果可能会更好。有时提升幅度较小，有时则较大，但这会增加复杂度。但如果我在这个阶段就开始加入反思机制，然后着手调整反思提示词，最终或许能达到这样的效果。

但事实证明，如果我能获得外部反馈，那么新信息的唯一来源就不只是 LLM 对之前相同信息的反思，而是来自外部的一些新信息。这样，随着我不断调整提示和外部反馈，有时最终会达到更高的性能水平。

因此，如果你正在研究提示工程，并且感觉自己的努力收效递减，调整了很多提示但效果却没有明显提升，那么或许可以考虑是否存在反思的空间，或者更好的是，是否可以引入一些外部反馈，让性能曲线摆脱这条趋于平缓的红线，迈向更高的性能提升轨道。

提醒一下，我们之前提到过，编写代码时的一种反馈来源就是直接运行代码，观察它生成的输出或错误信息，然后将这些输出反馈给 LLM，让它基于这些新信息进行思考，再利用这些信息编写新版本的代码。以下是软件代码或工具可以生成新信息以辅助反思过程的更多示例。)

如果你用大语言模型写邮件时，它偶尔会提到竞争对手的名字，那么如果你编写代码或构建一个软件工具，仅通过模式匹配（比如正则表达式匹配）来搜索输出中的竞争对手名称，那么每当你发现一个竞争对手的名字时，就将其作为批评或输入反馈给大语言模型。这是非常有用的信息，可以告诉它重写文本而不提及那些竞争对手。

再举一个例子，你可能会用网络搜索或查阅其他可信来源来核实一篇文章的事实。比如，如果一个研究助手说泰姬陵建于 1648 年，严格来说，泰姬陵实际上是在 1631 年下令建造的，并于 1648 年完工。所以这或许不算完全错误，但也没有准确反映历史。为了更精确地描述这座美丽建筑的建造时间，如果你进行网络搜索，找到详细说明泰姬陵建造时期的片段，并将这些信息作为额外输入提供给反思助手，那么它或许能利用这些信息写出更准确的泰姬陵历史文本版本。

最后一个例子，如果你使用 LLM 来撰写文案，可能是博客文章或研究论文摘要，但它写的内容有时会超出字数限制。LLM 在严格遵守字数限制方面仍然表现不佳。这时如果你实现一个字数统计工具，只需编写代码来精确计算字数，如果超出限制，就将字数反馈给 LLM 并要求它重试。这样可以帮助它更准确地达到你希望生成的输出长度。

因此，在这三个例子中，你都可以编写一段代码来帮助查找关于初始输出的更多信息，然后将这些信息（无论是你找到的竞争对手名称、网页搜索信息还是确切的字数统计）输入到反思型大语言模型中，以帮助它更好地思考如何改进输出。

反思同样具有强大的力量，希望这些内容能对你的实际工作有所帮助。在下一个模块中，我们将以此为基础探讨工具的使用——除了你已看到的几个工具示例外，你还将学习如何系统性地让大语言模型调用不同功能，这将显著增强你的智能体应用能力。希望你喜欢这段关于反思的学习之旅。现在我将对你所学内容进行总结，期待在下一个视频中与你再见。

