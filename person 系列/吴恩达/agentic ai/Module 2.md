
## 1、Reflection to improve outputs of a task

反思设计模式是我在许多应用程序中使用过的一种方法，而且实现起来出奇地简单。让我们来看看。就像人类有时会反思自己的输出并找到改进的方法一样，大型语言模型也可以做到。例如，我可能会写一封这样的邮件，如果我打字很快，最终得到的初稿可能并不理想。

如果我再看一遍，可能会发现下个月汤米哪天有空吃饭这部分写得不够清楚，还有打错的字，甚至忘了署名。这样我就能修改草稿，更具体地问：“汤米，5号到7号有空一起吃晚饭吗？”类似的过程也能让大语言模型优化它们的输出。

你可以让 LLM 撰写邮件的初稿，得到邮件版本 1 后，可以将其传递给同一个模型（或同一个大语言模型），但使用不同的提示词，要求它进行反思并写出改进后的第二稿，从而获得最终输出——邮件版本2。在这里，我只是简单地硬编码了这个工作流程：先让大语言模型生成初稿，然后再提示它进行反思和改进，最终得到邮件版本 2。

事实证明，类似的方法也可以用于优化其他类型的输出。例如，当你让大语言模型编写代码时，可以先让它生成完成某项任务的初版代码，随后将这段代码交给同一个或另一个大语言模型进行错误检查，并生成经过改进的第二版代码。

不同的 LLM 各有所长，因此有时我会选择不同的模型来撰写初稿和进行反思改进。例如，事实证明，推理模型（有时也被称为思维模型）在发现错误方面表现相当出色，所以我有时会通过直接生成代码来撰写初稿，但随后会使用推理模型来检查错误。

现在，与其仅让大语言模型（LLM）对代码进行自我反思，事实证明，如果能获得外部反馈（即来自 LLM 之外的新信息），反思的效果会显著增强。就代码而言，一个可行的方法是直接执行代码以观察其行为，并通过检查输出（包括代码的任何错误信息）来获取极其有用的信息，这些信息能帮助 LLM 进行反思并找到改进代码的方法。

在这个例子中，大语言模型生成了代码的第一版草稿，但当我运行它时，却产生了语法错误。当你将这些代码输出和错误日志反馈给大语言模型，并要求它根据反馈进行反思并写出新的草稿时，这为它提供了大量非常有用的信息，从而能够生成一个更好的第二版代码。

所以反思设计模式并不是魔法。它并不能让大语言模型每次都 100% 正确无误，但往往能带来些许性能提升。不过需要牢记的一个设计考量是：当有新的外部信息可以融入反射过程时，反射机制会发挥出更强大的作用。

因此在这个例子中，如果你能运行代码并将代码输出或错误信息作为反思步骤的额外输入，就能让大语言模型进行更深入的反思，找出可能存在的问题（如果有的话）。相比缺乏这类可吸收的外部信息，这种做法能产生质量更高的代码第二版。关键要记住：每当反思环节有机会获取额外信息时，其效果就会显著增强。接下来让我们进入下一个视频，我将系统性地比较"反思生成"与"直接生成"（有时称为零样本提示）的差异。我们继续观看下一个视频吧。

## 2、Why not just direct generation?

让我们来看看为什么我们可能更倾向于使用反思工作流程，而不是仅仅提示一次大型语言模型（LLM），让它直接生成答案就完事。在直接生成的方式中，你只需给 LLM 一个指令，让它生成答案。

因此，你可以要求一个大型语言模型写一篇关于黑洞的文章，让它直接生成文本；或者让它编写计算复利的 Python 函数，让它直接输出代码。你在这里看到的提示示例也被称为零样本提示。让我解释一下零样本的含义。与零样本提示相反，一种相关的方法是在你的提示中包含一个或多个你希望输出看起来像的示例。

这被称为单次提示（one-shot prompting），如果在提示中包含一个期望的输入-输出对示例；或者根据提示中包含的示例数量，称为双次提示（two-shot prompting）或少次提示（few-shot prompting）。因此，零次提示（zero-shot prompting）指的是不包含任何期望输出示例的情况。不过，如果你还不熟悉这些术语，也不用担心。

重要的是，你在这些例子中看到的只是直接提示大语言模型一次性生成答案，我也称之为零样本提示，因为我们没有包含任何示例。事实证明，多项研究表明，反思能提高直接生成在各种任务上的表现。

该图表改编自 Madaan 等人的研究论文，展示了不同模型在执行各类任务时，在有反思机制和无反思机制下的表现对比。阅读此图的关键在于观察相邻的浅色与深色条形组：浅色条代表零样本提示（zero-shot prompting）的模型表现，深色条则展示同一模型在引入反思机制后的效果。

蓝色、绿色和红色分别代表使用不同模型（如 GPT-3.5 和 GPT-4）进行的实验。可以看到，在许多不同应用中，带有反思机制的深色柱状图明显高于浅色柱状图。当然，具体效果可能因应用场景而异。以下是反思机制可能发挥作用的更多案例。

如果你正在生成结构化数据，比如 HTML 表格，有时输出格式可能会出现错误。因此，使用反思提示来验证 HTML 代码可能会有所帮助。如果是基本的 HTML，这可能帮助不大，因为大型语言模型在基本 HTML 方面表现相当出色。但特别是当你处理更复杂的结构化输出时，比如可能包含大量嵌套的 JSON 数据结构，反思更有可能发现错误。

或者，如果你让大语言模型生成一系列步骤来构成一套操作指南，比如如何冲泡一杯完美的茶，有时大语言模型可能会遗漏某些步骤，而通过反思提示来检查指南的连贯性和完整性可能有助于发现错误。再比如，我实际做过的一个项目是利用大语言模型生成域名，但有时它生成的域名会有意想不到的含义，或者非常难发音。

因此，我利用反思提示来反复检查域名是否存在任何有问题的内涵或含义，或者名称是否难以发音。实际上，我们团队的人工智能基金就采用了这种方法，帮助我们为正在合作的初创企业集思广益，想出合适的域名。

我想给你举几个反思提示的例子。在头脑风暴域名时，你可以让它回顾你建议的域名，然后检查每个名字是否容易发音。确认每个名字在英语或其他语言中是否有负面含义，最后输出一个仅包含符合这些标准的简短名单。或者为了改进一封邮件，你可以写一个反思提示，让它先审阅邮件的初稿，检查语气，核实所有陈述的事实和承诺是否准确。

在 LLM 被输入了大量事实、日期等信息以撰写邮件草稿的背景下，这确实讲得通。所有这些信息都将作为 LLM 上下文的一部分提供。然后，基于它可能发现的任何问题，撰写下一版邮件草稿。以下是一些撰写反思提示的建议。

这有助于明确表示你希望它审查或反思输出的初稿。如果你能指定一套明确的标准，比如域名是否易于发音、是否可能有负面含义，或者对于邮件，检查语气并核实事实，那么这将更好地引导大语言模型根据你最关心的标准进行反思和批评。

我发现，学习写出更好提示词的方法之一，就是大量阅读别人写的提示词。有时候我甚至会下载开源软件，专门去找那些我认为写得特别好的软件中的提示词，仔细阅读作者们写的提示词内容。

所以我希望你现在对如何撰写一个基本的反思提示有了概念，甚至可能会在自己的工作中尝试一下，看看是否能帮助你提高表现。在下一个视频中，我想和大家分享一个有趣的例子，我们将开始探讨多模态的输入和输出。我们会让一个算法对正在生成的图像或图表进行反思。让我们一起来看看吧。

## 3、Chart generation workflow

在本模块中看到的编码实验室里，您将体验一个图表生成工作流程，通过使用智能代理来创建精美的图表。事实证明，反思能显著提升输出质量。让我们具体看看：这个案例中，我有一台咖啡机的销售数据，显示拿铁咖啡、热巧克力、卡布奇诺等不同饮品的售出时间及对应价格。

我们希望让一个智能体生成一张图表，对比 2024 年和 2025 年第一季度（Q1）的咖啡销售数据。一种实现方式是编写提示词，要求大语言模型利用存储在电子表格（CSV 文件或以逗号分隔值的表格文件）中的数据，创建 2024 年与 2025 年第一季度咖啡销售额的对比图表。

而一个大型语言模型可能会像这样编写 Python 代码来生成图表。使用这个 v1 版本的代码，如果你执行它，可能会生成这样的图表。当我运行这段由 LLM 输出的代码时，它第一次实际上生成了这个结果。这是一个堆叠条形图，并不是一种非常直观的可视化方式，看起来也不是一个很好的图表。

但你可以做的是，将代码的第一版以及这段代码生成的图表一起输入到一个多模态模型中——这个模型是一个也能接受图像输入的大语言模型（LLM）——然后让它检查这段代码生成的图像，对图像进行评价，找到改进可视化的方法，并更新代码以生成更清晰、更好的图表。

多模态大语言模型能够运用视觉推理能力，因此它实际上可以通过视觉观察这张图表来寻找改进方法。当我这样做时，它生成了一张非堆叠式的柱状图，而是将 2024 年和 2025 年的咖啡销售额分开显示的常规柱状图，我认为这种呈现方式更加美观清晰。

当你到达编程实验室时，请随意尝试这些问题，看看是否能得到更好看的图表。因为不同的 LLM 各有优缺点，有时我会用不同的 LLM 进行初始生成和反思。例如，你可以用一个 LLM 生成初始代码，比如 GPT-4o 或 GPT-5 之类的模型，然后像这样提示它编写 Python 代码来生成可视化图表等等。

然后，反思提示可能是这样的：你让大语言模型扮演一位专家数据分析师的角色，提供建设性的反馈，然后给它代码的第一版，即生成的部分，可能还包括代码生成的计算历史，并要求它根据特定标准进行批评。

记住，当你给出诸如可读性、清晰度和完整性等具体标准时，这有助于大型语言模型更好地理解该做什么。然后，你可以要求它编写新的代码来实现你的改进。你可能会发现，有时使用推理模型进行反思可能比非推理模型效果更好。

因此，当你尝试不同的模型进行初始生成和反思时，这些是你可能会切换或尝试不同组合的不同配置。所以当你进入编码实验室时，我希望你能享受可视化咖啡销售的过程。现在，当你构建一个应用程序时，你可能会想知道的一件事是，反思是否真的能提高你在特定应用程序上的性能？

多项研究表明，反思机制在某些应用上能小幅提升性能，在另一些应用上则能大幅提升，而在其他应用中可能几乎没有任何效果。因此，了解反思对您具体应用的影响将很有帮助，同时也能指导您如何调整初始生成或反思提示以获得更好的性能。在下一个视频中，我们将探讨反思工作流程的评估方法。让我们继续观看下一个视频。





