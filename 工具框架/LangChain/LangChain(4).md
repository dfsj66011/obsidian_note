
大家好，我叫 Nitesh，欢迎来到我的 YouTube 频道。在今天的视频中，我们将继续我们的Lang Chain播放列表。到目前为止，我已在播放列表中添加了一个视频。在那个视频中，我讨论了什么是Lang Chain，并尝试向大家解释为什么需要Lang Chain。而今天的视频可能比之前的视频更加重要。

在今天的视频中，我将为大家详细讲解Lang Chain的核心组件有哪些。如果你完整观看本期视频，将获得两大收获：首先，你会深入理解Lang Chain框架的组织架构，能洞见开发者的设计思路；其次，今后本系列视频都将以本期内容为基础展开——今天讨论过的每个组件，后续都会有专题视频深入讲解。所以看完这期视频，你就能获得一份学习路线图。

你会发现在这个播放列表中我们将涵盖哪些内容。好的，现在在开始视频之前，我想先声明一下：今天的视频中我们不会编写任何代码，也不会构建任何项目，原因非常简单。在开始这个播放列表之前，我已经告诉过你，一般来说，我观察到网上关于区块链的资源，在打好区块链基础之前就直接跳到做项目，

我认为这不是学习这个库的正确方法。我觉得正确的方法是先对库有一个概念性的概述，然后再开始编写代码。所以在这个播放列表中，我也做了这样的安排。前两个视频，也就是上一个视频和今天的视频，我会给你一个关于这个库的理论基础。一旦这个基础建立起来，我们就会在接下来的所有课程中编写代码和构建项目。这就是为什么在这个视频中也是如此。

我原本计划不包含任何代码，但这并不意味着视频会很无聊。我已经确保在解释每个组件的过程中，我会给你们很多有趣且相关的工业实例，所以很可能你们不会觉得这个视频无聊。现在，我想我已经给你们足够多的关于这个视频的介绍，让我们开始吧。现在，在正式开始视频之前，我先给大家快速回顾一下。

我想回顾一下上一个视频，那是这个播放列表的第一个视频。在那里，我详细地尝试解释了什么是Lang Chain以及为什么需要它。好的，我在那里告诉过你们，Lang Chain是一个开源的框架，属于后链（post-chain）范畴，它能解决整个复杂性。Lang Chain最大的优势在于，它能够在所有组件之间非常高效地进行编排，从而处理整个复杂性。

管道构建可以完成，并且您可以用最少的代码获得最大的输出。我之前也告诉过您，LangChain中有链的概念，您可以在其中将不同的组件串联成一个链，而链的最大优点在于一个组件的输出可以自动作为另一个组件的输入，这样我们就不需要手动编写代码。我还告诉过您另一个特性，即LangChain是一个模型无关的框架。

这意味着如果明天你不想使用OpenAI的GPT模型，而是想使用Google的Gemini模型，你不需要做太多的代码更改，基本上只需要一两行代码就能完成这个转换。我在上一个视频中已经告诉过你所有这些好处，还提到了现在人们使用LangChain主要用来做什么。我通过例子告诉你，很多人正在构建对话式聊天机器人。

很多人正在为自己的公司制作大量的人工智能知识辅助工具，许多公司现在也在制作代理。看完今天的视频后，你会更好地理解这些内容，好吗？现在让我们转向今天的主题，我们今天的主题是想了解LangChain中有哪些组件。首先，我想向你展示这张图，因为在这张图中，我已经列出了所有的组件。

所以总的来说，LangChain有6个不同的组成部分，如果你学习了这6个部分，相信我，你会理解LangChain的大部分概念，好吗？第一个组成部分是Models，第二个是Prompts，第三个是Chains，第四个是Memory，第五个是Indexes，第六个是Agents。我们在这个视频中的目标是逐一详细讨论所有这些组成部分，而且你会注意到，在这个完整的播放列表中，我们将讨论这6个组成部分，好吗？那么现在，

让我们从第一个组件开始，那就是模型。朋友们，我们会非常仔细地学习模型这个组件，因为它是LangChain中最重要的组件。看这里写着：LangChain模型是与AI模型交互的核心接口。我知道这个定义可能让你们不太明白，所以为了更好地理解，我会给你们讲一点背景故事。

所以NLP的整个历史中，有一个特定的应用是每个人都想开发的，那就是聊天机器人。聊天机器人可能是NLP领域中最受欢迎的应用，每个人都想在NLP中创建自己的聊天机器人。但在开发聊天机器人时，以前有两个主要问题，现在没有了。那么第一个问题是让聊天机器人理解用户的查询，对吧？我输入了“Hi, can you check my email”。

现在我能让聊天机器人理解我的意思，这是创建聊天机器人时的第一个重大挑战，我们称之为自然语言理解（NLU）的挑战。第二个挑战是，即使聊天机器人理解了我的问题，它也要能给出正确的回复，这也是一个很大的挑战。所以基本上，上下文感知和文本生成也是一个重大挑战。在这两个挑战上，我们都付出了很多努力，尝试了很多方法来解决它们。

最终，LLMs（大型语言模型）出现了，并且LLMs同时解决了这两个问题。因此，为了训练LLMs，我们几乎使用了整个互联网的数据，这导致了什么结果呢？不仅LLMs内部对自然语言的理解得到了发展，同时它还具备了上下文感知的文本生成能力。所以，我想说的是，随着LLMs的出现，NLP（自然语言处理）领域的这两个重大问题同时得到了解决，对吧？但是，一个新的问题出现了。这个新问题是，由于LLMs是在整个互联网的数据上训练的。

所以它们内部有很多参数，像数十亿个参数，正因为如此，LLM的规模非常庞大，非常非常大，意思是市场上很多优秀的LLM，它们的规模都超过100GB。现在的问题在于，这么大的文件，普通人根本无法在自己的电脑上存储和运行，就连小公司也无法在自己的服务器上运行，因为云服务的费用会高得让你付不起。所以这就带来了第二个重大挑战，现在全世界任何人都可以访问这些API，发送自己的查询。

而这些API会反过来与LLM对话，你可以在全世界任何地方调用这些API，发送你的查询，这些API会反过来与LLM对话，LLM会返回它的响应，而这个响应会到达用户那里。现在这个模型的好处是什么？我不需要在电脑上运行LLM，也不需要在我的云服务上运行它。我需要用多少，就向API发送多少问题，然后只需要支付相应的费用，所以这个问题也解决了。但现在出现了第三个问题，那就是实现的问题。

意思是不同的LLM提供商编写的API采用了不同的方式，这意味着，如果我是一个应用程序开发者，并且需要在我的应用程序中与两个不同的LLM API进行交互，那么我就必须编写不同类型的代码。我来给你展示一下这个东西，注意看这里，这里有两段代码，第一段是OpenAI的，如果我要与OpenAI的GPT模型进行通信，使用他们的API，那么这就是它的代码；而这段代码是Cloud API的，如果我要与Anthropic的Cloud SONNET进行交互。

那么这就是与它的API进行通信的代码，你已经可以看到有一点小小的区别，所以如果我要在同一个应用程序中使用两个LLM用于不同的目的，我就必须写两种不同类型的代码，或者假设我创建了一个应用程序，最初我是在Open AI的帮助下构建的，并且我写了这段代码，现在突然我不想使用Open AI的API了，因为它们太贵了，我想使用Cloud的API，那么我就必须修改我的代码库，将其转换过来，这是一项相当费力的工作。

所以基本上标准化成了一个挑战，Gemini的API表现方式不同，OpenAI的API表现方式不同，Cloud的API表现方式也不同，甚至我得到的返回响应也是不同类型的。于是LangChain发现了这个问题，LangChain识别出这个问题，并说如果我们能创建一个接口，让任何人都能以标准化的方式与任何公司的API进行交互会怎样。

意思是您不需要在代码中做太多修改，就能立即与Open AI进行通信，稍作改动后，您还可以与Gemini对话。这就是Lanchina的模型组件，模型组件本质上是一个接口，通过它，您可以与任何公司的AI模型进行通信。事实上，现在我要向您展示代码，请看下面，这里有两段代码。

在第一个代码中，我们正在与OpenAI的API进行交互，而在第二个代码中，我们正在与云端进行交互。现在你可以亲自去看看代码中有多少差异。这里你只是调用了不同的包，之后调用方式是完全相同的，返回结果后打印的方式也完全相同。你实际上只需要修改一行，仅需修改两行，一行是这个，另一行是这个。

你的工作完成了，你可以立即切换到从Open AI到云端，事实上，你得到的答案也会非常相似，所以解析它们也变得非常容易。简而言之，models组件是与AI模型交互的整个接口，它将其标准化，好吗？我希望你现在明白了models组件是什么。现在我要在这里讨论另一件事。

在Lang Chain中，你可以与两种类型的模型、两种AI模型进行交流，第一种是语言模型，第二种是嵌入模型。好的，我很快给你介绍一下这两种模型。语言模型基本上是LLMs（大型语言模型），你给这些模型一个文本输入，比如“how are you today”，然后它会返回一个文本输出，比如“I am good, how about you”。所以，LLMs基本上就是语言模型。

那些在文本输入文本输出哲学上工作的人，好吧，在他们的帮助下，你可以创建所有的应用程序，你可以创建聊天机器人，你可以创建AI代理，所有这些你都可以在语言模型的帮助下完成。嵌入模型略有不同，这些模型是你输入文本，但它们会返回一个向量作为输出。

而且我们在上一个视频中也讨论过这个问题，它们的主要用途是语义搜索，这一点我在上一个视频中也告诉过你们，对吧？所以LangChain可以与这两种类型的模型进行通信，既可以与语言模型通信，也可以与嵌入模型通信。事实上，我会向你们展示LangChain中有哪些语言模型可用，以及有哪些嵌入模型可用。

所以如果你进入文档，这是LangChain的文档，在这里你来到聊天模型的部分，你会看到这里下面，你会找到所有可以与LangChain帮助进行通信的提供商，有Chat-Anthropic，Chat-Mystril AI，Chat-Azure，Chat-Open AI，Chat-Vertex AI，Chat-Bedrock（这是AWS的），Chat-Hugging Face，所以你会在这里看到很多你之前可能听说过的名字。

不仅如此，他们还告诉你这些语言模型有哪些功能可用，比如是否有工具调用的功能（这在创建代理时很有用）、是否能获得结构化输出、是否支持多模态输入等，所有这些信息都在这里提供了。所以，你一定要去看看这个列表，了解一下有哪些语言模型可用。

其次，这个页面告诉你Lang Chain中有哪些嵌入模型可用。再次，你会发现很多知名的名字，比如Open AI、Mysterial AI，还有IBM的嵌入模型，还有Ullama。所以我建议你去稍微探索一下，读一读这个页面，你会稍微建立起自己的观点。简而言之，如果我可以总结的话，模型这个组件基本上是一个接口。

借助它，您可以通过AI模型进行沟通，并解决最大的问题，这个接口这个组件就是，以前不同的API和LLM各自为政，而这个特定组件将整个事情标准化，这样您只需进行少量代码更改，就可以与任何LLM提供商进行交互，这就是这个特定组件背后的整个理念。

我真的希望你能理解这一点，Lang chain的第二个组件是prompts，现在prompts是什么呢，一旦你理解了它，所以，如果你正在使用某个LLM，那么你发送给那个LLM的输入，就被称为prompt，所以prompts基本上就是提供给LLM的输入，比如如果你正在使用chat gpt，并且你向chat gpt提问了，what is campus x，那么这个字符串，what is campus x，你可以称之为prompt。

现在提示词在大型语言模型的世界中非常重要，大型语言模型的输出很大程度上依赖于提示词，实际上非常敏感。也就是说，如果你稍微改变一下提示词，大型语言模型的输出就会发生很大变化。举个例子，假设你问一个大型语言模型：“用学术语气解释线性回归”，然后你又问同一个模型另一个问题。

用有趣的语气解释线性回归，你会发现你只改了一个词，但你的LLM输出会大不相同，所以提示词超级重要。实际上，过去两年里围绕提示词已经兴起了一个研究领域，你会发现这个领域有很多工作机会。这个领域叫做提示工程，而这个职位叫做提示工程师，尽管目前在社交媒体上有点名声不佳。

但相信我，这是一个重要的研究领域，围绕大语言模型（LLMs），所以LangChain也意识到了这一点，既然我们在帮助构建基于LLM的应用程序，而LLMs非常依赖于提示（prompts），那么我们应该拥有一个非常优秀的组件来处理提示。于是他们开发了与提示相关的组件，LangChain在创建提示方面给了你很大的灵活性。

事实上，你可以创建很多不同且强大的提示类型。在LangChain中，我给你一些例子。比如，这里我们来看第一个例子，你可以做什么？你可以借助LangChain的帮助，创建非常强大、动态且可重复使用的提示。例如，你事先并不知道用户会让我总结哪个主题，以及以什么语气进行总结。那么，我能做的就是创建一个动态提示，这就是我的提示。

我只是放了一些占位符在这里，比如我还没说主题，也没提到情感。现在，我会问用户，用户会告诉我，比如“用有趣的语气告诉我关于板球的事”。那么现在我可以快速把占位符换成“板球”和“有趣”，然后把这个提示发送给我的大语言模型。同样地，明天可能会有另一个用户来使用同样的提示。

比方说，生物学，用严肃的语气，对吧，所以这是Lanchain中的可重用提示，此外，如果你想，你也可以创建基于角色的提示，所以你可以做的是，你先创建一个系统级别的提示，在那里你写一个类似这样的消息：嗨，你是一个经验丰富的，然后你放一个占位符，职业的，职业会在之后由用户告诉你，然后你创建一个用户级别的提示。

当用户说“告诉我关于这个话题”，以后如果有用户来问“你是一位经验丰富的医生”，那么这里就会填充内容，话题就会变成“病毒性发烧”，这个话题就会出现在这里。所以你在做什么呢？你在引导你的LLM，告诉它“你是一位经验丰富的医生”，现在请以一位经验丰富的医生的身份告诉我关于病毒性发烧的信息。同样地，明天可能会有另一个用户来说“嗨，你是一位经验丰富的工程师”。

告诉我关于开发桥梁的事情，我不知道，类似这样的东西，你也可以进行基于角色的提示，使用LangChain，下一个例子也非常有趣，如果你想的话，可以进行少量示例提示，使用LangChain，那么少量示例提示是什么呢，就是你首先给你的LLM展示一些例子，然后问它一个问题，比如假设你正在为客服创建一个聊天机器人，

那么你首先会做什么呢？你会给你的LLM展示一些例子，之前的信息，然后你告诉它这些信息属于什么类型，就像这里写的，“我这个月被收取了两次订阅费”，这是一个账单问题，我已经提前告诉了LLM。我还给出了另一个例子，“每次我尝试登录时应用都会崩溃”，这是一个技术问题，“你能解释一下如何升级我的套餐吗”。

我告诉过你输出应该是什么，现在我在做什么，我正在创建一个模板，我会按照这个格式向LLM提问，这将是我的工单，也就是我的查询，输出中需要说明类别，好的，现在我要做什么，我会创建一个简短的提示模板，我会把我所有的例子都放进去，我会给出我的示例提示，我会给出我的示例模板。

而现在我该怎么做呢，我会发送一个新的查询，然后我会问，基于你之前看到的例子，告诉我这个新例子属于哪个类别。那么接下来会发生什么呢？基于整个代码，我的LLM将收到这个提示。看这里写着：将以下客户支持票据分类到以下类别之一：账单问题、技术问题。

对于一般查询，这是我的示例1，这是我的示例2，这是我的示例3，这是我的示例4，以及这是我的最终查询，我的用户向我提出的，在这一点上，现在我的LLM会在这里打印出类别，好的，所以这是一个非常出色的少量示例提示模板，好的，所以你可以非常轻松地创建它，使用LangChain，现在在这一点上，如果你觉得有点困难，一个完整的代码，

因为，显然你没有读过所有这些内容，所以不用担心，我只是想向你展示一个概念，那就是你可以通过提示组件在Lang Chain中实现多少种不同的提示技术。所以，再次强调，这是一个非常重要的组件，未来我们会在此基础上制作一两个专门的视频。接下来是Lang Chain的另一个组件，它的名字叫做Chains，这个组件非常重要，以至于Lang Chain就是以它的名字命名的，明白了吗？

那么我来解释一下，chains是什么，它们能做什么。chains基本上是一个组件，借助它我们可以在lang chain中构建pipelines。所以，基本概念是，无论你构建什么LLM应用，你都可以给它一个pipeline的形状，对吧。而你可以借助chains的帮助来构建这个pipeline。好了，我来给你举一个例子，假设，

你需要开发一个LLM应用程序，用户会在输入中提供一大段英文文本，大约1000字左右，而你的任务是在输出中提供其少于100字的印地语摘要。这个LLM应用程序需要你来构建。那么，你决定整个应用程序的流程如下：首先你会收到输入，然后将这个输入首先发送给一个LLM，这个LLM的任务是将输入翻译成印地语。

所以这里正在进行翻译工作，之后我们会把翻译好的文本发送到第二个LLM中，这个LLM会做什么呢？它会生成一个少于100字的印地语摘要。那么你已经为你的LLM应用程序决定了这个流程，现在你可以轻松地将这个流程以管道的形式表示出来，对吧？现在如果你不使用链式结构，你需要做什么呢？

整个流程设计需要手动完成，这意味着你需要从用户那里获取输入，然后调用这个LLM，将输入提供给它，并告诉它将其翻译成印地语，你会得到印地语翻译，然后你再将其传递给另一个LLM，告诉它生成印地语翻译的摘要，最后你会得到最终的输出。

所以如果你手动设计整个流程，你需要从每个阶段提取输出，并手动将其输入到下一个阶段。链式结构解决了这个问题，链式结构最大的特点是它能自动将一个阶段的输出作为下一个阶段的输入，你不需要为此手动编写任何代码。

这意味着如果你借助链的帮助完成了整个任务，那么你只需要在这里提供一个英文文本，并调用链，然后在幕后，所有这些任务都会自动执行，你将直接在这里得到你的结果，你不需要担心中间的环节，比如LLM1的输出需要我输入到LLM2中，链在幕后完成了所有这些繁重的工作。

那么，如果用简单的语言来说，chain（链）这个概念可以帮助你在Lang chain中构建一个流水线。这个流水线最大的优点在于，前一个阶段的输出会自动成为下一个阶段的输入，你不需要为此手动编写代码。好了，还有更好的地方在于，我刚才向你展示的chain只是一个简单的顺序链，其中一个阶段接一个阶段地进行。

但如果你愿意，借助链条的帮助，你可以构建非常复杂的管道，对吧，事实上，我会给你一些例子，比如你可以构建的一个管道是并行链的，我会重写它，并行链，那么，里面有什么呢，比如说，你想做什么，你想构建任何一个这样的应用程序，用户会在那里给你一个输入，

并且你需要根据该输入打印一份详细报告给用户，比如假设用户写了911事件，那么你的输出中会有一份详细报告，好吗，现在你想在其中实现什么功能，即你想在其中结合多个LLM的输出展示出来，好吗，

也就是说，你的流程会是这样的：你会收到输入，然后将该输入发送给LLM1，LLM1会做什么呢？它会生成关于该主题的报告。同时，你也会将同样的输入发送给LLM2，LLM2也会生成一份关于它的报告。然后你在做什么呢？你会发送给第三个LLM，并要求它将这两份报告合并起来。

欢迎参加讲座。如果你在讲座中受到欢迎。在那里你正在并行执行一些事情。那么你可以非常轻松地改变整个流程的执行方式。我再举一个例子。还有一个例子是关于条件变化的。在那里你可以基于不同的条件进行各种处理。比如假设你正在创建一个AI代理。它接收用户的反馈。所以你问用户觉得我们的服务怎么样。用户告诉你他对反馈的感受。现在你正在用LP Open Allam处理这个反馈。如果反馈是好的，你就说声谢谢，事情就结束了。但如果反馈不好，你会立即给你的客户支持团队发一封邮件。如果你在处理这个流程，你可以轻松地构建它，这里进行的处理是基于一个条件的，而且用LP Open Change也很容易实现。使用Change组件和Long Change，你可以构建更多类似甚至更复杂的流程。

设计非常精美，并且大大减少了您的工作量。稍后我们会详细解释变更，但无论如何，让我们先阅读一下它的定义。这里写着：索引将您的应用程序连接到外部知识源，如PDF网站和数据库。那么，索引是什么呢？第三部分是向量存储，第四部分是检索器。这四部分组合在一起就形成了索引。

让我们详细讨论一下什么是索引以及为什么需要它们。当你使用ChatGPT来处理所有查询时，ChatGPT通常能够回答你的所有问题，因为它是在整个互联网的数据上进行训练的，所以它知道答案。但有些情况下，ChatGPT无法回答你的问题。例如，如果我在一家名为XYZ的公司工作，我去问ChatGPT：“你能告诉我吗，因为我在XYZ公司工作”，而这个问题涉及到我们公司的私人数据，ChatGPT将无法回答，因为在训练时它没有看到这些数据。我们在私人和职业生活中所做的许多事情，与之相关的问题ChatGPT可能无法回答。

我们不能问ChatGPT，因为ChatGPT不知道这些信息，那么有什么解决方案吗？其实你可以让你的LLM连接一个外部知识库。比如我能做什么？我可以选择一个LLM，并为其提供我们XYZ公司的全部规则手册。现在，如果我提出一个普通问题，比如“印度的总理是谁”，这个LLM当然会回答，因为它在训练中已经见过这些内容。但是，如果我问“XYZ公司的休假政策是什么”，它也能回答，因为它现在有了这个外部知识来源。

好的，那么为了构建这类应用程序，我们使用了索引，这里有四个主要组成部分。现在好消息是，我在上一个视频中已经向你们介绍过这样的一个系统，我再给你们展示同样的例子。一般来说，这类系统是如何实现的呢？首先，你要做什么呢？在我们的案例中，就是我们的PDF，也就是我们公司的规则手册。

因为它非常大，伙计，它有1000页，是一家非常大的公司，所以也有很多规则。所以你首先需要做的是，无论那本规则手册放在哪里，伙计，它可能在Google Drive上，或者在S3上，你需要从那里加载它并带过来。加载的工作就是文档加载器的任务，对吧？所以无论从哪里获取数据，文档加载器将帮助您。现在，一旦您获取了数据，即获取了这个PDF，接下来您需要做什么才能实现对此文档的语义搜索呢？因此，您需要将整个文档分解为小块。可以根据页面、段落或章节进行分解。例如，我们正在按页面进行分解，那么一千页的文档我们就分解为一千个小块。这个分块操作是由谁来完成的呢？是我们的团队。

第二个组件文本分割器之后我们做什么？我们将文档转换为向量，以便进行语义搜索。对于每个页面，我们将使用一些嵌入模型创建嵌入，这是我们之前稍微讨论过的。那么现在我有了1000页对应的1000个嵌入向量。现在显然，因为我随时都可以进行搜索，今天可以，后天可以，十天后也可以，所以我必须把这些向量存储在某个地方。于是我把这些向量存储在一个数据库中。由于我们在这个数据库中存储向量，这种特殊的数据库被称为向量数据库或向量存储，这是我们的第三个组件。好了，现在我所有的嵌入都在一个向量存储中。现在会发生什么呢？一旦有用户查询，比如“兄弟，告诉我xyz公司的休假政策是什么”。

 
  
की तो यहाँ पर एक fourth component आता है picture में जिसका नाम है retriever retriever क्या करता है जट से इस query को उठाता है और इसका embedding generate करता है with the help of an embedding model और फिर जो vector हमें मिलता है उस vector को पकड़ के इस database में एक semantic search करता है और semantic search से उसको relevant results मिलते हैं और उन relevant results को और user की query को उठा के llm को देता है और llm फिर आपको पलट के reply करता है तो यह जो पूरी चीज हो रही है इसी को हम indexes के थूँ execute करते हैं और indexes में यह चार components मिल करके यह पूरा का पूरा heavy lifting करते हैं तो simple शब्दों में indexes is the way using which you can build llm applications which has access to external knowledge source ठीक है अब यहाँ पे external knowledge source कुछ भी हो सकता है pdfs भी हो सकते हैं कोई website भी हो सकती है या फिर किसी company का database भी हो सकता है यहाँ पे पूरी flexibility है ठीक है तो आगे चल के हम इस playlist में यह सारी चीजे करके आपको दिखाएंगे ठीक है मैं आपको प्राक्टिकली प्रॉपर प्रॉजेक्स बना के दिखाऊंगा कि कैसे यह पूरा काम होता है एं ट्रस्ट मी लांग चेन की वज़े से यह पूरा का पूरा काम बहुत असान हो जाता है तो आपको बहुत जाधा कोड लिखने की ज़रूरत भी नहीं है तो आपको इंडेक्स के बारे में थोड़ा आईडिया लग गया लांग चेन का अगला कंपोनेंट है मेमिरी अब नाम से तो शायद आपको थोड़ा समझ में आई रहा होगा बड़ थोड़ा डीटेल में डिसकस करते हैं यहा बेस्ट अप्लिकेशन्स बनाओगे तो आपको यह बात समझ में आईगी कि एलेलम में जब आप एपीऐ कॉल्स मारते हो तो वो सारे के सारे कॉल्स स्टेटलेस होते हैं इसका मतलब क्या हुआ एक इक्जांपल के थूँ मैं आपको समझाता हूँ मालो मैं कोई एले तो जट से मॉडल ने मुझे रिप्लाइ किया अब मैंने क्या किया मैंने अपने कोड में जा करके जो मेरा क्वेरी है उसको चेंज कर दिया और वहाँ पर मैंने लिख दिया अब यह सेम चीज मैंने एपीऐ पर हिट की यह नहीं है कि इसको याद ही नहीं है पिछला क्वेशन नरेंडर मोडी के बारे में पूछा गया यहां पर वो ही को डीकोड ही नहीं कर पारा अब हामे सलीद महवादी चॉम समझमे आ रहा है कि स्टेटलेस क्या होता है स्टेटलेस का मतलब ही होता है कि जबभी आप अपेकयकांपै मारते हो हमेशाएगर शाथ 스타일 में हर शाथ साथ साथ को अआपआट मुझ जऻगी है मतलब उसको प्रीवियस रिक्वेस्ट के बारे में कोई मेंबरी नहीं होती और इसे एक बहुत प्रॉबलम है आप खुछ सोचो अगर आप इस तरह के सिस्टम के साथ एक चैट बॉट बनाओ तो चैट बॉट से बात करना कितना फ्रस्ट्रीटिंग होगा क्योंकि उसको कोन्वर्सेशन की कोई मेंबरी रहेगी ही नहीं उसको हर घड़ी याद दिलाना पड़ेगा कि हम क्या बात कर रहे थे और ये बहुत बड़ी प्रॉबलम है जब आप एलेलम अप्लिकेशन्स बनाने जाते हो और इसी प्रॉबलम को सॉल्व करता है लैंगचेन का ये कंपोनेंट जिसका नाम है मेमरी सो मेमरी के हेल्ब से आप अपने पूरे के पूरे कोन्वर्सेशन में मेमरी का फीचर आड़ कर सकते हो ठीक है अब थोड़ा ये एडवांस टॉपिक है बट फिर भी मैं आपको थोड़ा सा बताता हूँ कि कितने तरह की मेमरी's अवेलेबल है लैंगचेन में हैं तो बहुत सारी अलग-अलग मेमरी's बट जो frequently यूज होने वाली मेमरी's हैं वो मैंने यहाँ पर लिख रखी हैं जैसे सबसे ज़्याल तो मेमरी यूज होती है वो है conversation buffer memory तो यहाँ पर आप क्या करते हो कि जैसे आप अपने chatbot से बात कर रहे हो तो अभी तक जितनी बात्चीत हुई है आप उस सब को store करके रखते हो और जब आप next API call मार रहे होते हो तो आप यह पूरा का पूरा chat history भी भेजते हो model के पास तो फिर उसको समझ में आ जाता है कि किस बारे में बात हो रही है ठीक है बस इसमें एकी problem है कि अगर आपकी chat बहुत बड़ी हो गई तो फिर क्या होगा यह chat history भी बहुत बड़ी हो जाएगी और फिर बहुत ज़ादा text को प्रोसेस करने में आपकी बहुत ज़ादा पैसे लगेंगे ठीक है तो यह एक टाइब की memory है second है conversation buffer window memory यहाँ पे आप last n interactions को store करके रखते हो जैसे आपने बोल दिया कि last 100 messages को store करके रखो तो यह constantly update होता रहता है और at any point आप last 100 interactions को अपने पास रखते हो और अगले API call में भेजते हो ठीक है उसके बाद third memory है summarizer based memory यहाँ पे आप क्या करते हो कि आप अभी तक की अपनी पूरी memory का I'm sorry अभी तक की अपने पूरे chat history का एक summary generate करते हो और वो summary आप अपने API call में भेजते हो ठीक है इस से हम थोड़ा text बचा पाते हैं और हमें थोड़ा कम पैसा देना पड़ता है इसके अलावा एक और memory होती है custom memory जहांपर आप थोड़े advanced use cases के लिए बहुत specialised pieces of information memory में रखते हो जैसे user के preferences हैं उनके बारे में कुछ facts and figures हैं यह आप हमेशा memory में रखते हो जिससे आपको आगे बाचीद करने में आसानी होती है ठीक है तो यह बहुत interesting topic है और honestly बहुत practical topic है थियोरिटिकल जो भी हमें discuss करना था हमने कर लिया बाकि going forward in the playlist हम इसके बारे में काफी detail में discussion करेंगे अब बात करते हैं आप पिछले छे मैनों की बात करो तो I am pretty sure आप ने कभी ना कभी कही ना कहीं AI Agents के बारे में definitely सुना होगा हर कोई एक ही बात बोल रहा है कि AI Agents are going to be the next big thing जो की सच हो भी सकता है पर ठीक है जो भी है एक बार हम थोड़ा स्क्राथ से fundamentally समझने की कोई करते हैं कि AI Agents क्या होते हैं और आप लेंग चेन में कैसे बिल्ड कर सकते हूँ हमने multiple times यह discuss कर लिया कि LLMs में दो बहुत बड़ी खोबियां है पहला है NLU और दूसरा है text generation मतलब LLMs language को समझते भी हैं और समझ के पलट के सही text भी generate कर पाते है तो अब जब LLMs आये पिक्चर में तो सबसे obvious जो use case था LLMs का वो था chatbot बनाना और लोगों ने खुब chatbot बनाये LLMs को यूज़ करके अगर मेरा chatbot मेरी बात अच्छे से समझ सकता है और reply कर सकता है तो वो पलट के कुछ काम भी कर सकता है जैसे एक example लेके मैं आपको समझाता हूँ माल लो मैं एक travel website पे एक chatbot से बात कर रहो make my trip माल लो मैं ने उस chatbot से पूछा की can you tell me summer के time में इंडिया में best travel destination कौन सा है अगर ये chatbot के बदले एक AI एजिन्ट होता तो मैं इस से कुछ काम भी करवा सकता हूँ जैसे मैं इस से तुरंट ये question पूछ सकता हूँ की can you tell me 24th जैनवरी को सबसे cheapest flight कौन सी है डेली से शिमला के बीच और ये AI एजिन्ट क्या करेगा ये जट से किसी API पे hit करेगा और ये answer निकाल के ले आएगा की ओके इंडिगो की ये flight है जो सबसे चीप है on 24th जैनवरी from Delhi to शिमला अब मैं फिर से क्या कर सकता हूँ एक step आगे बढ़ करके इसको बोल सकता हूँ can you book the flight और सिंस इसके पास ये capability है वो जट से जा करके make my trip की website पे हमारी ये flight bookinging भी कर देगा और ये एक बड़ के लिए चाट बॉट के लिए अच्छाट बॉट के लिए आजेंट के लिए अच्छाट बॉट के लिए अच्छाट बॉट के लिए आजेंट के लिए अच्छाट बॉट के लिए अच्छाट बॉट के लिए अच्छाट बॉट के लिए आजेंट के लि में बेसिकली दो चीज़े होती हैं जो चाट बॉट के बास नहीं होती पहला इसके पास रीजनिंग केपिबिलिटी होती है और दूसरा AI एजेंट के पास कुछ टूल्स का एकसेस होता है जैसे इस API पे हिट करके ये निकाल के लापाना की सबसे सस्ती फ्लाइट कौन सी है तो अलग अलग टूल्स का एकसेस रहता है AI एजेंट के पास ठीक है इन दोनों केपिबिलिटी की help से एक AI एजेंट आपके काम करके दे सकता है ठीक है तो एक example के थूँ मैं आपको समझाता हूँ कि AI एजेंट काम कैसे करता है exactly ठीक है तो माल लो हमारे पास एक AI एजेंट है हमने बनाया और हमने उसको दो टूल्स दिये पहला टूल है एक calculator मतलब कभी भी during any conversation मेरे AI एजेंट को अगर कोई भी mathematical calculation करना है तो वो जट से इस tool को use कर सकता है और second मैंने इसको एक weather API का access दिया है कि अगर कभी भी इसको दुनिया में किसी भी city का weather condition निकालना है किसी भी date पे तो ये निकाल सकता है ये दो टूल्स मैंने दे रखे हैं अपने AI एजेंट को अब एक user आता है और वो मेरे AI एजेंट से बात करना शुरू करता है और वो question पूछता है कि can you multiply the temperature और राधर today's temperature of Delhi with 3 this is the query यूजर ने बोला क्या आप आज के Delhi के temperature को 3 से multiply करके मुझे answer बता सकते हो अब देखो ये AI एजेंट इस query को कैसे handle करेगा so since इसके पास reasoning capability है it means कि वो reason कर सकता है कि मुझे exactly करना क्या है ठीक है तो यहाँ पे अलग-अलग techniques के थूँ reasoning होती है बहुत सारे popular techniques हैं उनमें से एक बहुत popular technique है chain of thought prompting जहां पे आपका AI एजेंट क्या करेगा आपके query को break down करेगा step by step और फिर उसके through वो reason करने की कोशिश करेगा जैसे AI एजेंट जैसे इये query पढ़ेगा can you multiply today's temperature of Delhi with 3 तो वो इस पूरे query को पहले break down करेगा step by step वो बोलेगा कि मुझे आज के Delhi के temperature को 3 से multiply करना है मतलब मुझे इसके लिए Delhi का आज का temperature चाहिए और जैसे ही मुझे temperature मिल जाएगा मैं उसको 3 से multiply कर सकता हूँ ठीक है अब उसका पूरा focus आ जाएगा Delhi का आज का temperature निकालने के उपर तो वो जाकर के चेक करेगा कि क्या उसके पास कोई ऐसा tool है जो उसको Delhi का temperature बता सकता है तो वो notice करेगा कि हाँ उसके पास एक weather API है तो वो जट से weather API पे hit करेगा और input में देगा Delhi और weather API पलट करके result में बोलेगा 25 degree Celsius तो अब आपका agent बोलेगा कि अब मेरे पास Delhi का temperature है अब मुझे इस number को 25 degree Celsius को 3 से multiply करना है बट ये operation perform करने के लिए मुझे calculator की ज़रूरत है तो वो वापस जाकर अपने tools में चेक करेगा कि क्या मेरे पास calculator का access है the answer is yes तो वो जट से इस calculator को call करेगा और उसको input में देगा 25, 3 and multiplication का operation ये तीनो inputs calculator में जाएंगे calculator पलटके 75 बोलेगा और यही 75 finally आपका output बन जाएगा and this is how AI agents work ठीक है so basically summarize अगर मैं करूँ तो AI agent और chatbot में बस इतना ही difference है कि AI agent के पास reasoning capacity है और tools का access है ठीक है so an AI agent is just evolved form of chatbot where you can perform some action with the help of AI agents because it has got reasoning capabilities and access to tools ठीक है I hope आपको समझ में आ गया बहुत interesting topic है और अभी ऐसा लग रहा है जैसे सारी बड़ी companies और जो अच्छे सारे researchers है AI के world में वो सब इस topic पर converge कर रहे है and I am pretty sure अगले एक से देड़ साल में इस front पे बहुत progress होने वाली है तो हम इसको भी काफी detail में discuss करेंगे Lang chain में बहुत आसान बना दिया है AI agents को बनाना और हम एक AI agent बना के आपको दिखाएंगे ठीक है तो with that this concludes our discussion हमने सारे components के वारे में एक introduction ले लिया अब हम लोग एक एक करके इन सारे components को detail में study करेंगे जैसे हमारा जो next video है वहाँ पे हम जो first component है Models वाला उसको काफी detail में देखने वाले है ठीक है तो अगर आपको video पसंद आया please like करना और अगर आपने इस channel को subscribe नहीं किया है please do subscribe मिलते हैं next video में bye