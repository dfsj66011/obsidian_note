

欢迎来到当今人工智能领域最激动人心的话题：模型上下文协议（MCP）！

这门免费课程是与Anthropic合作开发的，将带你从入门到精通，逐步理解、使用并开发基于MCP的应用程序。

第一单元将帮助你快速上手：

- 了解课程大纲。
- 获取有关认证流程和日程安排的更多信息。
- 认识课程背后的团队。
- 创建您的账户。
- 加入我们的 Discord 服务器，与同学和我们见面。

让我们开始吧！

## 本课程将带给你什么？

在本课程中，您将：

- 📖 学习模型上下文协议的理论、设计与实践。
- 🧑‍💻 掌握使用成熟的 MCP SDK 和框架。
- 💾 分享你的项目，探索社区创建的应用。
- 🏆 参与挑战，将你的 MCP 实现与其他同学的成果进行对比评估。
- 🎓 完成作业，获得结业证书。

还有更多！

在本课程结束时，您将了解 MCP 的工作原理，以及如何利用最新的 MCP 标准构建自己的 AI 应用程序，这些应用程序可以整合外部数据和工具。

## 课程是什么样的？

该课程包括：

- 基础单元：学习 MCP 理论概念的部分。
- 实践环节：学习使用成熟的 MCP SDK 构建应用程序。这些实践环节将提供预配置的环境。
- 用例作业：应用所学概念解决你选择的现实问题。
- 合作项目：我们正与 Hugging Face 的合作伙伴协作，为你提供最新的 MCP 实现和工具。

本课程是一个持续发展的项目，将根据您的反馈和贡献不断演进！欢迎在GitHub上提交问题和拉取请求，并在我们的Discord服务器中参与讨论

## 教学大纲是什么？

以下是本课程的总体教学大纲。每个单元将发布更详细的主题列表。

| 章节  | 主题             | 描述                                                           |
| --- | -------------- | ------------------------------------------------------------ |
| 0   | 入职培训           | 为你配备所需的工具和平台。                                                |
| 1   | MCP 基础、架构与核心概念 | 解释模型上下文协议（Model Context Protocol）的核心概念、架构和组件。展示一个使用MCP的简单用例。 |
| 2   | 端到端用例：MCP实战    | 构建一个简单的端到端MCP应用程序，可以与社区共享。                                   |
| 3   | 部署用例：MCP实战     | 使用Hugging Face生态系统和合作伙伴服务构建一个已部署的MCP应用程序。                    |
| 4   | 奖励单元           | 额外单元助您充分利用课程，与合作伙伴的图书馆和服务协同工作。                               |

## 有什么先决条件？

要参加本课程，您应具备：
* 对人工智能（AI）和大语言模型（LLM）概念的基本理解​
* 熟悉软件开发原则和API概念​
* 至少掌握一门编程语言（课程示例将使用Python或TypeScript）

如果你没有这些也不用担心！以下是一些可以帮助你的资源：

* LLM 课程​ 将带你了解使用和构建大型语言模型的基础知识。
* 智能代理课程​ 将指导你如何用大型语言模型构建 AI 代理。

> 上述课程本身并非先决条件，因此只要您理解了大语言模型（LLMs）和智能体的概念，现在就可以开始学习本课程！

## 我需要哪些工具？

你只需要两样东西：

- 一台能上网的电脑。
- 一个账户：用于访问课程资源和创建项目。如果还没有账户，你可以在这里免费注册一个。


# 模型上下文协议（MCP）简介

欢迎来到MCP课程的第一单元！在本单元中，我们将探讨模型上下文协议的基础知识。

## 你将学到什么

在本单元中，您将：

- 了解什么是模型上下文协议（MCP）及其重要性
- 学习与MCP相关的关键概念和术语
- 探讨MCP解决的集成挑战
- 了解MCP的主要优势和目标
- 查看一个简单的MCP集成实例

在本单元结束时，您将对MCP的基础概念有扎实的理解，并准备好深入探讨下一单元中关于其架构和实现的内容。

## MCP 的重要性

人工智能生态系统正在迅速发展，大型语言模型（LLMs）和其他人工智能系统的能力日益增强。然而，这些模型往往受限于其训练数据，无法获取实时信息或专业工具。这种限制阻碍了人工智能系统在许多场景中提供真正相关、准确且有帮助的响应的潜力。

这就是模型上下文协议（MCP）的用武之地。MCP使AI模型能够连接外部数据源、工具和环境，实现AI系统与更广泛的数字世界之间信息和能力的无缝传输。这种互操作性对于真正实用的AI应用的发展和采用至关重要。

## 第一单元概述

本单元内容概要如下：

1. 什么是模型上下文协议？——我们将首先定义MCP是什么，并讨论它在AI生态系统中的作用。
2. 关键概念——我们将探讨与MCP相关的基本概念和术语。
3. 集成挑战——我们将分析MCP旨在解决的问题，特别是“M×N集成问题”。
4. 优势与目标——我们将讨论MCP的主要优势和目标，包括标准化、增强AI能力和互操作性。
5. 简单示例——最后，我们将通过一个简单的MCP集成示例来了解其实际运作方式。

让我们一起深入探索Model Context Protocol的精彩世界！


# 关键概念与术语

在深入探讨模型上下文协议（MCP）之前，理解构成MCP基础的关键概念和术语非常重要。本节将介绍支撑该协议的基本理念，并为整个课程中讨论MCP实现提供一个共同的词汇表。

MCP常被称为“AI应用的USB-C”。正如USB-C为连接各种外设与计算设备提供了标准化的物理和逻辑接口，MCP则为AI模型与外部能力对接提供了一致性协议。这种标准化让整个生态系统受益：

- 用户可以在各种AI应用中享受更简单、更一致的体验
- AI应用开发者可以轻松集成不断增长的工具和数据源生态系统
- 工具和数据提供商只需创建一次实现，即可适配多个AI应用
- 整个生态系统将从增强的互操作性、创新和减少碎片化中受益


## 整合问题

M×N 集成问题指的是在没有标准化方法的情况下，将M个不同的人工智能应用程序连接到N个不同的外部工具或数据源所面临的挑战。

### 没有MCP（M×N问题）

如果没有像MCP这样的协议，开发人员将需要创建M×N个自定义集成——每个集成对应AI应用程序与外部功能的一种可能配对。

![Without MCP](https://huggingface.co/datasets/mcp-course/images/resolve/main/unit1/1.png)

每个AI应用都需要单独与每个工具/数据源集成。这是一个非常复杂且昂贵的过程，给开发者带来了很多障碍，并产生了高昂的维护成本。

一旦我们拥有多个模型和多个工具，集成的数量就会变得难以管理，每个集成都有其独特的接口。

![Multiple Models and Tools](https://huggingface.co/datasets/mcp-course/images/resolve/main/unit1/1a.png)

### 采用MCP（M+N解决方案）

MCP通过提供一个标准接口，将这一问题转化为M+N问题：每个AI应用只需实现一次MCP的客户端，每个工具/数据源只需实现一次服务端。这极大降低了集成复杂度和维护负担。

![With MCP](https://huggingface.co/datasets/mcp-course/images/resolve/main/unit1/2.png)

## 核心MCP术语

既然我们已经了解了MCP解决的问题，现在让我们深入探讨构成MCP协议的核心术语和概念。

> MCP是一种类似于HTTP或USB-C的标准协议，旨在将AI应用程序与外部工具和数据源连接起来。因此，使用标准术语对于确保MCP有效运作至关重要。
> 
> 在记录我们的应用程序和与社区沟通时，应使用以下术语。

### 组件

就像HTTP中的客户端服务器关系一样，MCP也有客户端和服务器。

![MCP Components](https://huggingface.co/datasets/mcp-course/images/resolve/main/unit1/3.png)

Host：终端用户直接与之交互的面向用户的 AI 应用程序。示例包括Anthropic 的 Claude 桌面版、Cursor 等 AI 增强型集成开发环境（IDE）、Hugging Face Python SDK 等推理库，或基于 LangChain 或 smolagents 等库构建的自定义应用程序。Host 负责发起与 MCP 服务器的连接，并协调用户请求、LLM 处理和外部工具之间的整体流程。

客户端：宿主应用程序中的一个组件，负责管理与特定MCP服务器的通信。每个客户端与单个服务器保持 1:1 的连接，处理 MCP 通信的协议级细节，并充当宿主逻辑与外部服务器之间的中介。

服务器：一个外部程序或服务，通过MCP协议提供能力（工具、资源、提示）。

> 很多内容将“客户端”和“Host”混为一谈。严格来说，Host 是面向用户的应用程序，而客户端是 Host 应用程序中负责与特定 MCP 服务器通信的组件。

### 能力

当然，应用程序的价值在于它所提供的功能总和。因此，功能是应用程序最重要的部分。MCP可以与任何软件服务连接，但有一些常见功能适用于许多AI应用程序。

| Capability    | Description                                              | Example                      |
| ------------- | -------------------------------------------------------- | ---------------------------- |
| **Tools**     | AI模型可调用的可执行函数，用于执行操作或检索计算数据。通常与应用程序的用例相关。                | 天气应用程序的一个工具可能是一个返回特定地点天气的函数。 |
| **Resources** | 提供上下文但无需大量计算的只读数据源。                                      | 研究助理可能掌握着获取科学论文的资源。          |
| **Prompts**   | 预定义的模板或工作流程，用于指导用户、AI模型和可用功能之间的交互。                       | 一个总结提示。                      |
| **Sampling**  | 服务器发起的请求，要求客户端/主机执行LLM交互，从而实现递归操作，使LLM能够审查生成的内容并做出进一步决策。 | 一个写作应用程序审查自己的输出并决定进一步改进它。    |

在下图中，我们可以看到应用于代码代理用例的集体能力。

![collective diagram](https://huggingface.co/datasets/mcp-course/images/resolve/main/unit1/8.png)

该应用程序可能会以以下方式使用其MCP实体：

| Entity   | Name  | Description               |
| -------- | ----- | ------------------------- |
| Tool     | 代码解释器 | 一个可以执行LLM所编写代码的工具。        |
| Resource | 文档    | 包含应用程序文档的资源。              |
| Prompt   | 代码风格  | 引导大语言模型生成代码的提示词。          |
| Sampling | 代码审查  | 一种采样方法，允许LLM审查代码并做出进一步决策。 |

### 结论

理解这些关键概念和术语为有效使用MCP奠定了基础。在接下来的章节中，我们将在此基础上深入探讨构成模型上下文协议的架构组件、通信协议及其功能特性。

# MCP的建筑组件

在上一节中，我们讨论了MCP的核心概念和术语。现在，让我们更深入地探讨构成MCP生态系统的架构组件。


## Host, Client 和 Server

模型上下文协议（MCP）基于客户端-服务器架构构建，可实现AI模型与外部系统之间的结构化通信。

![MCP Architecture](https://huggingface.co/datasets/mcp-course/images/resolve/main/unit1/4.png)

MCP架构由三个主要组件构成，每个组件都有明确的角色和职责：主机（Host）、客户端（Client）和服务器（Server）。我们在上一节简要提及过这些组件，现在让我们深入探讨每个组件及其具体职责。

### Host

主机是面向用户的AI应用程序，终端用户可以直接与之交互。

示例包括：

- AI聊天应用，如OpenAI的ChatGPT或Anthropic的Claude桌面版
- 增强AI功能的集成开发环境（IDE），如Cursor，或与Continue.dev等工具的集成
- 使用LangChain或smolagents等库构建的自定义AI代理和应用程序

在大多数情况下，用户会根据自身需求和偏好选择 Host 应用。例如，开发者可能选择Cursor，因其强大的代码编辑功能；而领域专家则可能使用基于 smolagents 构建的定制化应用程序。


### Client

客户端是主机应用程序中的一个组件，负责管理与特定MCP服务器的通信。其主要特点包括：

- 每个客户端与单个服务器保持1:1连接
- 处理MCP通信的协议级细节
- 充当主机逻辑与外部服务器之间的中介 

### Server

服务器是一个外部程序或服务，通过MCP协议向AI模型提供功能。服务器：

- 提供对特定外部工具、数据源或服务的访问
- 作为现有功能的轻量级封装
- 可在本地（与主机同一台机器）或远程（通过网络）运行
- 以标准化格式公开其功能，供客户端发现和使用

## 沟通流程

让我们来看看这些组件在典型的MCP工作流程中是如何相互作用的：

> 在下一节中，我们将通过实际示例深入探讨使这些组件得以运行的通信协议。

1. **用户交互**：用户与主机应用程序进行交互，表达意图或查询。
2. 主机处理：主机处理用户的输入，可能会使用大型语言模型（LLM）来理解请求并确定可能需要哪些外部功能。
3. 客户端连接：主机指示其客户端组件连接到相应的服务器。
4. 能力发现：客户端查询服务器以发现其提供的能力（工具、资源、提示）。
5. 能力调用：根据用户需求或LLM的判断，主机指示客户端从服务器调用特定功能。
6. 服务器执行：服务器执行所请求的功能并将结果返回给客户端。
7. 结果整合：客户端将这些结果反馈给主机，主机将其整合到LLM的上下文中或直接呈现给用户。

这种架构的一个关键优势在于其模块化特性。单个主机可以通过不同的客户端同时连接到多个服务器。新的服务器可以轻松加入生态系统，而无需对现有主机进行任何修改。不同服务器之间的功能可以轻松组合。

> 正如我们在上一节所讨论的，这种模块化设计将传统的M×N集成问题（M个AI应用连接到N个工具/服务）转化为更易管理的M+N问题，其中每个主机和服务器只需实现一次MCP标准。

该架构看似简单，但其优势在于通信协议的标准化和组件间职责的明确划分。这种设计形成了一个紧密的生态系统，使人工智能模型能够与不断增长的外部工具和数据源无缝连接。

## 总结

这些交互模式遵循着塑造MCP设计与演进的几项核心原则。该协议通过提供通用AI连接标准实现标准化，同时保持核心协议简洁性以支持高级功能扩展，以此贯彻简约理念。安全机制要求敏感操作必须获得用户明确授权，可发现性则支持动态功能探测。协议设计秉持可扩展思想，通过版本管理与能力协商支持迭代升级，并确保不同实现方案与运行环境间的互操作性。

在下一节中，我们将探讨使这些组件有效协同工作的通信协议。
