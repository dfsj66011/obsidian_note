
### 1、概览

**训练目标：**

深度生成模型试图解决的问题——它利用少量样本，对新数据做出最佳预测估计。而我们要做的是，通过某种方式训练模型，使其学会匹配数据的真实分布，但问题是我们没有足够的样本来理解真实分布，所以我们最终只能得到一个近似分布，然后从这个近似分布中采样。用数学术语来说，这个真实分布用 $P_{\text{data}}(X)$ 表示，而预测分布用 $P_\phi(X)$ 表示。本质上，我们试图做的就是让 $P_\phi(X)$ 与 $P_{\text{data}}(X)$ 相匹配。这正是深度生成模型训练的目标。

------

**深度生成模型（DGMs）**

深度生成模型（DGMs）的输入是从未知且复杂的数据分布中提取的大量现实世界样本，它们输出的是一个训练好的神经网络，该网络参数化了一个近似分布。

DGMs 两大目标：

1. 始终追求生成逼真的内容（真实性生成）
2. 实现可控的生成可控性生成（可控性生成）


**输入：** 假设样本是从一个潜在的、我们并不了解的复杂数据分布中独立同分布抽取而来的。

DGMs 的主要目标是从有限数据集中学习概率分布，它使用深度神经网络对模型分布进行参数化，其中 $\phi$ 代表网络的可训练参数。训练目标是找到最优参数 $\phi^*$，使模型分布 $P_\phi(X)$ 与真实分布 $P_{\text{data}}(X)$ 之间的差异最小化。

该模型通常被称为生成模型，因为一旦模型训练完成，我们就能从这个分布中采样，生成源源不断的新样本，这些样本都符合真实数据分布。

--------

**KL 散度** 

$$D_{\mathrm{KL}}(P|Q) = \sum_x P(x) \log \frac{P(x)}{Q(x)}  $$

参数 $φ$ 是通过最小化 $P_{\text{data}}$ 与 $P_\phi$ 之间的差异来学习的。如何量化这两个概率分布之间的差异？KL 散度。

$$\text { Penalty }(x)=P(x) \cdot \log \frac{P(x)}{Q(x)}$$
$P(x)$ 衡量了结果 $x$ 的重要性（因为它发生的频率如此之高）。

形式化理解：$P(x)$ 是真实分布；$Q(x)$ 是预测分布；最直接的方法，求绝对值，绝对差值是个不错的起点，但它并不能涵盖所有情况。例如，如果我们计算绝对差值并将所有这些绝对差值相加，当样本范围内包含大量数据点时，总和可能会变得非常大。

因此，我们需要一种能够捕捉这种差异的度量方法，并且在数据点数量巨大的情况下也不会失控。而通过这两个分布之间的比率，可以很好地实现这一点。但我们实际取比率的对数，其结果还需要乘以 $p(x)$，即数据在真实分布下的重要性（概率）。

举个例子，比如 $P(A)=0.9, Q(A)=0.1$，在比较重要的样本点上，预测的很离谱，则惩罚很大，1.98；而反之，如果 $P(B)=0.1, Q(B)=0.9$，在不重要的样本点上，预测很离谱，-0.21，惩罚不大，而如果精确相等，则惩罚为 0。

---

**模型预测分布与基本设置：**

$P_\phi$ 表示的预测分布必须是一个概率分布，因此，它必须满足两个基本属性：

1. 非负性，即对于所有 $x$，$P_{\phi}(x)> 0$。
2. 整个定义域上的积分应该等于 1。

*如何确保非负性？* 只需对神经网络的原始输出应用一个正函数即可，例如指数函数；

*如何确保积分为 1？* 归一化？

*然而最大的挑战在于这个归一化常数，也称为配分函数，它是难以处理且无法计算的*。因为我们甚至不知道有多少样本，这看起来是一项艰巨的任务。因此，在复杂场景下这是不可能计算的。这种难以处理的问题是推动不同深度生成模型家族发展的核心原因。

----

**不同类型的深度生成模型：**

*基于能量的模型*：其基本原理是将概率转换为能量值，给更有可能的数据点分配较低的能量，而给不太可能的数据点分配较高的能量。

想象一下，我们收集了 1000 名学生在某门课程中的考试成绩，学生的分数并不是在 0 到 100 之间均匀分布的，数据是有一定形状的。例如，多数学生的分数集中在 70 分左右，少数在 40 分左右，还有少数在 90 分左右。

基于能量的模型并不直接分配概率，而是为每一个可能的得分赋予一个能量值。能量表示模型认为该分数有多么不寻常。能量越低意味着它更典型，能量越高意味着它不那么典型。例如，80 分概率高，则 80 分获得低能量。在基于能量的模型中，首先会预测所有得分的能量分布，能量分布可以很容易地转换为概率分布，方法是对能量分布取指数。

*自回归模型*：目标是预测下一个 token。而下一个部分取决于到目前为止生成的所有内容。

*变分自编码器*：编码器基本上将输入压缩成一个小的潜在嵌入。输入被压缩后，潜在空间会捕捉数据中的隐藏结构。这就像一种压缩数据的方式，然后从潜在空间，数据通过解码器将潜在嵌入转换回一个看起来与输入非常相似的样本。这与传统的自动编码器非常不同，因为潜在空间是概率性的。它学习的是一个分布，而不是单一的值。

*归一化流*：想象一下，有两种形状，比如一个完美的圆球和一张皱巴巴的纸。归一化流是一种方法，它学习如何缓慢而平滑地拉伸、扭曲和弯曲简单形状，使其在不撕裂或粘合任何部分的情况下精确转变为复杂形状。比如从一些噪声开始，如高斯分布，然后应用不同的操作，比如拉伸、扭曲，这几乎就像一个流体元素。从一些简单的分布开始，然后扭曲它、弯曲它、转动它，以达到真实分布，这正是深度生成模型试图预测的。

*生成对抗网络*，由两个网络组成，一个生成器和一个判别器，它们相互竞争。

--------

### 2、VAE

**基本原理：**

简单例子，假设你收集了班上所有同学的手写样本。比如这些学生都写了 “hello”，我们假设有 100 名学生，他们都在纸上写了 “hello”，每个人书写风格不同。假设现在要求造一台机器，它能够生成 “hello” 这个词的手写样本，并且这些样本要与班上学生的手写风格相匹配。实际上，我们希望的是预测班级学生手写风格的概率分布，这是 DGM 的主要目标之一。

因此，直觉的想法是：决定手写风格的隐藏因素是什么？每个学生的手写风格取决于许多 *隐藏特征*，例如书写的压力、是否倾斜、字母宽窄、书写速度、字迹整洁度等等，如果能捕捉到所有这些特征，并编写一个函数，将这些特征作为输入，然后输出笔迹。然而，这些特征在最终的图像中是看不到的，但它们确实影响了字母的形状。

**解码器**：

潜在变量 $z$，潜在空间的维度通常比实际数据分布要低，潜在空间相对于真实数据分布是压缩的。解码器通常是一个神经网络，根据样本在潜在空间中的位置，生成的数据也会有所不同。为了避免解码器输出确定性结果，要求它输出每个像素点概率分布的均值和标准差，例如对于 28x28 的图像，就有 $\mu_{1},\sigma_{1}, \cdots \mu_{784},\sigma_{784}$。我们使用神经网络将潜在空间变量 $z$ 作为输入，并在真实空间中生成输出。*解码器预测的是像素概率，而不是最终的图像*。一旦获得这个分布，我们就可以从中采样以得到各种输出结果。

**编码器**：

这种从真实空间到潜在空间的压缩是如何发生的？一种方法是访问潜在空间中的所有可能点，看看哪些图像与目标图像最接近，显然这不是一个好的解决方案，因为它完全难以处理。

所以我们希望潜在空间中的位置实际上是有意义的，并且对应着某些信息。为什么它被称为变分自编码器？相比较纯自编码器中，变分自编码器所做的不是给出一个点作为输出，而是给出一个区域，这个区域是找到目标图像的最可能区域，这就是“变分”一词的由来。

**VAE**：

观测变量 $x$，对应我们所见的数据以及潜变量 $z$，用于捕捉隐藏的变化因素。

* 解码器输出的概率分布：$p_{\phi}(x|z)$
* 编码器输出的概率分布：$q_{\theta}(z|x)$

### 3、VAE 的训练

VAE 设置的主要目标是最终图像应尽可能接近原始图像。这里有两个神经网络，前者负责学习编码；后者负责学习解码。我们需要以某种方式训练这些神经网络的参数来优化某个目标。所以目标函数是什么？

我们最初的目标是希望我们的概率分布能够匹配底层数据的真实概率分布。这意味着我们要最大化 $$p_{\phi}(x)$$例如如果你输入一张图像，解码器网络应该给出一个很高的概率值，这说明变分自编码器训练得很好。而如果得到的值是 0，这意味着解码器认为这个图像不太可能出现在你的分布中，但这是不对的，因为我就是从分布本身取的这张图像。

问题是，计算这个概率并不简单，需要任取一个潜在空间中的点，进行计算输出某特定图像的概率，本质上，我们需要对整个潜在空间中所有可能的点进行积分。$$p_{\phi}(x)=\int p_{\phi}(x|z)p(z)\mathrm{d}z$$
#### ELBO

详见 [[理解扩散模型（Paper）]] 第 2.1、2.2 章节


$$\begin{align}
{\mathbb{E}_{q_{\phi}(z|x)}\left[\log\frac{p(x, z)}{q_{\phi}(z|x)}\right]}
&= {\mathbb{E}_{q_{\phi}(z|x)}\left[\log\frac{p_{\theta}(x|z)p(z)}{q_{\phi}(z|x)}\right]}         && {\text{(Chain Rule of Probability)}}\\
&= {\mathbb{E}_{q_{\phi}(z|x)}\left[\log p_{\theta}(x|z)\right] + \mathbb{E}_{q_{\phi}(z|x)}\left[\log\frac{p(z)}{q_{\phi}(z|x)}\right]}         && {\text{(Split the Expectation)}}\\
&= \underbrace{{\mathbb{E}_{q_{\phi}(z|x)}\left[\log p_{\theta}(x|z)\right]}}_\text{reconstruction term} - \underbrace{{D_{\mathrm{KL}}({q_{\phi}(z|x)} \| {p(z)})}}_\text{prior matching term} && {\text{(Definition of KL Divergence)}}
\end{align}$$

计算上可行的训练目标，证据下界由以下两项组成：

* 第一项是重构项，它来自 *解码器* 的概率，表示重建输出与原始输入相似。即在给定生成该图像的潜在变量的情况下，从解码器分布中采样该图像的概率。所以这基本上表明，无论你最终看到的图像是什么，重建输出都应该尽可能接近原始输入。
* 第二项是正则化项，它本质上鼓励 *编码器* 分布尽可能接近潜在变量的假设分布，而这种分布通常是一个高斯分布。当我们将真实空间中的变量或数据样本转换到潜在空间时，它们可以以任何方式分布。但在更现实的场景中，分布更可能是高斯分布，因为会有一个平均值，而极端值的概率会非常低。因此我们希望编码器在潜在空间生成的分布尽可能接近一个以均值为中心、具有固定方差的高斯分布。

因此训练 VAE 的核心目标就是最大化 ELBO——这不仅涉及解码器的优化，还需要同步训练编码器。本质上，我们是在通过调整两个神经网络的权重参数来实现 ELBO 的最大化。

#### Demo 演练

[MNIST VAE Train Colab Notebook](https://colab.research.google.com/drive/18A4ApqBHv3-1K0k8rSe2rVOQ5viNpqA8?usp=sharing)

假设解码器的输入 2 个神经元，即假设潜在变量有两个维度，隐藏层 400，输出层 784 个 $\mu$，编码器是相反的架构。编码器的输出是 4 个值，对应着两个均值和两个标准差值。

虽然你可能认为这里只有两个值（比如均值和标准差各两个参数），但实际上每个参数都对应着两个值——两个均值值和两个标准差值的对数。而潜在变量 $z=\mu+\sigma \cdot \epsilon$，其中 $\epsilon \sim \mathcal{N}(0, 1)$，接着将这个潜在变量作为解码器网络的输入，从而生成你的输出。这就是我们完整的编码器-解码器架构。

ELBO 的定义：

* 重建损失：重建损失的目标是使输出图像与输入图像完全相同。它会逐像素比较输入与输出图像。因此，重建损失被表示为真实图像与预测图像之间的简单二元交叉熵损失。
* KL 散度损失：KL 散度损失的目标是确保潜在空间的分布 $\sim \mathcal{N}(0,1)$。
	* 对于均值项：为了确保 $\mu=0$，第一个损失项是 $\mu^2$。
	* 对于标准差项：$\sigma^2-\log(\sigma^2)-1$
		* 方差过大，模型会因为过于混乱而受到惩罚，所以有 $\sigma^2$ 项
		* 方差过小，模型也会因为过于特定而受到惩罚，$-\log(\sigma^2)$ 项会很大，$-1$ 是我们希望方差尽可能接近于 1。

-----

